<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=">
<meta name="GENERATOR" content="Quadralay WebWorks Publisher 5.0.4">
<meta name="TEMPLATEBASE" content="SunLook1.0">
<meta name="LASTUPDATED" content="Wed Apr 05 20:07:16 2000">
<title>What Every Computer Scientist Should Know About Floating-Point Arithmetic</title>
</head>

<body bgcolor="#FFFFFF">

<!-- BEGINNING OF NAVIGATION BAR ------------------------------------------------- -->

<table width="100%" cellpadding="0" cellspacing="0" border="0">
<tr bgcolor="cccccc">

<td align="left">
&nbsp;&nbsp;<font face="helvetica,arial" size="2">Numerical Computation Guide</font>
</td>

<td valign="top" align="right"><a href="../../../index.html"><IMG SRC="images/home01.gif" ALT="Home" WIDTH="30" HEIGHT="26" BORDER="0" 
VSPACE="0"></a><a href="ncgTOC.html"><IMG SRC="images/toc01.gif" ALT="Contents" WIDTH="30" HEIGHT="26" BORDER="0" 
VSPACE="0"></a><a href="ncg_x86.html"><IMG SRC="images/prev01.gif" ALT="Previous" WIDTH="30" HEIGHT="26" BORDER="0" 
VSPACE="0"></a><a href="ncg_compliance.html"><IMG SRC="images/next01.gif" ALT="Next" WIDTH="30" HEIGHT="26" BORDER="0" 
VSPACE="0"></a><a href="ncgIX.html"><IMG SRC="images/index01.gif" ALT="Index" WIDTH="30" HEIGHT="26" BORDER="0" VSPACE="0"></a></td>

</tr>
</table>

<!-- END OF NAVIGATION BAR ------------------------------------------------------- -->

<br clear="all">

<hr>

<blockquote>

<div align="center">
<h1 align="left">
  <a name="4675"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Appendix D </font>
</h1>
</div>

<h1 align="left">
  <a name="674"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">What Every Computer Scientist Should Know About Floating-Point Arithmetic</font>
</h1>


<p><hr noshade size="1">
  <a name="678"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><b>Note &#150; </b>This appendix is an edited reprint of the paper <em>What Every Computer Scientist Should Know About Floating-Point Arithmetic</em>, by David Goldberg, published in the March, 1991 issue of Computing Surveys. Copyright 1991, Association for Computing Machinery, Inc., reprinted by permission. </font>
<hr noshade size="1"></p>


<h2>
  <a name="852"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Abstract</font>
</h2>


<p>
  <a name="764"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Floating-point arithmetic is considered an esoteric subject by many people. This is rather surprising because floating-point is ubiquitous in computer systems. Almost every language has a floating-point datatype; computers from PCs to supercomputers have floating-point accelerators; most compilers will be called upon to compile floating-point algorithms from time to time; and virtually every operating system must respond to floating-point exceptions such as overflow. This paper presents a tutorial on those aspects of floating-point that have a direct impact on designers of computer systems. It begins with background on floating-point representation and rounding error, continues with a discussion of the IEEE floating-point standard, and concludes with numerous examples of how computer builders can better support floating-point.</font>
</p>


<p>
  <a name="765"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Categories and Subject Descriptors: (Primary) C.0 [Computer Systems Organization]: General -- <em>instruction set design</em>; D.3.4 [Programming Languages]: Processors -- <em>compilers, optimization</em>; G.1.0 [Numerical Analysis]: General -- <em>computer arithmetic, error analysis, numerical algorithms</em> (Secondary) </font>
</p>


<p>
  <a name="751"> </a><font face="Verdana, Arial, Helvetica, sans-serif">D.2.1 [Software Engineering]: Requirements/Specifications -- <em>languages</em>; D.3.4 Programming Languages]: Formal Definitions and Theory -- <em>semantics</em>; D.4.1 Operating Systems]: Process Management -- <em>synchronization</em>.</font>
</p>


<p>
  <a name="769"> </a><font face="Verdana, Arial, Helvetica, sans-serif">General Terms: Algorithms, Design, Languages</font>
</p>


<p>
  <a name="771"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Additional Key Words and Phrases: Denormalized number, exception, floating-point, floating-point standard, gradual underflow, guard digit, NaN, overflow, relative error, rounding error, rounding mode, ulp, underflow.</font>
</p>


<h2>
  <a name="731"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Introduction</font>
</h2>


<p>
  <a name="679"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Builders of computer systems often need information about floating-point arithmetic. There are, however, remarkably few sources of detailed information about it. One of the few books on the subject, <em>Floating-Point Computation</em> by Pat Sterbenz, is long out of print. This paper is a tutorial on those aspects of floating-point arithmetic (<em>floating-point </em>hereafter) that have a direct connection to systems building. It consists of three loosely connected parts. The first section, <a href="ncg_goldberg.html#680">Rounding Error</a>, discusses the implications of using different rounding strategies for the basic operations of addition, subtraction, multiplication and division. It also contains background information on the two methods of measuring rounding error, ulps and <code>relative</code> <code>error</code>. The second part discusses the IEEE floating-point standard, which is becoming rapidly accepted by commercial hardware manufacturers. Included in the IEEE standard is the rounding method for basic operations. The discussion of the standard draws on the material in the section <a href="ncg_goldberg.html#680">Rounding Error</a>. The third part discusses the connections between floating-point and the design of various aspects of computer systems. Topics include instruction set design, optimizing compilers and exception handling. </font>
</p>


<p>
  <a name="675"> </a><font face="Verdana, Arial, Helvetica, sans-serif">I have tried to avoid making statements about floating-point without also giving reasons why the statements are true, especially since the justifications involve nothing more complicated than elementary calculus. Those explanations that are not central to the main argument have been grouped into a section called "The Details," so that they can be skipped if desired. In particular, the proofs of many of the theorems appear in this section. The end of each proof is marked with the <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> symbol. When a proof is not included, the <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> appears immediately following the statement of the theorem. </font>
</p>


<h2>
  <a name="680"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Rounding Error </font>
</h2>


<p>
  <a name="681"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Squeezing infinitely many real numbers into a finite number of bits requires an approximate representation. Although there are infinitely many integers, in most programs the result of integer computations can be stored in 32 bits. In contrast, given any fixed number of bits, most calculations with real numbers will produce quantities that cannot be exactly represented using that many bits. Therefore the result of a floating-point calculation must often be rounded in order to fit back into its finite representation. This rounding error is the characteristic feature of floating-point computation. The section <a href="ncg_goldberg.html#689">Relative Error and Ulps</a> describes how it is measured. </font>
</p>


<p>
  <a name="676"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since most floating-point calculations have rounding error anyway, does it matter if the basic arithmetic operations introduce a little bit more rounding error than necessary? That question is a main theme throughout this section. The section <a href="ncg_goldberg.html#693">Guard Digits</a> discusses<em> guard </em>digits, a means of reducing the error when subtracting two nearby numbers. Guard digits were considered sufficiently important by IBM that in 1968 it added a guard digit to the double precision format in the System/360 architecture (single precision already had a guard digit), and retrofitted all existing machines in the field. Two examples are given to illustrate the utility of guard digits. </font>
</p>


<p>
  <a name="1362"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard goes further than just requiring the use of a guard digit. It gives an algorithm for addition, subtraction, multiplication, division and square root, and requires that implementations produce the same result as that algorithm. Thus, when a program is moved from one machine to another, the results of the basic operations will be the same in every bit if both machines support the IEEE standard. This greatly simplifies the porting of programs. Other uses of this precise specification are given in <a href="ncg_goldberg.html#704">Exactly Rounded Operations</a>. </font>
</p>


<h3>
  <a name="682"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Floating-point Formats </font>
</h3>


<p>
  <a name="683"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Several different representations of real numbers have been proposed, but by far the most widely used is the floating-point representation.<a href="#1370"><sup>1</sup></a> Floating-point representations have a base <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> (which is always assumed to be even) and a precision <font face="Arial,Helvetica"><em>p</em></font>. If <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10 and <font face="Arial,Helvetica"><em>p</em></font> = 3, then the number 0.1 is represented as 1.00 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-1</sup>. If <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 and <font face="Arial,Helvetica"><em>p</em></font>&nbsp;=&nbsp;24, then the decimal number 0.1 cannot be represented exactly, but is approximately 1.10011001100110011001101<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 2<sup>-4</sup>. </font>
</p>


<p>
  <a name="10061"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In general, a floating-point number will be represented as <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> <font face="Arial,Helvetica"><em>d.dd... d</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times; <img src="chars/beta.gif"></font><sup><em>e</em></sup>, where <font face="Arial,Helvetica"><em>d.dd... d</em></font> is called the <em>significand<a href="#1377"><sup>2</sup></a></em> and has<em> </em><font face="Arial,Helvetica"><em>p</em></font> digits. More precisely <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> <font face="Arial,Helvetica"><em>d</em></font><sub>0</sub><font face="Arial,Helvetica"><em> . d</em></font><sub>1</sub><font face="Arial,Helvetica"><em> d</em></font><sub>2</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>d</em></font><sub>p-1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup> represents the number </font>
</p>


<a name="687"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(1) <img src="images/ncg_goldberg283.gif" height="25" width="260">
.<br></font>


<p>
  <a name="13488"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The term <em>floating-point number</em> will be used to mean a real number that can be exactly represented in the format under discussion. Two other parameters associated with floating-point representations are the largest and smallest allowable exponents, <font face="Arial,Helvetica"><em>e</em></font><sub>max</sub> and <font face="Arial,Helvetica"><em>e</em></font><sub>min</sub>. Since there are <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>p</sup> possible significands, and <font face="Arial,Helvetica"><em>e</em></font><sub>max</sub> - <font face="Arial,Helvetica"><em>e</em></font><sub>min</sub> + 1 possible exponents, a floating-point number can be encoded in</font>
</p>


<a name="1366"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg278.gif" height="21" width="212">
<br></font>


<p>
  <a name="1371"> </a><font face="Verdana, Arial, Helvetica, sans-serif">bits, where the final +1 is for the sign bit. The precise encoding is not important for now. </font>
</p>


<p>
  <a name="1372"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There are two reasons why a real number might not be exactly representable as a floating-point number. The most common situation is illustrated by the decimal number 0.1. Although it has a finite decimal representation, in binary it has an infinite repeating representation. Thus when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, the number 0.1 lies strictly between two floating-point numbers and is exactly representable by neither of them. A less common situation is that a real number is out of range, that is, its absolute value is larger than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <img src="images/ncg_goldberg213.gif" height="20" width="28">
 or smaller than 1.0 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <img src="images/ncg_goldberg218.gif" height="20" width="27">
. Most of this paper discusses issues due to the first reason. However, numbers that are out of range will be discussed in the sections <a href="ncg_goldberg.html#918">Infinity</a> and <a href="ncg_goldberg.html#929">Denormalized Numbers</a>. </font>
</p>


<p>
  <a name="684"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Floating-point representations are not necessarily unique. For example, both 0.01&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>1</sup> and 1.00 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-1</sup> represent 0.1. If the leading digit is nonzero (<font face="Arial,Helvetica"><em>d</em></font><sub>0</sub> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font> 0 in equation <a href="ncg_goldberg.html#687">(1)</a> above), then the representation is said to be <em>normalized</em>. The floating-point number 1.00 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-1</sup> is normalized, while 0.01 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>1</sup> is not. When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>&nbsp;= 2, <font face="Arial,Helvetica"><em>p</em></font> = 3, <font face="Arial,Helvetica"><em>e</em></font><sub>min</sub>&nbsp;= -1 and <font face="Arial,Helvetica"><em>e</em></font><sub>max</sub> = 2 there are 16 normalized floating-point numbers, as shown in <a href="ncg_goldberg.html#1374">FIGURE&nbsp;D-1</a>. The bold hash marks correspond to numbers whose significand is 1.00. Requiring that a floating-point representation be normalized makes the representation unique. Unfortunately, this restriction makes it impossible to represent zero! A natural way to represent 0 is with 1.0&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <img src="images/ncg_goldberg304.gif" height="20" width="42">
, since<sup> </sup>this preserves the fact that the numerical ordering of nonnegative real numbers corresponds to the lexicographic ordering of their floating-point representations.<a href="#685"><sup>3</sup></a> When the exponent is stored in a <font face="Arial,Helvetica"><em>k</em></font> bit field, that means that only 2<sup><em>k</em></sup> - 1 values are available for use as exponents, since one must be reserved to represent 0. </font>
</p>


<p>
  <a name="691"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Note that the <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> in a floating-point number is part of the notation, and different from a floating-point multiply operation. The meaning of the <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> symbol should be clear from the context. For example, the expression (2.5 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-3</sup>) <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> (4.0 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>2</sup>) involves only a single floating-point multiplication.</font>
</p>


<a name="1373"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg251.gif" height="71" width="700">
<br></font>


<a name="1374"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">FIGURE D-1 	 Normalized numbers when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <font face="Arial,Helvetica"><em>p</em></font> = 3,<font face="Arial,Helvetica"><em> e</em></font><sub>min</sub>  =  -1, <font face="Arial,Helvetica"><em>e</em></font><sub>max</sub>  = 2<br></font>


<h3>
  <a name="689"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Relative Error and Ulps </font>
</h3>


<p>
  <a name="688"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since rounding error is inherent in floating-point computation, it is important to have a way to measure this error. Consider the floating-point format with <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>&nbsp;= 10 and <font face="Arial,Helvetica"><em>p</em></font> = 3, which will be used throughout this section. If the result of a floating-point computation is 3.12 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-2</sup>, and the answer when computed to infinite precision is .0314, it is clear that this is in error by 2 units in the last place. Similarly, if the real number .0314159 is represented as 3.14 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-2</sup>, then it is in error by .159 units in the last place. In general, if the floating-point number <font face="Arial,Helvetica"><em>d.d</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>d</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup> is used to represent <font face="Arial,Helvetica"><em>z</em></font>, then it is in error by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakmidl.gif"></font><font face="Arial,Helvetica"><em>d.d</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>d</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> - </font>(<font face="Arial,Helvetica"><em>z</em></font>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakmidl.gif"><img src="chars/beta.gif"></font><sup><em>p-1 </em></sup>units in the last place.<a href="#690"><sup>4</sup></a><sup>,</sup> <a href="#728"><sup>5</sup></a> The term <em>ulps</em> will be used as shorthand for "units in the last place." If the result of a calculation is the floating-point number nearest to the correct result, it still might be in error by as much as .5 ulp. Another way to measure the difference between a floating-point number and the real number it is approximating is <em>relative error</em>, which is simply the difference between the two numbers divided by the real number. For example the relative error committed when approximating 3.14159 by 3.14 &times; 10<sup>0</sup> is .00159/3.14159&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> .0005. </font>
</p>


<p>
  <a name="714"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To compute the relative error that corresponds to .5 ulp, observe that when a real number is approximated by the closest possible floating-point number<em> </em><font face="Arial,Helvetica"><em>d.dd</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>dd</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font><strong> </strong><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>,<strong> </strong>the error can be as large as 0.00<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>00<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>'<font  face="Verdana, Arial, Helvetica, sans-serif"> &times; <img src="chars/beta.gif"></font><sup><em>e</em></sup>, where <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>' is the digit <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2, there are <font face="Arial,Helvetica"><em>p</em></font> units in the significand of the floating-point number, and <font face="Arial,Helvetica"><em>p</em></font><em> </em>units of 0 in the significand of the error. This error is ((<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>-p</em></sup>) <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>. Since numbers of the form <font face="Arial,Helvetica"><em>d.dd</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>dd</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup> all have the same absolute error, but have values that range between <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup> and <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>, the relative error ranges between ((<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>-p</em></sup>) <font  face="Verdana, Arial, Helvetica, sans-serif">&times; <img src="chars/beta.gif"></font><sup><em>e</em></sup>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup> and ((<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>-p</em></sup>) <font  face="Verdana, Arial, Helvetica, sans-serif">&times; <img src="chars/beta.gif"></font><sup><em>e</em></sup>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e+1</em></sup>. That is, </font>
</p>


<a name="5736"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(2) <img src="images/ncg_goldberg36.gif" height="31" width="105">
<br></font>


<p>
  <a name="716"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In particular, the relative error corresponding to .5 ulp can vary by a factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. This factor is called the <em>wobble</em>. Setting <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> = (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>-p</em></sup> to the largest of the bounds in <a href="ncg_goldberg.html#5736">(2)</a> above, we can say that when a real number is rounded to the closest floating-point number, the relative error is always bounded by <font face="Arial,Helvetica"><em>e</em></font>, which is referred to as <em>machine epsilon</em>. </font>
</p>


<p>
  <a name="4695"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In the example above, the relative error was .00159/3.14159 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> .0005. In order to avoid such small numbers, the relative error is normally written as a factor times <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, which in this case is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> = (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>-p</em></sup> = 5(10)<sup>-3</sup> = .005. Thus the relative error would be expressed as (.00159/3.14159)/.005) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"> <img src="chars/approx.gif"></font> 0.1<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. </font>
</p>


<p>
  <a name="4698"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To illustrate the difference between ulps and relative error, consider the real number <font face="Arial,Helvetica"><em>x</em></font> = 12.35. It is approximated by <img src="images/ncg_goldberg298.gif" height="16" width="10">
 = 1.24<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>1</sup>. The error is 0.5 ulps, the relative error is 0.<font face="Arial,Helvetica"><em>8</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Next consider the computation 8<img src="images/ncg_goldberg302.gif" height="16" width="10">
. The exact value is 8<font face="Arial,Helvetica"><em>x</em></font> = 98.8, while the computed value is 8<img src="images/ncg_goldberg126.gif" height="16" width="10">
 = 9.92 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>1</sup>. The error is now 4.0 ulps, but the relative error is still 0.<font face="Arial,Helvetica"><em>8</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. The error measured in ulps is 8 times larger, even though the relative error is the same. In general, when the base is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>, a fixed relative error expressed in ulps can wobble by a factor of up to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. And conversely, as equation <a href="ncg_goldberg.html#5736">(2)</a> above shows, a fixed error of .5 ulps results in a relative error that can wobble by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>.</font>
</p>


<p>
  <a name="4701"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The most natural way to measure rounding error is in ulps. For example rounding to the nearest floating-point number corresponds to an error of less than or equal to .5 ulp. However, when analyzing the rounding error caused by various formulas, relative error is a better measure. A good illustration of this is the analysis in the section <a href="ncg_goldberg.html#1129">Theorem 9</a>. Since <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> can overestimate the effect of rounding to the nearest floating-point number by the wobble factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>, error estimates of formulas will be tighter on machines with a small <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. </font>
</p>


<p>
  <a name="4702"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When only the order of magnitude of rounding error is of interest, ulps and <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> may be used interchangeably, since they differ by at most a factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. For example, when a floating-point number is in error by <font face="Arial,Helvetica"><em>n</em></font> ulps, that means that the number of contaminated digits is log<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><font face="Arial,Helvetica"><em> n</em></font>. If the relative error in a computation is <font face="Arial,Helvetica"><em>n</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, then </font>
</p>


<a name="1378"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(3)  contaminated digits <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> log<sub><img src="chars/beta.gif"></sub><font face="Arial,Helvetica"><em> n</em></font>.<br></font>


<h3>
  <a name="693"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Guard Digits </font>
</h3>


<p>
  <a name="694"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One method of computing the difference between two floating-point numbers is to compute the difference exactly and then round it to the nearest floating-point number. This is very expensive if the operands differ greatly in size. Assuming <font face="Arial,Helvetica"><em>p</em></font> = 3, 2.15 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>12</sup> - 1.25 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-5</sup> would be calculated as </font>
</p>

<dl>  <dl>
     <dt> <a name="1379"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>	 x</em></font> = 2.15<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>12 <br></sup><font face="Arial,Helvetica"><em>	 y</em></font> = .0000000000000000125<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>12<br></sup><font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> = 2.1499999999999999875 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>12</sup></font>
  </dl>
</dl>
<p>
  <a name="695"> </a><font face="Verdana, Arial, Helvetica, sans-serif">which rounds to 2.15 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>12</sup>. Rather than using all these digits, floating-point hardware normally operates on a fixed number of digits. Suppose that the number of digits kept is <font face="Arial,Helvetica"><em>p</em></font>, and that when the smaller operand is shifted right, digits are simply discarded (as opposed to rounding). Then 2.15&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>12</sup>&nbsp;-&nbsp;1.25&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>-5</sup> becomes </font>
</p>

<dl>  <dl>
     <dt> <a name="1382"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>	 x</em></font> = 2.15<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>12 <br></sup><font face="Arial,Helvetica"><em>	 y</em></font> = 0.00<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>12<br></sup><font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> = 2.15 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>12</sup></font>
  </dl>
</dl>
<p>
  <a name="696"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The answer is exactly the same as if the difference had been computed exactly and then rounded. Take another example: 10.1 - 9.93. This becomes </font>
</p>

<dl>  <dl>
     <dt> <a name="1383"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>	 x</em></font> = 1.01 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>1 <br></sup><font face="Arial,Helvetica"><em>	 y</em></font> = 0.99<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>1<br></sup><font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> = .02<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>1</sup></font>
  </dl>
</dl>
<p>
  <a name="697"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The correct answer is .17, so the computed difference is off by 30 ulps and is wrong in every digit! How bad can the error be?</font>
</p>


<h4>
  <a name="1367"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 1 </font>
</h4>

<dl>
  <dt> <a name="1381"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Using a floating-point format with parameters </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><em> </em><em>and</em><em> </em><font face="Arial,Helvetica"><em>p</em></font><em>, and computing differences using </em><font face="Arial,Helvetica"><em>p</em></font><em> </em><em>digits, the relative error of the result can be as large as</em><em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><em> </em>-<em> 1</em>. </font>
</dl>

<h4>
  <a name="1368"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1380"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A relative error of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1 in the expression <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> occurs when <font face="Arial,Helvetica"><em>x</em></font> = 1.00<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>0 and <font face="Arial,Helvetica"><em>y</em></font>&nbsp;=&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">.<img src="chars/rho.gif"><img src="chars/rho.gif">...<img src="chars/rho.gif"></font>, where <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/rho.gif"></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1. Here <font face="Arial,Helvetica"><em>y</em></font> has <font face="Arial,Helvetica"><em>p</em></font> digits (all equal to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/rho.gif"></font>). The exact difference is <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>. However, when computing the answer using only <font face="Arial,Helvetica"><em>p</em></font> digits, the rightmost digit of <font face="Arial,Helvetica"><em>y</em></font> gets shifted off, and so the computed difference is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup>+1</sup>. Thus the error is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>&nbsp;- <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup>+1</sup> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup> (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1), and the relative error is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1)/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</dl>

<p>
  <a name="1369"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>=2, the relative error can be as large as the result, and when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>=10, it can be 9 times larger. Or to put it another way, when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>=2, equation <a href="ncg_goldberg.html#1378">(3)</a> shows that the number of contaminated digits is log<sub>2</sub>(1/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>) = log<sub>2</sub>(2<sup><em>p</em></sup>) = <font face="Arial,Helvetica"><em>p</em></font>. That is, all of the <font face="Arial,Helvetica"><em>p</em></font> digits in the result are wrong! Suppose that one extra digit is added to guard against this situation (a <em>guard digit</em>). That is, the smaller number is truncated to <font face="Arial,Helvetica"><em>p</em></font> + 1 digits, and then the result of the subtraction is rounded to <font face="Arial,Helvetica"><em>p</em></font> digits. With a guard digit, the previous example becomes </font>
</p>

<dl>  <dl>
     <dt> <a name="9503"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>	 x</em></font> = 1.01<font  face="Verdana, Arial, Helvetica, sans-serif">0 &times;</font> 10<sup>1<br></sup><font face="Arial,Helvetica"><em>	 y</em></font> = 0.993<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>1<br></sup><font face="Arial,Helvetica"><em>x</em></font> - y = .017 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>1</sup></font>
  </dl>
</dl>
<p>
  <a name="698"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and the answer is exact. With a single guard digit, the relative error of the result may be greater than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, as in 110 - 8.59. </font>
</p>

<dl>  <dl>
     <dt> <a name="677"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>	 x</em></font> = 1.1<font  face="Verdana, Arial, Helvetica, sans-serif">0 &times;</font> 10<sup>2 <br></sup><font face="Arial,Helvetica"><em>	 y</em></font> = .085<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>2<br></sup><font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font> = 1.015 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>2</sup></font>
  </dl>
</dl>
<p>
  <a name="706"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This rounds to 102, compared with the correct answer of 101.41, for a relative error of .006, which is greater than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> = .005. In general, the relative error of the result can be only slightly larger than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. More precisely, </font>
</p>


<h4>
  <a name="699"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 2 </font>
</h4>

<dl>
  <dt> <a name="1385"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If </em><font face="Arial,Helvetica"><em>x</em></font><em> and </em><font face="Arial,Helvetica"><em>y</em></font><em> are floating-point numbers in a format with parameters </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><em> </em><em>and </em><font face="Arial,Helvetica"><em>p</em></font><em>, and if subtraction is done with </em><font face="Arial,Helvetica"><em>p</em></font><em> + 1 digits (i.e. one guard digit), then the relative rounding error in the result is less than 2</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. </font>
</dl>

<p>
  <a name="1388"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This theorem will be proven in <a href="ncg_goldberg.html#1127">Rounding Error</a>. Addition is included in the above theorem since <font face="Arial,Helvetica"><em>x</em></font> and <font face="Arial,Helvetica"><em>y</em></font> can be positive or negative. </font>
</p>


<h3>
  <a name="700"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Cancellation</font>
</h3>


<p>
  <a name="701"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The last section can be summarized by saying that without a guard digit, the relative error committed when subtracting two nearby quantities can be very large. In other words, the evaluation of any expression containing a subtraction (or an addition of quantities with opposite signs) could result in a relative error so large that <em>all</em> the digits are meaningless (Theorem 1). When subtracting nearby quantities, the most significant digits in the operands match and cancel each other. There are two kinds of cancellation: catastrophic and benign. </font>
</p>


<p>
  <a name="9518"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Catastrophic cancellation</em> occurs when the operands are subject to rounding errors. For example in the quadratic formula, the expression <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - 4<font face="Arial,Helvetica"><em>ac</em></font> occurs. The quantities <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> and 4<font face="Arial,Helvetica"><em>ac</em></font> are subject to rounding errors since they are the results of floating-point multiplications. Suppose that they are rounded to the nearest floating-point number, and so are accurate to within <em>.5 </em>ulp. When they are subtracted, cancellation can cause many of the accurate digits to disappear, leaving behind mainly digits contaminated by rounding error. Hence the difference might have an error of many ulps. For example, consider <font face="Arial,Helvetica"><em>b</em></font> = 3.34, <font face="Arial,Helvetica"><em>a</em></font>&nbsp;= 1.22, and <font face="Arial,Helvetica"><em>c</em></font> = 2.28. The exact value of <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup>&nbsp;-&nbsp;4<font face="Arial,Helvetica"><em>ac</em></font> is .0292. But <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> rounds to 11.2 and 4<font face="Arial,Helvetica"><em>ac </em></font>rounds to 11.1, hence the final answer is .1 which is an error by 70 ulps, even though 11.2 - 11.1 is exactly equal to .1<a href="#9521"><sup>6</sup></a>. The subtraction did not introduce any error, but rather exposed the error introduced in the earlier multiplications.</font>
</p>


<p>
  <a name="707"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Benign cancellation</em> occurs when subtracting exactly known quantities. If <em>x</em> and <em>y</em> have no rounding error, then by Theorem 2 if the subtraction is done with a guard digit, the difference <em>x</em>-y has a very small relative error (less than 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>).</font>
</p>


<p>
  <a name="708"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A formula that exhibits catastrophic cancellation can sometimes be rearranged to eliminate the problem. Again consider the quadratic formula </font>
</p>


<a name="5751"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(4) <img src="images/ncg_goldberg122.gif" height="37" width="233">
<br></font>


<p>
  <a name="1391"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <img src="images/ncg_goldberg11.gif" height="18" width="40">
, then <img src="images/ncg_goldberg16.gif" height="18" width="47">
 does not involve a cancellation and</font>
</p>


<a name="11563"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg46.gif" height="21" width="75">
. <br></font>


<p>
  <a name="11565"> </a><font face="Verdana, Arial, Helvetica, sans-serif">But the other addition (subtraction) in one of the formulas will have a catastrophic cancellation. To avoid this, multiply the numerator and denominator of <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub> by</font>
</p>


<a name="11566"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg51.gif" height="21" width="84">
<br></font>


<p>
  <a name="11568"> </a><font face="Verdana, Arial, Helvetica, sans-serif">(and similarly for <font face="Arial,Helvetica"><em>r</em></font><sub>2</sub>) to obtain </font>
</p>


<a name="5811"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(5) <img src="images/ncg_goldberg56.gif" height="37" width="233">
<br></font>


<p>
  <a name="10672"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <img src="images/ncg_goldberg60.gif" height="18" width="40">
 and <img src="images/ncg_goldberg10.gif" height="16" width="29">
, then computing <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub> using formula <a href="ncg_goldberg.html#5751">(4)</a> will involve a cancellation. Therefore, use formula <a href="ncg_goldberg.html#5811">(5)</a> for computing <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub> and <a href="ncg_goldberg.html#5751">(4)</a> for <font face="Arial,Helvetica"><em>r</em></font><sub>2</sub>. On the other hand, if <font face="Arial,Helvetica"><em>b</em></font> &lt; 0, use <a href="ncg_goldberg.html#5751">(4)</a> for computing <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub> and <a href="ncg_goldberg.html#5811">(5)</a> for <font face="Arial,Helvetica"><em>r</em></font><sub>2</sub>. </font>
</p>


<p>
  <a name="1393"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The expression <em>x</em><sup>2</sup> - <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> is another formula that exhibits catastrophic cancellation. It is more accurate to evaluate it as (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>).<a href="#1397"><sup>7</sup></a> Unlike the quadratic formula, this improved form still has a subtraction, but it is a benign cancellation of quantities without rounding error, not a catastrophic one. By Theorem 2, the relative error in <em>x</em>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>y</em></font> is at most 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. The same is true of <em>x</em> +<font face="Arial,Helvetica"><em> y</em></font>. Multiplying two quantities with a small relative error results in a product with a small relative error (see the section <a href="ncg_goldberg.html#1127">Rounding Error</a>). </font>
</p>


<p>
  <a name="725"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In order to avoid confusion between exact and computed values, the following notation is used. Whereas <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font> denotes the exact difference of <em>x</em> and <em>y</em>, <em>x</em> <img src="images/ncg_goldberg199.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> y</em></font> denotes the computed difference (i.e., with rounding error). Similarly <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font>, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font>, and <img src="images/ncg_goldberg209.gif" height="12" width="11">
 denote computed addition, multiplication, and division, respectively. All caps indicate the computed value of a function, as in <code>LN(x)</code> or <code>SQRT(x)</code>. Lowercase functions and traditional mathematical notation denote their exact values as in ln(<font face="Arial,Helvetica"><em>x</em></font>) and <img src="images/ncg_goldberg41.gif" height="19" width="18">
 . </font>
</p>


<p>
  <a name="11589"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Although (<font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg26.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (<font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>) is an excellent approximation to <em>x</em><sup>2</sup> - y<sup>2</sup>, the floating-point numbers <em>x</em> and <em>y</em> might themselves be approximations to some true quantities <img src="images/ncg_goldberg35.gif" height="16" width="10">
 and <img src="images/ncg_goldberg40.gif" height="16" width="10">
. For example, <img src="images/ncg_goldberg45.gif" height="16" width="10">
 and <img src="images/ncg_goldberg50.gif" height="16" width="10">
 might be exactly known decimal numbers that cannot be expressed exactly in binary. In this case, even though <em>x</em>&nbsp;<img src="images/ncg_goldberg55.gif" height="15" width="13">
<font face="Arial,Helvetica"><em>&nbsp;y</em></font> is a good approximation to <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>, it can have a huge relative error compared to the true expression <img src="images/ncg_goldberg74.gif" height="16" width="28">
, and so the advantage of (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) over <em>x</em><sup>2</sup> - y<sup>2</sup> is not as dramatic. Since computing (<font face="Arial,Helvetica"><em>x</em></font>&nbsp;+<font face="Arial,Helvetica"><em>&nbsp;y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> -<font face="Arial,Helvetica"><em> y</em></font>) is about the same amount of work as computing <em>x</em><sup>2</sup>&nbsp;-&nbsp;y<sup>2</sup>, it is clearly the preferred form in this case. In general, however, replacing a catastrophic cancellation by a benign one is not worthwhile if the expense is large, because the input is often (but not always) an approximation. But eliminating a cancellation entirely (as in the quadratic formula) is worthwhile even if the data are not exact. Throughout this paper, it will be assumed that the floating-point inputs to an algorithm are exact and that the results are computed as accurately as possible.</font>
</p>


<p>
  <a name="711"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The expression <em>x</em><sup>2</sup> - <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> is more accurate when rewritten as (<font face="Arial,Helvetica"><em>x</em></font> -<font face="Arial,Helvetica"><em> y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> +<font face="Arial,Helvetica"><em> y</em></font>) because a catastrophic cancellation is replaced with a benign one. We next present more interesting examples of formulas exhibiting catastrophic cancellation that can be rewritten to exhibit only benign cancellation. </font>
</p>


<p>
  <a name="1402"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The area of a triangle can be expressed directly in terms of the lengths of its sides <font face="Arial,Helvetica"><em>a</em></font>, <font face="Arial,Helvetica"><em>b</em></font>, and <font face="Arial,Helvetica"><em>c</em></font> as </font>
</p>


<a name="1403"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(6) <img src="images/ncg_goldberg263.gif" height="19" width="287">
<br></font>


<p>
  <a name="10676"> </a><font face="Verdana, Arial, Helvetica, sans-serif">(Suppose the triangle is very flat; that is, <font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>. Then <font face="Arial,Helvetica"><em>s</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font face="Arial,Helvetica"><em>a</em></font>, and the term (<font face="Arial,Helvetica"><em>s</em></font>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>a</em></font>) in formula <a href="ncg_goldberg.html#1403">(6)</a> subtracts two nearby numbers, one of which may have rounding error. For example, if <font face="Arial,Helvetica"><em>a</em></font> = 9.0, <font face="Arial,Helvetica"><em>b</em></font> =<font face="Arial,Helvetica"><em> c</em></font> = 4.53, the correct value of <font face="Arial,Helvetica"><em>s</em></font> is 9.03 and <font face="Arial,Helvetica"><em>A</em></font> is 2.342.... Even though the computed value of <font face="Arial,Helvetica"><em>s</em></font> (9.05) is in error by only 2 ulps, the computed value of <font face="Arial,Helvetica"><em>A</em></font> is 3.04, an error of 70 ulps. </font>
</p>


<p>
  <a name="1404"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There is a way to rewrite formula <a href="ncg_goldberg.html#1403">(6)</a> so that it will return accurate results even for flat triangles [Kahan 1986]. It is </font>
</p>


<a name="1405"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(7) <img src="images/ncg_goldberg279.gif" height="35" width="350">
<br></font>


<p>
  <a name="10678"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <font face="Arial,Helvetica"><em>a</em></font>, <font face="Arial,Helvetica"><em>b, </em></font>and <font face="Arial,Helvetica"><em>c</em></font> do not satisfy <font face="Arial,Helvetica"><em>a</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/gtequal.gif"></font> <font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>, rename them before applying <a href="ncg_goldberg.html#1405">(7)</a>. It is straightforward to check that the right-hand sides of <a href="ncg_goldberg.html#1403">(6)</a> and <a href="ncg_goldberg.html#1405">(7)</a> are algebraically identical. Using the values of <font face="Arial,Helvetica"><em>a</em></font>, <font face="Arial,Helvetica"><em>b</em></font>, and <font face="Arial,Helvetica"><em>c</em></font> above gives a computed area of 2.35, which is 1 ulp in error and much more accurate than the first formula.</font>
</p>


<p>
  <a name="712"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Although formula <a href="ncg_goldberg.html#1405">(7)</a> is much more accurate than <a href="ncg_goldberg.html#1403">(6)</a> for this example, it would be nice to know how well <a href="ncg_goldberg.html#1405">(7)</a> performs in general. </font>
</p>


<h4>
  <a name="1409"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 3 </font>
</h4>

<dl>
  <dt> <a name="1407"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>The rounding error incurred when using <a href="ncg_goldberg.html#1405">(7)</a> to compute the area of a triangle is at most 11<img src="chars/epsilon.gif"></em><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">, provided that subtraction is performed with a guard digit, e&nbsp;</font><em><img src="chars/lt_equal.gif"></em><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">&nbsp;.005, and that square roots are computed to within 1/2 </font>ulp<em>. </em></font>
</dl>

<p>
  <a name="1408"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The condition that <font face="Arial,Helvetica"><em>e</em></font> &lt; .005 is met in virtually every actual floating-point system. For example when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <em>p</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 8 ensures that <font face="Arial,Helvetica"><em>e</em></font> &lt; .005, and when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>&nbsp;3 is enough. </font>
</p>


<p>
  <a name="1410"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In statements like Theorem 3 that discuss the relative error of an expression, it is understood that the expression is computed using floating-point arithmetic. In particular, the relative error is actually of the expression </font>
</p>


<a name="1411"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(8) <code>SQRT</code>((<font face="Arial,Helvetica"><em>a </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"> (</font><font face="Arial,Helvetica"><em>b</em></font> <em><img src="chars/circplus.gif"></em><font  face="Verdana, Arial, Helvetica, sans-serif"> </font><font face="Arial,Helvetica"><em>c</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"> (</font><font face="Arial,Helvetica"><em>c</em></font> <img src="images/ncg_goldberg65.gif" height="15" width="13">
<font  face="Verdana, Arial, Helvetica, sans-serif"> (</font><font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg289.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b)) </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (<font face="Arial,Helvetica"><em>c </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><font face="Arial,Helvetica"><em> </em></font>(<font face="Arial,Helvetica"><em>a </em></font><img src="images/ncg_goldberga.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> b</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><font face="Arial,Helvetica"><em> (a </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><font face="Arial,Helvetica"><em> </em></font>(<font face="Arial,Helvetica"><em>b</em></font> <img src="images/ncg_goldberg190.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> c</em></font>))) <img src="images/ncg_goldberg28.gif" height="12" width="11">
<font face="Arial,Helvetica"><em> 4</em></font><br></font>


<p>
  <a name="1412"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Because of the cumbersome nature of <a href="ncg_goldberg.html#1411">(8)</a>, in the statement of theorems we will usually say <em>the computed value of </em><font face="Arial,Helvetica"><em>E</em></font> rather than writing out <font face="Arial,Helvetica"><em>E</em></font> with circle notation.</font>
</p>


<p>
  <a name="713"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Error bounds are usually too pessimistic. In the numerical example given above, the computed value of <a href="ncg_goldberg.html#1405">(7)</a> is 2.35, compared with a true value of 2.34216 for a relative error of 0.7<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, which is much less than 11<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. The main reason for computing error bounds is not to get precise bounds but rather to verify that the formula does not contain numerical problems. </font>
</p>


<p>
  <a name="715"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A final example of an expression that can be rewritten to use benign cancellation is (1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font>)<sup><em>n</em></sup>, where <img src="images/ncg_goldberg15.gif" height="17" width="35">
. This expression arises in financial calculations. Consider depositing $100 every day into a bank account that earns an annual interest rate of 6%, compounded daily. If <font face="Arial,Helvetica"><em>n</em></font> = 365 and <font face="Arial,Helvetica"><em>i</em></font> = .06, the amount of money accumulated at the end of one year is </font>
</p>


<a name="5952"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">100<img src="images/ncg_goldberg78.gif" height="31" width="68">
 <br></font>


<p>
  <a name="10682"> </a><font face="Verdana, Arial, Helvetica, sans-serif">dollars. If this is computed using <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 and <em>p</em> = 24, the result is $37615.45 compared to the exact answer of $37614.05, a discrepancy of $1.40. The reason for the problem is easy to see. The expression 1 +<font face="Arial,Helvetica"><em> i</em></font>/<font face="Arial,Helvetica"><em>n</em></font> involves adding 1 to .0001643836, so the low order bits of <font face="Arial,Helvetica"><em>i</em></font>/<font face="Arial,Helvetica"><em>n</em></font> are lost. This rounding error is amplified when 1 + <font face="Arial,Helvetica"><em>i</em></font>/<font face="Arial,Helvetica"><em>n</em></font> is raised to the <font face="Arial,Helvetica"><em>n</em></font>th power. </font>
</p>


<p>
  <a name="719"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The troublesome expression (1 + <font face="Arial,Helvetica"><em>i</em></font>/<font face="Arial,Helvetica"><em>n</em></font>)<sup><em>n</em></sup> can be rewritten as <font face="Arial,Helvetica"><em>e</em></font><sup>nln(1 + </sup><sup><em>i</em></sup><sup>/</sup><sup><em>n</em></sup><sup>)</sup>, where now the problem is to compute ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) for small <em>x</em>. One approach is to use the approximation ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>, in which case the payment becomes $37617.26, which is off by $3.21 and even less accurate than the obvious formula. But there is a way to compute ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) very accurately, as Theorem 4 shows [Hewlett-Packard 1982]. This formula yields $37614.07, accurate to within two cents! </font>
</p>


<p>
  <a name="1413"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Theorem 4 assumes that <code>LN(x)</code> approximates ln(<font face="Arial,Helvetica"><em>x</em></font>) to within 1/2 ulp. The problem it solves is that when <em>x</em> is small, <code>LN</code>(1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) is not close to ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) because 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> has lost the information in the low order bits of <em>x</em>. That is, the computed value of ln(1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font>) is not close to its actual value when <img src="images/ncg_goldberg47.gif" height="16" width="28">
. </font>
</p>


<h4>
  <a name="1202"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 4 </font>
</h4>

<dl>
  <dt> <a name="720"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em> If ln(1 + x) is computed using the formula </em></font>
  <dl>
     <dt> <a name="11644"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl>

<a name="5998"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg101.gif" height="67" width="233">
<br></font>

<dl>  <dl>
     <dt> <a name="11645"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl><dl>
  <dt> <a name="1416"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>the relative error is at most 5</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><font  size="3" face="Verdana, Arial, Helvetica, sans-serif"> when 0 </font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><font  size="3" face="Verdana, Arial, Helvetica, sans-serif"> x &lt; 3/4, provided subtraction is performed with a guard digit, e &lt; 0.1, and ln is computed to within 1/2 ulp. </font></font>
</dl>

<p>
  <a name="1414"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This formula will work for any value of <em>x</em> but is only interesting for <img src="images/ncg_goldberg61.gif" height="17" width="35">
, which is where catastrophic cancellation occurs in the naive formula ln(1 + <font face="Arial,Helvetica"><em>x</em></font>). Although the formula may seem mysterious, there is a simple explanation for why it works. Write ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) as</font>
</p>


<a name="5972"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg70.gif" height="36" width="118">
. <br></font>


<p>
  <a name="10680"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The left hand factor can be computed exactly, but the right hand factor <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;=&nbsp;ln(1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>x</em></font> will suffer a large rounding error when adding 1 to <em>x</em>. However, <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font> is almost constant, since ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>. So changing <em>x</em> slightly will not introduce much error. In other words, if <img src="images/ncg_goldberg75.gif" height="16" width="29">
, computing <img src="images/ncg_goldberg80.gif" height="16" width="34">
 will be a good approximation to <em>x</em><font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;=&nbsp;ln(1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font>). Is there a value for <img src="images/ncg_goldberg89.gif" height="16" width="10">
 for which <img src="images/ncg_goldberg86.gif" height="16" width="10">
 and <img src="images/ncg_goldberg99.gif" height="16" width="29">
 can be computed accurately? There is; namely <img src="images/ncg_goldberg95.gif" height="16" width="10">
 = (1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><font face="Arial,Helvetica"><em> x</em></font>) <img src="images/ncg_goldberg284.gif" height="15" width="13">
 1, because then 1 + <img src="images/ncg_goldberg67.gif" height="16" width="10">
 is exactly equal to 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>. </font>
</p>


<p>
  <a name="1415"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The results of this section can be summarized by saying that a guard digit guarantees accuracy when nearby precisely known quantities are subtracted (benign cancellation). Sometimes a formula that gives inaccurate results can be rewritten to have much higher numerical accuracy by using benign cancellation; however, the procedure only works if subtraction is performed using a guard digit. The price of a guard digit is not high, because it merely requires making the adder one bit wider. For a 54 bit double precision adder, the additional cost is less than 2%. For this price, you gain the ability to run many algorithms such as formula <a href="ncg_goldberg.html#1403">(6)</a> for computing the area of a triangle and the expression ln(1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font>). Although most modern computers have a guard digit, there are a few (such as Cray systems) that do not. </font>
</p>


<h3>
  <a name="704"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Exactly Rounded Operations </font>
</h3>


<p>
  <a name="705"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When floating-point operations are done with a guard digit, they are not as accurate as if they were computed exactly then rounded to the nearest floating-point number. Operations performed in this manner will be called <em>exactly rounded</em>.<a href="#729"><sup>8</sup></a> The example immediately preceding Theorem 2 shows that a single guard digit will not always give exactly rounded results. The previous section gave several examples of algorithms that require a guard digit in order to work properly. This section gives examples of algorithms that require exact rounding. </font>
</p>


<p>
  <a name="1417"> </a><font face="Verdana, Arial, Helvetica, sans-serif">So far, the definition of rounding has not been given. Rounding is straightforward, with the exception of how to round halfway cases; for example, should 12.5 round to 12 or 13? One school of thought divides the 10 digits in half, letting {0,&nbsp;1,&nbsp;2,&nbsp;3,&nbsp;4} round down, and {5, 6, 7, 8, 9} round up; thus 12.5 would round to 13. This is how rounding works on Digital Equipment Corporation's VAX computers. Another school of thought says that since numbers ending in 5 are halfway between two possible roundings, they should round down half the time and round up the other half. One way of obtaining this 50% behavior to require that the rounded result have its least significant digit be even. Thus 12.5 rounds to 12 rather than 13 because 2 is even. Which of these methods is best, round up or round to even? Reiser and Knuth [1975] offer the following reason for preferring round to even. </font>
</p>


<h4>
  <a name="1419"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 5 </font>
</h4>

<dl>
  <dt> <a name="1418"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Let x and y be floating-point numbers, and define x</em><sub>0</sub><em> = x, x</em><sub>1</sub><em> = (x</em><sub>0</sub><em> </em><img src="images/ncg_goldberg303.gif" height="15" width="13">
<em> y) </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><em> y, </em><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><em>, x</em><sub>n</sub><em>&nbsp;= (x</em><sub>n-1</sub><em>&nbsp;</em><img src="images/ncg_goldberg293.gif" height="15" width="13">
<em>&nbsp;y) </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><em> y. If </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font><em> and </em><img src="images/ncg_goldberg6.gif" height="15" width="13">
<em> are exactly rounded using round to even, then either x</em><sub>n</sub><em> = x for all n or x</em><sub>n</sub><em> = x</em><sub>1</sub><em> for all n</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1. z</font>
</dl>

<p>
  <a name="722"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To clarify this result, consider <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 3 and let <em>x</em> = 1.00, <em>y</em> = -.555. When rounding up, the sequence becomes</font>
</p>


<a name="11653"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>x</em><sub>0</sub> <img src="images/ncg_goldberg84.gif" height="15" width="13">
 y = 1.56, <em>x</em><sub>1</sub> = 1.56 <img src="images/ncg_goldberg93.gif" height="15" width="13">
 .555 = 1.01, <em>x</em><sub>1</sub>&nbsp;<img src="images/ncg_goldberg103.gif" height="15" width="13">
&nbsp;y = 1.01 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> .555 = 1.57,<br></font>


<p>
  <a name="11655"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and each successive value of <em>x</em><sub>n</sub> increases by .01, until <em>x</em><sub>n</sub> = 9.45 (n <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 845)<a href="#730"><sup>9</sup></a>. Under round to even, <em>x</em><sub>n</sub> is always 1.00. This example suggests that when using the round up rule, computations can gradually drift upward, whereas when using round to even the theorem says this cannot happen. Throughout the rest of this paper, round to even will be used. </font>
</p>


<p>
  <a name="742"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One application of exact rounding occurs in multiple precision arithmetic. There are two basic approaches to higher precision. One approach represents floating-point numbers using a very large significand, which is stored in an array of words, and codes the routines for manipulating these numbers in assembly language. The second approach represents higher precision floating-point numbers as an array of ordinary floating-point numbers, where adding the elements of the array in infinite precision recovers the high precision floating-point number. It is this second approach that will be discussed here. The advantage of using an array of floating-point numbers is that it can be coded portably in a high level language, but it requires exactly rounded arithmetic.</font>
</p>


<p>
  <a name="744"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The key to multiplication in this system is representing a product <em>x</em>y as a sum, where each summand has the same precision as <em>x</em> and <em>y</em>. This can be done by splitting <em>x</em> and <em>y</em>. Writing <em>x</em> = <font face="Arial,Helvetica"><em>x</em></font><sub>h</sub> + x<sub><em>l</em></sub> and <em>y</em> = <font face="Arial,Helvetica"><em>y</em></font><sub>h</sub> + y<sub><em>l</em></sub>, the exact product is</font>
</p>


<a name="11662"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>x</em><font face="Arial,Helvetica"><em>y</em></font> = <font face="Arial,Helvetica"><em>x</em></font><sub>h</sub><font face="Arial,Helvetica"><em>&nbsp;y</em></font><sub>h</sub> + <font face="Arial,Helvetica"><em>x</em></font><sub>h</sub> <font face="Arial,Helvetica"><em>y</em></font><sub>l</sub> + <font face="Arial,Helvetica"><em>x</em></font><sub>l</sub> <font face="Arial,Helvetica"><em>y</em></font><sub>h</sub> + <font face="Arial,Helvetica"><em>x</em></font><sub>l</sub> <font face="Arial,Helvetica"><em>y</em></font><sub>l</sub>. <br></font>


<p>
  <a name="11664"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <em>x</em> and <em>y</em> have <em>p</em> bit significands, the summands will also have <em>p</em> bit significands provided that <em>x</em><sub>l</sub>, <em>x</em><sub>h</sub>, <em>y</em><sub>h</sub>, <em>y</em><sub>l</sub> can be represented using <font  face="Verdana, Arial, Helvetica, sans-serif">[</font><font face="Arial,Helvetica"><em>p</em></font>/2<font  face="Verdana, Arial, Helvetica, sans-serif">]</font> bits. When <font face="Arial,Helvetica"><em>p</em></font> is even, it is easy to find a splitting. The number <em>x</em><sub>0</sub>.<font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <em>x</em><sub>p - 1</sub> can be written as the sum of <em>x</em><sub>0</sub>.<font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font><sub>p/2 - 1</sub> and 0.0 <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> 0<font face="Arial,Helvetica"><em>x</em></font><sub>p/2</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>x</em></font><sub>p&nbsp;-&nbsp;1</sub>. When <em>p</em> is odd, this simple splitting method will not work. An extra bit can, however, be gained by using negative numbers. For example, if <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <em>p</em> = 5, and <em>x</em> = .10111, <em>x</em> can be split as <em>x</em><sub>h</sub> = .11 and <em>x</em><sub>l</sub>&nbsp;=&nbsp;-.00001. There is more than one way to split a number. A splitting method that is easy to compute is due to Dekker [1971], but it requires more than a single guard digit. </font>
</p>


<h4>
  <a name="745"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 6</font>
</h4>

<dl>
  <dt> <a name="746"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Let p be the floating-point precision, with the restriction that p is even when </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>&nbsp;&gt;&nbsp;2<em>, and assume that floating-point operations are exactly rounded. Then if </em><font face="Arial,Helvetica"><em>k</em></font><em>&nbsp;=&nbsp;</em>[p/2]<em> is half the precision (rounded up) and m = </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><em> + </em>1<em>, x can be split as x = x</em><sub>h</sub><em> + x</em><sub>l</sub><em>, where </em></font>
</dl>

<a name="13096"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>x</em><sub>h</sub><em> = (m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em>&nbsp;x)&nbsp;</em><img src="images/ncg_goldberg112.gif" height="15" width="13">
<em>&nbsp;(m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> x </em><img src="images/ncg_goldberg138.gif" height="15" width="13">
<em> x), x</em><sub>l</sub><em> = x </em><img src="images/ncg_goldberg144.gif" height="15" width="13">
<em> x</em><sub>h</sub><em>, </em><br></font>


<p>
  <a name="13097"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>and each x</em><sub>i</sub><em> is representable using</em> [p/2]<em> bits of precision.</em> </font>
</p>


<p>
  <a name="8119"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To see how this theorem works in an example, let <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 4, <font face="Arial,Helvetica"><em>b</em></font> = 3.476, <font face="Arial,Helvetica"><em>a</em></font> = 3.463, and <font face="Arial,Helvetica"><em>c</em></font> = 3.479. Then <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - <font face="Arial,Helvetica"><em>ac</em></font> rounded to the nearest floating-point number is .03480, while <font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><font face="Arial,Helvetica"><em> b</em></font> = 12.08, <font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>c</em></font> = 12.05, and so the computed value of <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - <font face="Arial,Helvetica"><em>ac</em></font> is .03. This is an error of 480 ulps. Using Theorem 6 to write <font face="Arial,Helvetica"><em>b</em></font> = 3.5 - .024, <font face="Arial,Helvetica"><em>a</em></font>&nbsp;=&nbsp;3.5&nbsp;-&nbsp;.037, and <font face="Arial,Helvetica"><em>c</em></font>&nbsp;=&nbsp;3.5&nbsp;- .021, <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> becomes 3.5<sup>2</sup> - 2 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 3.5 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> .024 + .024<sup>2</sup>. Each summand is exact, so <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup>&nbsp;=&nbsp;12.25 - .168 + .000576, where the sum is left unevaluated at this point. Similarly, <font face="Arial,Helvetica"><em>ac</em></font> = 3.5<sup>2</sup> - (3.5 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> .037 + 3.5 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> .021) + .037 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> .021 = 12.25 - .2030 +.000777. Finally, subtracting these two series term by term gives an estimate for <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - <font face="Arial,Helvetica"><em>ac</em></font> of 0&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font>&nbsp;.0350&nbsp;<img src="images/ncg_goldberg154.gif" height="15" width="13">
&nbsp;.000201 = .03480, which is identical to the exactly rounded result. To show that Theorem 6 really requires exact rounding, consider <em>p</em> = 3, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, and <em>x</em> = 7. Then <font face="Arial,Helvetica"><em>m</em></font>&nbsp;=&nbsp;5, <font face="Arial,Helvetica"><em>mx</em></font> = 35, and <font face="Arial,Helvetica"><em>m</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;= 32. If subtraction is performed with a single guard digit, then (<font face="Arial,Helvetica"><em>m</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;<img src="images/ncg_goldberg165.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>x</em></font> = 28. Therefore, <em>x</em><sub>h</sub> = 4 and <em>x</em><sub>l</sub> = 3, hence <em>x</em><sub>l</sub> is not representable with <font  face="Verdana, Arial, Helvetica, sans-serif">[</font><font face="Arial,Helvetica"><em>p</em></font><em>/2</em>] = 1 bit. </font>
</p>


<p>
  <a name="8130"> </a><font face="Verdana, Arial, Helvetica, sans-serif">As a final example of exact rounding, consider dividing <font face="Arial,Helvetica"><em>m</em></font> by 10. The result is a floating-point number that will in general not be equal to <font face="Arial,Helvetica"><em>m</em></font>/10. When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, multiplying <font face="Arial,Helvetica"><em>m</em></font>/10 by 10 will restore <font face="Arial,Helvetica"><em>m</em></font>, provided exact rounding is being used. Actually, a more general fact (due to Kahan) is true. The proof is ingenious, but readers not interested in such details can skip ahead to section <a href="ncg_goldberg.html#799">The IEEE Standard</a>.</font>
</p>


<h4>
  <a name="780"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 7</font>
</h4>

<dl>
  <dt> <a name="781"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>When </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><em> = </em>2<em>, if </em><font face="Arial,Helvetica"><em>m</em></font><em> and </em><font face="Arial,Helvetica"><em>n</em></font><em> are integers with |m| &lt; </em>2<sup><em>p - 1</em></sup><em> and </em><font face="Arial,Helvetica"><em>n</em></font><em> has the special form n = </em>2<sup><em>i</em></sup><em> + </em>2<sup><em>j</em></sup><em>, then (m </em><img src="images/ncg_goldberg69.gif" height="12" width="11">
<em> n) </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> n = m, provided floating-point operations are exactly rounded.</em> </font>
</dl>

<h4>
  <a name="783"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="784"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Scaling by a power of two is harmless, since it changes only the exponent, not the significand. If <font face="Arial,Helvetica"><em>q</em></font> = <font face="Arial,Helvetica"><em>m</em></font>/<font face="Arial,Helvetica"><em>n</em></font>, then scale <font face="Arial,Helvetica"><em>n</em></font> so that 2<sup><em>p</em></sup><sup> - 1</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>n</em></font> &lt; 2<sup><em>p</em></sup> and scale <font face="Arial,Helvetica"><em>m</em></font> so that 1/2 &lt; <font face="Arial,Helvetica"><em>q</em></font> &lt; 1. Thus, 2<sup><em>p</em></sup><sup> - 2</sup> &lt; <font face="Arial,Helvetica"><em>m</em></font> &lt; 2<sup><em>p</em></sup>. Since <font face="Arial,Helvetica"><em>m</em></font> has <em>p</em> significant bits, it has at most one bit to the right of the binary point. Changing the sign of <font face="Arial,Helvetica"><em>m</em></font> is harmless, so assume that <font face="Arial,Helvetica"><em>q</em></font> &gt; 0.</font>
  <dt> <a name="786"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <img src="images/ncg_goldberg113.gif" height="16" width="10">
 = <em>m </em><img src="images/ncg_goldberg82.gif" height="12" width="11">
<em> n</em>, to prove the theorem requires showing that </font>
</dl>

<a name="787"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(9) <img src="images/ncg_goldberg118.gif" height="31" width="64">
 <br></font>

<dl>
  <dt> <a name="788"> </a><font face="Verdana, Arial, Helvetica, sans-serif">That is because <font face="Arial,Helvetica"><em>m</em></font> has at most 1 bit right of the binary point, so <font face="Arial,Helvetica"><em>n</em></font><img src="images/ncg_goldberg140.gif" height="16" width="10">
 will round to <font face="Arial,Helvetica"><em>m</em></font>. To deal with the halfway case when |<font face="Arial,Helvetica"><em>n</em></font><img src="images/ncg_goldberg145.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>m</em></font>| = 1/4, note that since the initial unscaled <font face="Arial,Helvetica"><em>m</em></font> had |<font face="Arial,Helvetica"><em>m</em></font>| &lt; 2<sup><em>p</em></sup><sup> - 1</sup>, its low-order bit was 0, so the low-order bit of the scaled <font face="Arial,Helvetica"><em>m</em></font> is also 0. Thus, halfway cases will round to <font face="Arial,Helvetica"><em>m</em></font>. </font>
  <dt> <a name="1199"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Suppose that <font face="Arial,Helvetica"><em>q</em></font> = .<font face="Arial,Helvetica"><em>q</em></font><sub>1</sub><font face="Arial,Helvetica"><em>q</em></font><sub>2</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font>, and let <img src="images/ncg_goldberg170.gif" height="16" width="10">
 = .<font face="Arial,Helvetica"><em>q</em></font><sub>1</sub><font face="Arial,Helvetica"><em>q</em></font><sub>2</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>q</em></font><sub>p</sub>1. To estimate |<font face="Arial,Helvetica"><em>n</em></font><img src="images/ncg_goldberg175.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>m</em></font>|, first compute</font>
</dl>

<a name="11670"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">|<img src="images/ncg_goldberg180.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>q</em></font>| = |<font face="Arial,Helvetica"><em>N</em></font>/2<sup><em>p</em></sup><sup> + 1</sup> - <font face="Arial,Helvetica"><em>m</em></font>/<font face="Arial,Helvetica"><em>n</em></font>|, <br></font>

<dl>
  <dt> <a name="11672"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where <font face="Arial,Helvetica"><em>N</em></font> is an odd integer. Since <font face="Arial,Helvetica"><em>n</em></font> = 2<sup><em>i</em></sup>&nbsp;+&nbsp;2<sup><em>j</em></sup> and 2<sup><em>p</em></sup><sup> - 1</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>n</em></font> &lt; 2<sup><em>p</em></sup>, it must be that <font face="Arial,Helvetica"><em>n</em></font> = 2<sup><em>p</em></sup><sup>&nbsp;-&nbsp;1</sup>&nbsp;+ 2<sup><em>k</em></sup> for some k <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>p - </em></font>2, and thus</font>
  <dl>
     <dt> <a name="11703"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl>

<a name="11680"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg21.gif" height="35" width="298">
.<br></font>

<dl>  <dl>
     <dt> <a name="11681"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl><dl>
  <dt> <a name="11685"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The numerator is an integer, and since <font face="Arial,Helvetica"><em>N</em></font> is odd, it is in fact an odd integer. Thus,</font>
</dl>

<a name="11704"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">|<img src="images/ncg_goldberg185.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>q</em></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1/(<font face="Arial,Helvetica"><em>n</em></font>2<sup><em>p</em></sup><sup> + 1 - </sup><sup><em>k</em></sup>). <br></font>

<dl>
  <dt> <a name="11706"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Assume <font face="Arial,Helvetica"><em>q</em></font> &lt; <img src="images/ncg_goldberg200.gif" height="16" width="10">
 (the case <font face="Arial,Helvetica"><em>q</em></font> &gt; <img src="images/ncg_goldberg204.gif" height="16" width="10">
 is similar).<a href="#11697"><sup>10</sup></a> Then <font face="Arial,Helvetica"><em>n</em></font><img src="images/ncg_goldberg231.gif" height="16" width="10">
 &lt; <font face="Arial,Helvetica"><em>m</em></font>, and </font>
</dl>

<a name="793"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">|<em>m-n<img src="images/ncg_goldberg247.gif" height="16" width="10">
</em>|= <em>m-n<img src="images/ncg_goldberg252.gif" height="16" width="10">
</em> =<em> n</em>(<em>q-<img src="images/ncg_goldberg258.gif" height="16" width="10">
</em>) = <em>n</em>(<em>q</em>-(<img src="images/ncg_goldberg269.gif" height="16" width="10">
-2<sup><em>-p-1</em></sup>))<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/lt_equal.gif"> </font><img src="images/ncg_goldberg273.gif" height="37" width="118">
<br></font>


<a name="9915"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">	 =(2<sup><em>p</em></sup><sup>-1</sup>+2<sup><em>k</em></sup>)2<sup><em>-p-1</em></sup>-2<sup><em>-p-1+k</em></sup> = <img src="images/ncg_goldberg240.gif" height="31" width="10">
<br></font>

<dl>
  <dt> <a name="9922"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This establishes <a href="ncg_goldberg.html#787">(9)</a> and proves the theorem.<a href="#9921"><sup>11</sup></a> <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</dl>

<p>
  <a name="9923"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The theorem holds true for any base <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>, as long as 2<sup><em>i</em></sup> + 2<sup><em>j</em></sup> is replaced by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>i</em></sup> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>j</em></sup>. As <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> gets larger, however, denominators of the form <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>i</em></sup> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>j</em></sup> are farther and farther apart. </font>
</p>


<p>
  <a name="798"> </a><font face="Verdana, Arial, Helvetica, sans-serif">We are now in a position to answer the question, Does it matter if the basic arithmetic operations introduce a little more rounding error than necessary? The answer is that it does matter, because accurate basic operations enable us to prove that formulas are "correct" in the sense they have a small relative error. The section <a href="ncg_goldberg.html#700">Cancellation</a> discussed several algorithms that require guard digits to produce correct results in this sense. If the input to those formulas are numbers representing imprecise measurements, however, the bounds of Theorems 3 and 4 become less interesting. The reason is that the benign cancellation <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font> can become catastrophic if <em>x</em> and <em>y</em> are only approximations to some measured quantity. But accurate operations are useful even in the face of inexact data, because they enable us to establish exact relationships like those discussed in Theorems 6 and 7. These are useful even if every floating-point variable is only an approximation to some actual value. </font>
</p>


<h2>
  <a name="799"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">The IEEE Standard </font>
</h2>


<p>
  <a name="800"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There are two different IEEE standards for floating-point computation. IEEE 754 is a binary standard that requires <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <em>p</em> = 24 for single precision and <em>p</em> = 53 for double precision [IEEE 1987]. It also specifies the precise layout of bits in a single and double precision. IEEE 854 allows either <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 or <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10 and unlike 754, does not specify how floating-point numbers are encoded into bits [Cody et al. 1984]. It does not require a particular value for <em>p</em>, but instead it specifies constraints on the allowable values of <em>p</em> for single and double precision. The term <em>IEEE Standard</em> will be used when discussing properties common to both standards. </font>
</p>


<p>
  <a name="801"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This section provides a tour of the IEEE standard. Each subsection discusses one aspect of the standard and why it was included. It is not the purpose of this paper to argue that the IEEE standard is the best possible floating-point standard but rather to accept the standard as given and provide an introduction to its use. For full details consult the standards themselves [IEEE 1987; Cody et al. 1984]. </font>
</p>


<h3>
  <a name="802"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Formats and Operations </font>
</h3>


<h4>
  <a name="803"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Base </font>
</h4>


<p>
  <a name="804"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It is clear why IEEE 854 allows <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10. Base ten is how humans exchange and think about numbers. Using <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10 is especially appropriate for calculators, where the result of each operation is displayed by the calculator in decimal. </font>
</p>


<p>
  <a name="805"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There are several reasons why IEEE 854 requires that if the base is not 10, it must be 2. The section <a href="ncg_goldberg.html#689">Relative Error and Ulps</a> mentioned one reason: the results of error analyses are much tighter when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> is 2 because a rounding error of .5 ulp wobbles by a factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> when computed as a relative error, and error analyses are almost always simpler when based on relative error. A related reason has to do with the effective precision for large bases. Consider <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16, <em>p</em>&nbsp;=&nbsp;1 compared to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <em>p</em> = 4. Both systems have 4 bits of significand. Consider the computation of 15/8. When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, 15 is represented as 1.111 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup>3</sup>, and 15/8 as 1.111 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup>0</sup>. So 15/8 is exact. However, when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16, 15 is represented as <font face="Arial,Helvetica"><em>F</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 16<sup>0</sup>, where <font face="Arial,Helvetica"><em>F</em></font> is the hexadecimal digit for 15. But 15/8 is represented as 1 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 16<sup>0</sup>, which has only one bit correct. In general, base 16 can lose up to 3 bits, so that a precision of <em>p</em> hexadecimal digits can have an effective precision as low as 4<font face="Arial,Helvetica"><em>p</em></font> - 3 rather than 4<font face="Arial,Helvetica"><em>p</em></font> binary bits. Since large values of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> have these problems, why did IBM choose <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16 for its system/370? Only IBM knows for sure, but there are two possible reasons. The first is increased exponent range. Single precision on the system/370 has <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16, <em>p</em> = 6. Hence the significand requires 24 bits. Since this must fit into 32 bits, this leaves 7 bits for the exponent and one for the sign bit. Thus the magnitude of representable numbers ranges from about <img src="images/ncg_goldberg42.gif" height="19" width="31">
 to about <img src="images/ncg_goldberg52.gif" height="19" width="26">
 = <img src="images/ncg_goldberg57.gif" height="19" width="19">
. To get a similar exponent range when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 would require 9 bits of exponent, leaving only 22 bits for the significand. However, it was just pointed out that when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16, the effective precision can be as low as 4<font face="Arial,Helvetica"><em>p</em></font> -&nbsp;3&nbsp;=&nbsp;21 bits. Even worse, when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 it is possible to gain an extra bit of precision (as explained later in this section), so the <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 machine has 23 bits of precision to compare with a range of 21&nbsp;-&nbsp;24 bits for the <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16 machine. </font>
</p>


<p>
  <a name="806"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another possible explanation for choosing <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16 has to do with shifting. When adding two floating-point numbers, if their exponents are different, one of the significands will have to be shifted to make the radix points line up, slowing down the operation. In the <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 16, <em>p</em> = 1 system, all the numbers between 1 and 15 have the same exponent, and so no shifting is required when adding any of the (<img src="images/ncg_goldberg177.gif" height="24" width="16">
) = 105 possible pairs of distinct numbers from this set. However, in the <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, <em>p</em> = 4 system, these numbers have exponents ranging from 0 to 3, and shifting is required for 70 of the 105 pairs. </font>
</p>


<p>
  <a name="807"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In most modern hardware, the performance gained by avoiding a shift for a subset of operands is negligible, and so the small wobble of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 makes it the preferable base. Another advantage of using <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 is that there is a way to gain an extra bit of significance.<a href="#808"><sup>12</sup></a> Since floating-point numbers are always normalized, the most significant bit of the significand is always 1, and there is no reason to waste a bit of storage representing it. Formats that use this trick are said to have a <em>hidden</em> bit. It was already pointed out in <a href="ncg_goldberg.html#682">Floating-point Formats</a> that this requires a special convention for 0. The method given there was that an exponent of <em>e</em><sub>min</sub> - 1 and a significand of all zeros represents not <img src="images/ncg_goldberg114.gif" height="20" width="70">
, but rather 0. </font>
</p>


<p>
  <a name="809"> </a><font face="Verdana, Arial, Helvetica, sans-serif">IEEE 754 single precision is encoded in 32 bits using 1 bit for the sign, 8 bits for the exponent, and 23 bits for the significand. However, it uses a hidden bit, so the significand is 24 bits (<em>p</em> = 24), even though it is encoded using only 23 bits. </font>
</p>


<h4>
  <a name="810"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Precision </font>
</h4>


<p>
  <a name="811"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard defines four different precisions: single, double, single-extended, and double-extended. In IEEE 754, single and double precision correspond roughly to what most floating-point hardware provides. Single precision occupies a single 32 bit word, double precision two consecutive 32 bit words. Extended precision is a format that offers at least a little extra precision and exponent range (<a href="ncg_goldberg.html#812">TABLE&nbsp;D-1</a>).<p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><a name="812"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><b>TABLE D-1 	</b>&nbsp;&nbsp;IEEE 754 Format Parameters</font></font></b></caption>
  <tr bgcolor="#CCCCCC"><div align="center">
    <th colspan=1 rowspan=2><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="817"> </a>Parameter</font></th>
    <th colspan=4 rowspan=1><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="818"> </a>Format</font></th>
  </div></tr>
  <tr bgcolor="#CCCCCC"><div align="center">
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="823"> </a>Single</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="824"> </a>Single-Extended</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="825"> </a>Double</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="826"> </a>Double-Extended</font></th>
  </div></tr>
  <tr>
    <td>
<a name="827"> </a><font face="Arial,Helvetica"><em>p
</em></font></td>
    <td>
<a name="828"> </a>24
</td>
    <td>
<a name="829"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  32
</td>
    <td>
<a name="830"> </a>53
</td>
    <td>
<a name="831"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  64
</td>
  </tr>
  <tr>
    <td>
<a name="832"> </a><font face="Arial,Helvetica"><em>e</em></font><sub>max
</sub></td>
    <td>
<a name="833"> </a>+127
</td>
    <td>
<a name="834"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  1023
</td>
    <td>
<a name="835"> </a>+1023
</td>
    <td>
<a name="836"> </a> <font  face="Verdana, Arial, Helvetica, sans-serif">&gt;</font> 16383
</td>
  </tr>
  <tr>
    <td>
<a name="837"> </a><font face="Arial,Helvetica"><em>e</em></font><sub>min</sub> 
</td>
    <td>
<a name="838"> </a>-126
</td>
    <td>
<a name="839"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> -1022
</td>
    <td>
<a name="840"> </a>-1022
</td>
    <td>
<a name="841"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"> </font> -16382
</td>
  </tr>
  <tr>
    <td>
<a name="842"> </a>Exponent width in bits
</td>
    <td>
<a name="843"> </a>8
</td>
    <td>
<a name="844"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 11
</td>
    <td>
<a name="845"> </a>11
</td>
    <td>
<a name="846"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  15
</td>
  </tr>
  <tr>
    <td>
<a name="847"> </a>Format width in bits
</td>
    <td>
<a name="848"> </a>32
</td>
    <td>
<a name="849"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  43
</td>
    <td>
<a name="850"> </a>64
</td>
    <td>
<a name="851"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>  79
</td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="853"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard only specifies a lower bound on how many extra bits extended precision provides. The minimum allowable double-extended format is sometimes referred to as <em>80-bit format</em>, even though the table shows it using 79 bits. The reason is that hardware implementations of extended precision normally do not use a hidden bit, and so would use 80 rather than 79 bits.<a href="#854"><sup>13</sup></a> </font>
</p>


<p>
  <a name="855"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The standard puts the most emphasis on extended precision, making no recommendation concerning double precision, but strongly recommending that <em>Implementations should support the extended format corresponding to the widest basic format supported, </em><font  face="Verdana, Arial, Helvetica, sans-serif">...</font></font>
</p>


<p>
  <a name="857"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One motivation for extended precision comes from calculators, which will often display 10 digits, but use 13 digits internally. By displaying only 10 of the 13 digits, the calculator appears to the user as a "black box" that computes exponentials, cosines, etc. to 10 digits of accuracy. For the calculator to compute functions like exp, log and cos to within 10 digits with reasonable efficiency, it needs a few extra digits to work with. It is not hard to find a simple rational expression that approximates log with an error of 500 units in the last place. Thus computing with 13 digits gives an answer correct to 10 digits. By keeping these extra 3 digits hidden, the calculator presents a simple model to the operator. </font>
</p>


<p>
  <a name="858"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Extended precision in the IEEE standard serves a similar function. It enables libraries to efficiently compute quantities to within about .5 ulp in single (or double) precision, giving the user of those libraries a simple model, namely that each primitive operation, be it a simple multiply or an invocation of log, returns a value accurate to within about .5 ulp. However, when using extended precision, it is important to make sure that its use is transparent to the user. For example, on a calculator, if the internal representation of a displayed value is not rounded to the same precision as the display, then the result of further operations will depend on the hidden digits and appear unpredictable to the user. </font>
</p>


<p>
  <a name="859"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To illustrate extended precision further, consider the problem of converting between IEEE 754 single precision and decimal. Ideally, single precision numbers will be printed with enough digits so that when the decimal number is read back in, the single precision number can be recovered. It turns out that 9 decimal digits are enough to recover a single precision binary number (see the section <a href="ncg_goldberg.html#1251">Binary to Decimal Conversion</a>). When converting a decimal number back to its unique binary representation, a rounding error as small as 1 ulp is fatal, because it will give the wrong answer. Here is a situation where extended precision is vital for an efficient algorithm. When single-extended is available, a very straightforward method exists for converting a decimal number to a single precision binary one. First read in the 9 decimal digits as an integer <font face="Arial,Helvetica"><em>N</em></font>, ignoring the decimal point. From <a href="ncg_goldberg.html#812">TABLE&nbsp;D-1</a>, <em>p</em>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>&nbsp;32, and since 10<sup>9</sup>&nbsp;&lt;&nbsp;2<sup>32</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> 4.3 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>9</sup>, <font face="Arial,Helvetica"><em>N</em></font> can be represented exactly in single-extended. Next find the appropriate power 10<sup><em>P</em></sup> necessary to scale <font face="Arial,Helvetica"><em>N</em></font>. This will be a combination of the exponent of the decimal number, together with the position of the (up until now) ignored decimal point. Compute 10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>. If |<font face="Arial,Helvetica"><em>P</em></font>|&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;13, then this is also represented exactly, because 10<sup>13</sup> = 2<sup>13</sup>5<sup>13</sup>, and 5<sup>13</sup>&nbsp;&lt;&nbsp;2<sup>32</sup>. Finally multiply (or divide if <em>p</em> &lt; 0) <font face="Arial,Helvetica"><em>N</em></font> and 10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>. If this last operation is done exactly, then the closest binary number is recovered. The section <a href="ncg_goldberg.html#1251">Binary to Decimal Conversion</a> shows how to do the last multiply (or divide) exactly. Thus for |<font face="Arial,Helvetica"><em>P</em></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 13, the use of the single-extended format enables 9-digit decimal numbers to be converted to the closest binary number (i.e. exactly rounded). If |<font face="Arial,Helvetica"><em>P</em></font>| &gt; 13, then single-extended is not enough for the above algorithm to always compute the exactly rounded binary equivalent, but Coonen [1984] shows that it is enough to guarantee that the conversion of binary to decimal and back will recover the original binary number. </font>
</p>


<p>
  <a name="860"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If double precision is supported, then the algorithm above would be run in double precision rather than single-extended, but to convert double precision to a 17-digit decimal number and back would require the double-extended format. </font>
</p>


<h4>
  <a name="861"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Exponent </font>
</h4>


<p>
  <a name="862"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since the exponent can be positive or negative, some method must be chosen to represent its sign. Two common methods of representing signed numbers are sign/magnitude and two's complement. Sign/magnitude is the system used for the sign of the significand in the IEEE formats: one bit is used to hold the sign, the rest of the bits represent the magnitude of the number. The two's complement representation is often used in integer arithmetic. In this scheme, a number in the range [-2<sup>p-1</sup>, 2<sup>p-1</sup> - 1] is represented by the smallest nonnegative number that is congruent to it modulo 2<sup>p</sup>. </font>
</p>


<p>
  <a name="863"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE binary standard does not use either of these methods to represent the exponent, but instead uses a <font face="Arial,Helvetica"><em>biased</em></font> representation. In the case of single precision, where the exponent is stored in 8 bits, the bias is 127 (for double precision it is 1023). What this means is that if <img src="images/ncg_goldberg150.gif" height="18" width="9">
 is the value of the exponent bits interpreted as an unsigned integer, then the exponent of the floating-point number is <img src="images/ncg_goldberg156.gif" height="18" width="9">
 - 127. This is often called the <em>unbiased exponent</em> to distinguish from the biased exponent <img src="images/ncg_goldberg161.gif" height="18" width="9">
. </font>
</p>


<p>
  <a name="864"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Referring to <a href="ncg_goldberg.html#812">TABLE&nbsp;D-1</a>, single precision has <em>e</em><sub>max</sub> = 127 and <em>e</em><sub>min</sub>&nbsp;=&nbsp;-126. The reason for having |<em>e</em><sub>min</sub>| &lt; <em>e</em><sub>max</sub> is so that the reciprocal of the smallest number <img src="images/ncg_goldberg166.gif" height="20" width="51">
 will not overflow. Although it is true that the reciprocal of the largest number will underflow, underflow is usually less serious than overflow. The section <a href="ncg_goldberg.html#803">Base</a> explained that <em>e</em><sub>min</sub> - 1 is used for representing 0, and <a href="ncg_goldberg.html#875">Special Quantities</a> will introduce a use for <em>e</em><sub>max</sub> + 1. In IEEE single precision, this means that the biased exponents range between <em>e</em><sub>min</sub> - 1 = -127 and <em>e</em><sub>max</sub> + 1 = 128, whereas the unbiased exponents range between 0 and 255, which are exactly the nonnegative numbers that can be represented using 8 bits. </font>
</p>


<h4>
  <a name="865"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Operations </font>
</h4>


<p>
  <a name="866"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard requires that the result of addition, subtraction, multiplication and division be exactly rounded. That is, the result must be computed exactly and then rounded to the nearest floating-point number (using round to even). The section <a href="ncg_goldberg.html#693">Guard Digits</a> pointed out that computing the exact difference or sum of two floating-point numbers can be very expensive when their exponents are substantially different. That section introduced guard digits, which provide a practical way of computing differences while guaranteeing that the relative error is small. However, computing with a single guard digit will not always give the same answer as computing the exact result and then rounding. By introducing a second guard digit and a third <em>sticky</em> bit, differences can be computed at only a little more cost than with a single guard digit, but the result is the same as if the difference were computed exactly and then rounded [Goldberg 1990]. Thus the standard can be implemented efficiently. </font>
</p>


<p>
  <a name="867"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One reason for completely specifying the results of arithmetic operations is to improve the portability of software. When a program is moved between two machines and both support IEEE arithmetic, then if any intermediate result differs, it must be because of software bugs, not from differences in arithmetic. Another advantage of precise specification is that it makes it easier to reason about floating-point. Proofs about floating-point are hard enough, without having to deal with multiple cases arising from multiple kinds of arithmetic. Just as integer programs can be proven to be correct, so can floating-point programs, although what is proven in that case is that the rounding error of the result satisfies certain bounds. Theorem 4 is an example of such a proof. These proofs are made much easier when the operations being reasoned about are precisely specified. Once an algorithm is proven to be correct for IEEE arithmetic, it will work correctly on any machine supporting the IEEE standard. </font>
</p>


<p>
  <a name="868"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Brown [1981] has proposed axioms for floating-point that include most of the existing floating-point hardware. However, proofs in this system cannot verify the algorithms of sections <a href="ncg_goldberg.html#700">Cancellation</a> and <a href="ncg_goldberg.html#704">Exactly Rounded Operations</a>, which require features not present on all hardware. Furthermore, Brown's axioms are more complex than simply defining operations to be performed exactly and then rounded. Thus proving theorems from Brown's axioms is usually more difficult than proving them assuming operations are exactly rounded. </font>
</p>


<p>
  <a name="12892"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There is not complete agreement on what operations a floating-point standard should cover. In addition to the basic operations +, -, <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> and /, the IEEE standard also specifies that square root, remainder, and conversion between integer and floating-point be correctly rounded. It also requires that conversion between internal formats and decimal be correctly rounded (except for very large numbers). Kulisch and Miranker [1986] have proposed adding inner product to the list of operations that are precisely specified. They note that when inner products are computed in IEEE arithmetic, the final answer can be quite wrong. For example sums are a special case of inner products, and the sum ((2 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-30</sup> + 10<sup>30</sup>) - 10<sup>30</sup>) - 10<sup>-30</sup> is exactly equal to 10<sup>-30</sup>, but on a machine with IEEE arithmetic the computed result will be -10<sup>-30</sup>. It is possible to compute inner products to within 1 ulp with less hardware than it takes to implement a fast multiplier [Kirchner and Kulish 1987].<a href="#12895"><sup>14</sup></a> <a href="#12898"><sup>15</sup></a></font>
</p>


<p>
  <a name="872"> </a><font face="Verdana, Arial, Helvetica, sans-serif">All the operations mentioned in the standard are required to be exactly rounded except conversion between decimal and binary. The reason is that efficient algorithms for exactly rounding all the operations are known, except conversion. For conversion, the best known efficient algorithms produce results that are slightly worse than exactly rounded ones [Coonen 1984]. </font>
</p>


<p>
  <a name="873"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard does not require transcendental functions to be exactly rounded because of the <em>table maker's dilemma</em>. To illustrate, suppose you are making a table of the exponential function to 4 places. Then exp(1.626)&nbsp;=&nbsp;5.0835. Should this be rounded to 5.083 or 5.084? If exp(1.626) is computed more carefully, it becomes 5.08350. And then 5.083500. And then 5.0835000. Since exp is transcendental, this could go on arbitrarily long before distinguishing whether exp(1.626) is 5.083500<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>0<font face="Arial,Helvetica"><em>ddd</em></font> or 5.0834999<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>9<font face="Arial,Helvetica"><em>ddd</em></font>. Thus it is not practical to specify that the precision of transcendental functions be the same as if they were computed to infinite precision and then rounded. Another approach would be to specify transcendental functions algorithmically. But there does not appear to be a single algorithm that works well across all hardware architectures. Rational approximation, CORDIC,<a href="#874"><sup>16</sup></a> and large tables are three different techniques that are used for computing transcendentals on contemporary machines. Each is appropriate for a different class of hardware, and at present no single algorithm works acceptably over the wide range of current hardware.</font>
</p>


<h3>
  <a name="875"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Special Quantities </font>
</h3>


<p>
  <a name="876"> </a><font face="Verdana, Arial, Helvetica, sans-serif">On some floating-point hardware every bit pattern represents a valid floating-point number. The IBM System/370 is an example of this. On the other hand, the VAX<font size="-1"><sup>TM</sup></font> reserves some bit patterns to represent special numbers called <font face="Arial,Helvetica"><em>reserved operands</em></font>. This idea goes back to the CDC 6600, which had bit patterns for the special quantities <code>INDEFINITE</code> and <code>INFINITY</code>. </font>
</p>


<p>
  <a name="877"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard continues in this tradition and has NaNs (<em>Not a Number</em>) and infinities. Without any special quantities, there is no good way to handle exceptional situations like taking the square root of a negative number, other than aborting computation. Under IBM System/370 FORTRAN, the default action in response to computing the square root of a negative number like -4 results in the printing of an error message. Since every bit pattern represents a valid number, the return value of square root must be some floating-point number. In the case of System/370 FORTRAN, <img src="images/ncg_goldberg171.gif" height="19" width="51">
 is returned. In IEEE arithmetic, a NaN is returned in this situation. </font>
</p>


<p>
  <a name="754"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard specifies the following special values (see <a href="ncg_goldberg.html#878">TABLE&nbsp;D-2</a>): <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> 0, denormalized numbers, <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font> and NaNs (there is more than one NaN, as explained in the next section). These special values are all encoded with exponents of either <em>e</em><sub>max</sub>&nbsp;+&nbsp;1 or <em>e</em><sub>min</sub> - 1 (it was already pointed out that 0 has an exponent of <em>e</em><sub>min</sub> - 1). <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><a name="878"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><b>TABLE D-2 	</b>&nbsp;&nbsp;IEEE 754 Special Values</font></font></b></caption>
  <tr bgcolor="#CCCCCC"><div align="center">
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="881"> </a>Exponent</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="882"> </a>Fraction</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="883"> </a>Represents</font></th>
  </div></tr>
  <tr>
    <td>
<a name="884"> </a> <em>e</em> =<em> e</em><sub>min</sub> - 1
</td>
    <td>
<a name="885"> </a><font face="Arial,Helvetica"><em> f</em></font> =  0
</td>
    <td>
<a name="886"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"> &#177;</font>0
</td>
  </tr>
  <tr>
    <td>
<a name="887"> </a> <em>e</em> = <em>e</em><sub>min</sub> - 1
</td>
    <td>
<a name="888"> </a><font face="Arial,Helvetica"><em> f</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"> </font>0<font face="Arial,Helvetica"><em> 
</em></font></td>
    <td>
<a name="889"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg176.gif" height="20" width="57">

</font></td>
  </tr>
  <tr>
    <td>
<a name="890"> </a><sub> </sub><em>e</em><sub>min</sub>  <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"> </font> <em>e</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"> </font><em>e</em><sub>max
</sub></td>
    <td>
<a name="891"> </a> --
</td>
    <td>
<a name="892"> </a> 1.<font face="Arial,Helvetica"><em>f</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times; 2</font><sup><em>e
</em></sup></td>
  </tr>
  <tr>
    <td>
<a name="893"> </a><font face="Arial,Helvetica"><em> </em></font><em>e</em> = <em>e</em><sub>max</sub> + 1
</td>
    <td>
<a name="894"> </a><font face="Arial,Helvetica"><em> f</em></font> =  0
</td>
    <td>
<a name="895"> </a> &plusmn;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif">
</font></td>
  </tr>
  <tr>
    <td>
<a name="896"> </a> <em>e</em> = <em>e</em><sub>max</sub> + 1
</td>
    <td>
<a name="897"> </a><font face="Arial,Helvetica"><em> f</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"> </font>0
</td>
    <td>
<a name="898"> </a><code> </code>NaN
</td>
  </tr>
</table>


</p>
<br></font>
</p>


<h3>
  <a name="899"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">NaNs </font>
</h3>


<p>
  <a name="4986"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Traditionally, the computation of 0/0 or <img src="images/ncg_goldberg130.gif" height="19" width="25">
 has been treated as an unrecoverable error which causes a computation to halt. However, there are examples where it makes sense for a computation to continue in such a situation. Consider a subroutine that finds the zeros of a function <font face="Arial,Helvetica"><em>f</em></font>, say <code>zero(f)</code>. Traditionally, zero finders require the user to input an interval [<font face="Arial,Helvetica"><em>a</em></font>, <font face="Arial,Helvetica"><em>b</em></font>] on which the function is defined and over which the zero finder will search. That is, the subroutine is called as <code>zero(f</code>, <code>a</code>, <code>b)</code>. A more useful zero finder would not require the user to input this extra information. This more general zero finder is especially appropriate for calculators, where it is natural to simply key in a function, and awkward to then have to specify the domain. However, it is easy to see why most zero finders require a domain. The zero finder does its work by probing the function <code>f</code> at various values. If it probed for a value outside the domain of <code>f</code>, the code for <code>f</code> might well compute 0/0 or <img src="images/ncg_goldberg133.gif" height="19" width="25">
, and the computation would halt, unnecessarily aborting the zero finding process. </font>
</p>


<p>
  <a name="4991"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This problem can be avoided by introducing a special value called NaN, and specifying that the computation of expressions like 0/0 and <img src="images/ncg_goldberg246.gif" height="19" width="25">
 produce NaN, rather than halting. A list of some of the situations that can cause a NaN are given in <a href="ncg_goldberg.html#5001">TABLE&nbsp;D-3</a>. Then when <code>zero(f)</code> probes outside the domain of <code>f</code>, the code for <code>f</code> will return NaN, and the zero finder can continue. That is, <code>zero(f)</code> is not "punished" for making an incorrect guess. With this example in mind, it is easy to see what the result of combining a NaN with an ordinary floating-point number should be. Suppose that the final statement of <code>f</code> is <code>return(-b&nbsp;+</code>&nbsp;<code>sqrt(d))/(2*a)</code>. If <font face="Arial,Helvetica"><em>d</em></font> &lt; 0, then <code>f</code> should return a NaN. Since <font face="Arial,Helvetica"><em>d</em></font>&nbsp;&lt;&nbsp;0, <code>sqrt(d)</code> is a NaN, and <code>-b&nbsp;+&nbsp;sqrt(d)</code> will be a NaN, if the sum of a NaN and any other number is a NaN. Similarly if one operand of a division operation is a NaN, the quotient should be a NaN. In general, whenever a NaN participates in a floating-point operation, the result is another NaN. <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><a name="5001"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><b>TABLE D-3 	</b>&nbsp;&nbsp;Operations That Produce a NaN</font></font></b></caption>
  <tr bgcolor="#CCCCCC"><div align="center">
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="5005"> </a>Operation</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="5007"> </a><code>NaN</code> Produced By</font></th>
  </div></tr>
  <tr>
    <td>
<a name="5009"> </a><font face="Arial,Helvetica"><em>+
</em></font></td>
    <td>
<a name="5011"> </a><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/infinity.gif"></font> + (- <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>)
</td>
  </tr>
  <tr>
    <td>
<a name="5013"> </a><font  face="Verdana, Arial, Helvetica, sans-serif">&times;
</font></td>
    <td>
<a name="5015"> </a> 0 <font  face="Verdana, Arial, Helvetica, sans-serif">&times; <img src="chars/infinity.gif">
</font></td>
  </tr>
  <tr>
    <td>
<a name="5017"> </a>/
</td>
    <td>
<a name="5019"> </a> 0/0, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif">
</font></td>
  </tr>
  <tr>
    <td>
<a name="5021"> </a><code>REM
</code></td>
    <td>
<a name="5023"> </a><font face="Arial,Helvetica"><em> x</em></font> <code>REM</code> 0, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"> </font><code>REM</code> <font face="Arial,Helvetica"><em>y
</em></font></td>
  </tr>
  <tr>
    <td>
<a name="5028"> </a><img src="images/ncg_goldberg22.gif" height="19" width="16">

</td>
    <td>
<a name="5033"> </a><img src="images/ncg_goldberg27.gif" height="23" width="19">
 (when <font face="Arial,Helvetica"><em>x &lt; </em></font>0)
</td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="916"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another approach to writing a zero solver that doesn't require the user to input a domain is to use signals. The zero-finder could install a signal handler for floating-point exceptions. Then if <code>f</code> was evaluated outside its domain and raised an exception, control would be returned to the zero solver. The problem with this approach is that every language has a different method of handling signals (if it has a method at all), and so it has no hope of portability. </font>
</p>


<p>
  <a name="917"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In IEEE 754, NaNs are often represented as floating-point numbers with the exponent <em>e</em><sub>max</sub> + 1 and nonzero significands. Implementations are free to put system-dependent information into the significand. Thus there is not a unique NaN, but rather a whole family of NaNs. When a NaN and an ordinary floating-point number are combined, the result should be the same as the NaN operand. Thus if the result of a long computation is a NaN, the system-dependent information in the significand will be the information that was generated when the first NaN in the computation was generated. Actually, there is a caveat to the last statement. If both operands are NaNs, then the result will be one of those NaNs, but it might not be the NaN that was generated first. </font>
</p>


<h4>
  <a name="918"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Infinity </font>
</h4>


<p>
  <a name="919"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Just as NaNs provide a way to continue a computation when expressions like 0/0 or <img src="images/ncg_goldberg32.gif" height="19" width="25">
 are encountered, infinities provide a way to continue when an overflow occurs. This is much safer than simply returning the largest representable number. As an example, consider computing <img src="images/ncg_goldberg223.gif" height="21" width="48">
, when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>&nbsp;=&nbsp;10, <em>p</em> = 3, and <em>e</em><sub>max</sub> = 98. If <em>x</em>&nbsp;=&nbsp;3&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>70</sup> and <em>y</em> = 4 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>70</sup>, then <em>x</em><sup>2</sup> will overflow, and be replaced by 9.99 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>98</sup>. Similarly <em>y</em><sup>2</sup>, and <em>x</em><sup>2</sup> + <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> will each overflow in turn, and be replaced by 9.99 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>98</sup>. So the final result will be <img src="images/ncg_goldberg227.gif" height="21" width="148">
, which is drastically wrong: the correct answer is 5&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>70</sup>. In IEEE arithmetic, the result of <em>x</em><sup>2</sup> is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, as is <em>y</em><sup>2</sup>, <em>x</em><sup>2</sup> + <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> and <img src="images/ncg_goldberg232.gif" height="21" width="48">
. So the final result is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, which is safer than returning an ordinary floating-point number that is nowhere near the correct answer.<a href="#920"><sup>17</sup></a></font>
</p>


<p>
  <a name="921"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The division of 0 by 0 results in a NaN. A nonzero number divided by 0, however, returns infinity: 1/0 = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, -1/0 = -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. The reason for the distinction is this: if <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 0 and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 0 as <em>x</em> approaches some limit, then <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) could have any value. For example, when <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = sin <font face="Arial,Helvetica"><em>x</em></font> and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = <font face="Arial,Helvetica"><em>x</em></font>, then <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 1 as <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 0. But when <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;=&nbsp;1 - cos <font face="Arial,Helvetica"><em>x</em></font>, <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 0. When thinking of 0/0 as the limiting situation of a quotient of two very small numbers, 0/0 could represent anything. Thus in the IEEE standard, 0/0 results in a NaN. But when <font face="Arial,Helvetica"><em>c</em></font> &gt; 0, <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>, <font face="Arial,Helvetica"><em>and g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font>0, then <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font>, for any analytic functions f and g. If <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif">&lt;</font> 0 for small <em>x</em>, then <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, otherwise the limit is +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. So the IEEE standard defines <font face="Arial,Helvetica"><em>c</em></font>/0 = <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font>, as long as <font face="Arial,Helvetica"><em>c</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font> 0. The sign of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> depends on the signs of <font face="Arial,Helvetica"><em>c</em></font> and 0 in the usual way, so that -10/0 = -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, and -10/-0&nbsp;=&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">+<img src="chars/infinity.gif"></font>. You can distinguish between getting <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> because of overflow and getting <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> because of division by zero by checking the status flags (which will be discussed in detail in section <a href="ncg_goldberg.html#989">Flags</a>). The overflow flag will be set in the first case, the division by zero flag in the second. </font>
</p>


<p>
  <a name="922"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The rule for determining the result of an operation that has infinity as an operand is simple: replace infinity with a finite number <em>x</em> and take the limit as <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"> <img src="chars/infinity.gif"></font>. Thus 3/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>&nbsp;=&nbsp;0, because</font>
</p>


<a name="6075"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg237.gif" height="25" width="76">
. <br></font>


<p>
  <a name="6077"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Similarly, 4 - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> = -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, and <img src="images/ncg_goldberg242.gif" height="19" width="21">
&nbsp;=&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. When the limit doesn't exist, the result is a NaN, so <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> will be a NaN (<a href="ncg_goldberg.html#5001">TABLE&nbsp;D-3</a> has additional examples). This agrees with the reasoning used to conclude that 0/0 should be a NaN. </font>
</p>


<p>
  <a name="923"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When a subexpression evaluates to a NaN, the value of the entire expression is also a NaN. In the case of <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font> however, the value of the expression might be an ordinary floating-point number because of rules like 1/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> = 0. Here is a practical example that makes use of the rules for infinity arithmetic. Consider computing the function <em>x</em>/(<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup>&nbsp;+&nbsp;1). This is a bad formula, because not only will it overflow when <em>x</em> is larger than <img src="images/ncg_goldberg248.gif" height="20" width="55">
, but infinity arithmetic will give the wrong answer because it will yield 0, rather than a number near 1/<font face="Arial,Helvetica"><em>x</em></font>. However, <em>x</em>/(<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> + 1) can be rewritten as 1/(<font face="Arial,Helvetica"><em>x</em></font>&nbsp;+ <font face="Arial,Helvetica"><em>x</em></font><sup>-1</sup>). This improved expression will not overflow prematurely and because of infinity arithmetic will have the correct value when <em>x&nbsp;</em>=&nbsp;0: 1/(0 + 0<sup>-1</sup>) = 1/(0 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>) = 1/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> = 0. Without infinity arithmetic, the expression 1/(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>x</em></font><sup>-1</sup>) requires a test for <em>x</em>&nbsp;=&nbsp;0, which not only adds extra instructions, but may also disrupt a pipeline. This example illustrates a general fact, namely that infinity arithmetic often avoids the need for special case checking; however, formulas need to be carefully inspected to make sure they do not have spurious behavior at infinity (as <em>x</em>/(<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup>&nbsp;+&nbsp;1) did). </font>
</p>


<h4>
  <a name="924"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Signed Zero </font>
</h4>


<p>
  <a name="925"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Zero is represented by the exponent <em>e</em><sub>min</sub> - 1 and a zero significand. Since the sign bit can take on two different values, there are two zeros, +0 and -0. If a distinction were made when comparing +0 and -0, simple tests like <code>if</code>&nbsp;<code>(x</code>&nbsp;<code>=</code>&nbsp;<code>0)</code> would have very unpredictable behavior, depending on the sign of <code>x</code>. Thus the IEEE standard defines comparison so that +0 = -0, rather than -0 &lt; +0. Although it would be possible always to ignore the sign of zero, the IEEE standard does not do so. When a multiplication or division involves a signed zero, the usual sign rules apply in computing the sign of the answer. Thus 3<font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font>(+0) = +0, and +0/-3 = -0. If zero did not have a sign, then the relation 1/(1/<font face="Arial,Helvetica"><em>x</em></font>) = <font face="Arial,Helvetica"><em>x</em></font> would fail to hold when <em>x</em> =<font  face="Verdana, Arial, Helvetica, sans-serif"> &#177;<img src="chars/infinity.gif"></font>. The reason is that 1/-<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> and 1/+<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> both result in 0, and 1/0 results in +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, the sign information having been lost. One way to restore the identity 1/(1/<font face="Arial,Helvetica"><em>x</em></font>) = <font face="Arial,Helvetica"><em>x</em></font> is to only have one kind of infinity, however that would result in the disastrous consequence of losing the sign of an overflowed quantity. </font>
</p>


<p>
  <a name="926"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another example of the use of signed zero concerns underflow and functions that have a discontinuity at 0, such as log. In IEEE arithmetic, it is natural to define log 0&nbsp;= -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> and log <font face="Arial,Helvetica"><em>x</em></font> to be a NaN when <em>x</em> &lt; 0. Suppose that <em>x</em> represents a small negative number that has underflowed to zero. Thanks to signed zero, <em>x</em> will be negative, so log can return a NaN. However, if there were no signed zero, the log function could not distinguish an underflowed negative number from 0, and would therefore have to return -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. Another example of a function with a discontinuity at zero is the signum function, which returns the sign of a number. </font>
</p>


<p>
  <a name="927"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Probably the most interesting use of signed zero occurs in complex arithmetic. To take a simple example, consider the equation <img src="images/ncg_goldberg253.gif" height="19" width="90">
. This is certainly true when <font face="Arial,Helvetica"><em>z</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 0. If <font face="Arial,Helvetica"><em>z</em></font> = -1, the obvious computation gives <img src="images/ncg_goldberg259.gif" height="19" width="114">
 and <img src="images/ncg_goldberg264.gif" height="19" width="117">
. Thus, <img src="images/ncg_goldberg270.gif" height="19" width="83">
! The problem can be traced to the fact that square root is multi-valued, and there is no way to select the values so that it is continuous in the entire complex plane. However, square root is continuous if a <em>branch cut</em> consisting of all negative real numbers is excluded from consideration. This leaves the problem of what to do for the negative real numbers, which are of the form -<font face="Arial,Helvetica"><em>x</em></font> + <em>i</em>0, where <em>x</em> &gt; 0. Signed zero provides a perfect way to resolve this problem. Numbers of the form <em>x</em> + <font face="Arial,Helvetica"><em>i</em></font>(+0) have one sign <img src="images/ncg_goldberg274.gif" height="19" width="33">
 and numbers of the form <em>x</em> + <font face="Arial,Helvetica"><em>i</em></font>(-0) on the other side of the branch cut have the other sign <img src="images/ncg_goldberg280.gif" height="19" width="39">
. In fact, the natural formulas for computing <img src="images/ncg_goldberg285.gif" height="19" width="16">
 will give these results. </font>
</p>


<p>
  <a name="928"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Back to <img src="images/ncg_goldberg290.gif" height="19" width="90">
. If <font face="Arial,Helvetica"><em>z</em></font> =1 = -1 + <font face="Arial,Helvetica"><em>i</em></font>0, then</font>
</p>


<a name="11237"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">1/<font face="Arial,Helvetica"><em>z</em></font> = 1/(-1 + <font face="Arial,Helvetica"><em>i</em></font>0) = [(-1-<font face="Arial,Helvetica"><em>&nbsp;i</em></font>0)]/[(-1 + <font face="Arial,Helvetica"><em>i</em></font>0)(-1 - <font face="Arial,Helvetica"><em>i</em></font>0)]  = (-1 -- <font face="Arial,Helvetica"><em>i</em></font>0)/((-1)<sup>2</sup> - 0<sup>2</sup>)  = -1 + <font face="Arial,Helvetica"><em>i</em></font>(-0),<br></font>


<p>
  <a name="11239"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and so <img src="images/ncg_goldberg294.gif" height="19" width="146">
, while <img src="images/ncg_goldberg299.gif" height="19" width="109">
. Thus IEEE arithmetic preserves this identity for all <font face="Arial,Helvetica"><em>z</em></font>. Some more sophisticated examples are given by Kahan [1987]. Although distinguishing between +0 and -0 has advantages, it can occasionally be confusing. For example, signed zero destroys the relation <em>x</em>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>y</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwdbbo.gif"></font>&nbsp;1/<font face="Arial,Helvetica"><em>x</em></font> = 1/<font face="Arial,Helvetica"><em>y</em></font>, which is false when <em>x</em> = +0 and <em>y</em> = -0. However, the IEEE committee decided that the advantages of utilizing the sign of zero outweighed the disadvantages.</font>
</p>


<h4>
  <a name="929"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Denormalized Numbers </font>
</h4>


<p>
  <a name="930"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Consider normalized floating-point numbers with <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p </em>= 3, and <em>e</em><sub>min</sub>&nbsp;=&nbsp;-98. The numbers <em>x</em> = 6.87 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-97</sup> and <em>y</em> = 6.81<font  face="Verdana, Arial, Helvetica, sans-serif"> &times;</font> 10<sup>-97</sup> appear to be perfectly ordinary floating-point numbers, which are more than a factor of 10 larger than the smallest floating-point number 1.00 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-98</sup>. They have a strange property, however: <em>x</em> <img src="images/ncg_goldberg174.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> = 0 even though <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>! The reason is that <em>x</em>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>y</em></font>&nbsp;=&nbsp;.06&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>&nbsp;-97</sup>&nbsp; =&nbsp;6.0&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-99</sup> is too small to be represented as a normalized number, and so must be flushed to zero. How important is it to preserve the property </font>
</p>


<a name="932"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(10) <font face="Arial,Helvetica"><em>x = y </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwdbbo.gif"></font> <font face="Arial,Helvetica"><em>x - y = </em></font>0 ?<br></font>


<p>
  <a name="933"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It's very easy to imagine writing the code fragment, <code>if</code>&nbsp;<code>(x</code>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font>&nbsp;<code>y)</code>&nbsp;<code>then</code>&nbsp;<code>z</code>&nbsp;<code>=</code>&nbsp;<code>1/(x-y)</code>, and much later having a program fail due to a spurious division by zero. Tracking down bugs like this is frustrating and time consuming. On a more philosophical level, computer science textbooks often point out that even though it is currently impractical to prove large programs correct, designing programs with the idea of proving them often results in better code. For example, introducing invariants is quite useful, even if they aren't going to be used as part of a proof. Floating-point code is just like any other code: it helps to have provable facts on which to depend. For example, when analyzing formula <a href="ncg_goldberg.html#1403">(6)</a>, it was very helpful to know that <em>x</em>/2&nbsp;&lt;&nbsp;<font face="Arial,Helvetica"><em>y</em></font>&nbsp;&lt;&nbsp;2<font face="Arial,Helvetica"><em>x</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwdbrt.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;<img src="images/ncg_goldberg184.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> = <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>. Similarly, knowing that <a href="ncg_goldberg.html#932">(10)</a> is true makes writing reliable floating-point code easier. If it is only true for most numbers, it cannot be used to prove anything. </font>
</p>


<p>
  <a name="936"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard uses denormalized<a href="#935"><sup>18</sup></a> numbers, which guarantee <a href="ncg_goldberg.html#932">(10)</a>, as well as other useful relations. They are the most controversial part of the standard and probably accounted for the long delay in getting 754 approved. Most high performance hardware that claims to be IEEE compatible does not support denormalized numbers directly, but rather traps when consuming or producing denormals, and leaves it to software to simulate the IEEE standard.<a href="#937"><sup>19</sup></a> The idea behind denormalized numbers goes back to Goldberg [1967] and is very simple. When the exponent is <em>e</em><sub>min</sub>, the significand does not have to be normalized, so that when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 3 and <em>e</em><sub>min</sub> = -98, 1.00 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-98</sup> is no longer the smallest floating-point number, because 0.98 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-98</sup> is also a floating-point number. </font>
</p>


<p>
  <a name="938"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There is a small snag when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2 and a hidden bit is being used, since a number with an exponent of <em>e</em><sub>min</sub> will always have a significand greater than or equal to 1.0 because of the implicit leading bit. The solution is similar to that used to represent 0, and is summarized in <a href="ncg_goldberg.html#878">TABLE&nbsp;D-2</a>. The exponent <em>e</em><sub>min</sub> is used to represent denormals. More formally, if the bits in the significand field are <font face="Arial,Helvetica"><em>b</em></font><sub>1</sub>,<font face="Arial,Helvetica"><em> b</em></font><sub>2</sub>, <font  face="Verdana, Arial, Helvetica, sans-serif">...</font>, <font face="Arial,Helvetica"><em>b</em></font><sub>p&nbsp;-1</sub>, and the value of the exponent is <em>e</em>, then when <em>e</em> &gt; <em>e</em><sub>min</sub> - 1, the number being represented is 1.<font face="Arial,Helvetica"><em>b</em></font><sub>1</sub><font face="Arial,Helvetica"><em>b</em></font><sub>2</sub><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>b</em></font><sub>p - 1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup><em>e</em></sup> whereas when <em>e</em> = <em>e</em><sub>min</sub> - 1, the number being represented is 0.<font face="Arial,Helvetica"><em>b</em></font><sub>1</sub><font face="Arial,Helvetica"><em>b</em></font><sub>2</sub><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>b</em></font><sub>p - 1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup><em>e</em></sup><sup> + 1</sup>. The&nbsp;+1 in the exponent is needed because denormals have an exponent of <em>e</em><sub>min</sub>, not <em>e</em><sub>min</sub>&nbsp;-&nbsp;1. </font>
</p>


<p>
  <a name="939"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Recall the example of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 3, <em>e</em><sub>min</sub> = -98, <em>x</em> = 6.87 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-97</sup> and <em>y</em>&nbsp;=&nbsp;6.81&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>-97</sup> presented at the beginning of this section. With denormals, <em>x</em> -<font face="Arial,Helvetica"><em>&nbsp;y</em></font> does not flush to zero but is instead represented by the denormalized number .6&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>-98</sup>. This behavior is called gradual <em>underflow</em>. It is easy to verify that <a href="ncg_goldberg.html#932">(10)</a> always holds when using gradual underflow. </font>
</p>


<a name="942"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg23.gif" height="152" width="700">
<br></font>


<a name="943"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">FIGURE D-2 	 Flush To Zero Compared With Gradual Underflow<br></font>


<p>
  <a name="944"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><a href="ncg_goldberg.html#943">FIGURE&nbsp;D-2</a> illustrates denormalized numbers. The top number line in the figure shows normalized floating-point numbers. Notice the gap between 0 and the smallest normalized number <img src="images/ncg_goldberg146.gif" height="20" width="56">
. If the result of a floating-point calculation falls into this gulf, it is flushed to zero. The bottom number line shows what happens when denormals are added to the set of floating-point numbers. The "gulf" is filled in, and when the result of a calculation is less than <img src="images/ncg_goldberg151.gif" height="20" width="56">
, it is represented by the nearest denormal. When denormalized numbers are added to the number line, the spacing between adjacent floating-point numbers varies in a regular way: adjacent spacings are either the same length or differ by a factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. Without denormals, the <br>spacing abruptly changes from <img src="images/ncg_goldberg157.gif" height="20" width="63">
 to <img src="images/ncg_goldberg162.gif" height="20" width="27">
, which is a factor of <img src="images/ncg_goldberg167.gif" height="18" width="31">
, rather than the orderly change by a factor of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>. Because of this, many algorithms that can have large relative error for normalized numbers close to the underflow threshold are well-behaved in this range when gradual underflow is used. </font>
</p>


<p>
  <a name="945"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Without gradual underflow, the simple expression <em>x</em> <font face="Arial,Helvetica"><em>- y</em></font> can have a very large relative error for normalized inputs, as was seen above for <em>x</em> = 6.87 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 10<sup>-97</sup> and <em>y</em>&nbsp;=&nbsp;6.81&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;10<sup>-97</sup>. Large relative errors can happen even without cancellation, as the following example shows [Demmel 1984]. Consider dividing two complex numbers, <font face="Arial,Helvetica"><em>a</em></font> +<font face="Arial,Helvetica"><em> ib</em></font> and <font face="Arial,Helvetica"><em>c</em></font> + <font face="Arial,Helvetica"><em>id</em></font>. The obvious formula </font>
</p>


<a name="946"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg172.gif" height="33" width="146">
<em> </em><font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font><em> i</em><br></font>


<p>
  <a name="702"> </a><font face="Verdana, Arial, Helvetica, sans-serif">suffers from the problem that if either component of the denominator <font face="Arial,Helvetica"><em>c</em></font> +<font face="Arial,Helvetica"><em> id</em></font> is larger than <img src="images/ncg_goldberg208.gif" height="20" width="56">
, the formula will overflow, even though the final result may be well within range. A better method of computing the quotients is to use Smith's formula:</font>
</p>

<dl>  <dl>
     <dt> <a name="12010"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl>
<a name="1158"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(11) <img src="images/ncg_goldberg212.gif" height="89" width="282">
<br></font>

<dl>  <dl>
     <dt> <a name="12011"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
  </dl>
</dl>
<p>
  <a name="692"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Applying Smith's formula to (2 <font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font> 10<sup>-98</sup> +<font face="Arial,Helvetica"><em> i</em></font>10<sup>-98</sup>)/(4 <font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font> 10<sup>-98</sup> + <font face="Arial,Helvetica"><em>i</em></font>(2 <font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font> 10<sup>-98</sup>)) gives the correct answer of 0.5 with gradual underflow. It yields 0.4 with flush to zero, an error of 100 ulps. It is typical for denormalized numbers to guarantee error bounds for arguments all the way down to 1.0 x<img src="images/ncg_goldberg236.gif" height="20" width="27">
. </font>
</p>


<h3>
  <a name="950"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Exceptions, Flags and Trap Handlers </font>
</h3>


<p>
  <a name="951"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When an exceptional condition like division by zero or overflow occurs in IEEE arithmetic, the default is to deliver a result and continue. Typical of the default results are NaN for 0/0 and <img src="images/ncg_goldberg182.gif" height="19" width="25">
, and <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> for 1/0 and overflow. The preceding sections gave examples where proceeding from an exception with these default values was the reasonable thing to do. When any exception occurs, a status flag is also set. Implementations of the IEEE standard are required to provide users with a way to read and write the status flags. The flags are "sticky" in that once set, they remain set until explicitly cleared. Testing the flags is the only way to distinguish 1/0, which is a genuine infinity from an overflow. </font>
</p>


<p>
  <a name="952"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Sometimes continuing execution in the face of exception conditions is not appropriate. The section <a href="ncg_goldberg.html#918">Infinity</a> gave the example of <em>x</em>/(<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> + 1). When <em>x</em> &gt; <img src="images/ncg_goldberg187.gif" height="20" width="55">
, the denominator is infinite, resulting in a final answer of 0, which is totally wrong. Although for this formula the problem can be solved by rewriting it as 1/(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>x</em></font><sup>-1</sup>), rewriting may not always solve the problem. The IEEE standard strongly recommends that implementations allow trap handlers to be installed. Then when an exception occurs, the trap handler is called instead of setting the flag. The value returned by the trap handler will be used as the result of the operation. It is the responsibility of the trap handler to either clear or set the status flag; otherwise, the value of the flag is allowed to be undefined. </font>
</p>


<p>
  <a name="5376"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard divides exceptions into 5 classes: overflow, underflow, division by zero, invalid operation and inexact. There is a separate status flag for each class of exception. The meaning of the first three exceptions is self-evident. Invalid operation covers the situations listed in <a href="ncg_goldberg.html#5001">TABLE&nbsp;D-3</a>, and any comparison that involves a NaN. The default result of an operation that causes an invalid exception is to return a NaN, but the converse is not true. When one of the operands to an operation is a NaN, the result is a NaN but no invalid exception is raised unless the operation also satisfies one of the conditions in <a href="ncg_goldberg.html#5001">TABLE&nbsp;D-3</a>.<a href="#5385"><sup>20</sup></a> <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><a name="5585"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><b>TABLE D-4 	</b>&nbsp;&nbsp;Exceptions in IEEE 754*</font></font></b></caption>
  <tr bgcolor="#CCCCCC"><div align="center">
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="5633"> </a>Exception</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="5627"> </a>Result when traps disabled</font></th>
    <th><font face="Verdana, Arial, Helvetica, sans-serif" color="#003366"><a name="5646"> </a>Argument to trap handler</font></th>
  </div></tr>
  <tr>
    <td>
<a name="5597"> </a>overflow
</td>
    <td>
<a name="5599"> </a><font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font> or <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font><em>x</em><sub>max
</sub></td>
    <td>
<a name="5665"> </a>round(<em>x</em>2<sup>-</sup><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font>)
</td>
  </tr>
  <tr>
    <td>
<a name="5603"> </a>underflow
</td>
    <td>
<a name="5674"> </a>0, <img src="images/ncg_goldberg181.gif" height="20" width="33">
 or denormal
</td>
    <td>
<a name="5652"> </a>round(<em>x</em>2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font>)
</td>
  </tr>
  <tr>
    <td>
<a name="5609"> </a>divide by zero
</td>
    <td>
<a name="5692"> </a>&plusmn;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif">
</font></td>
    <td>
<a name="5613"> </a>operands
</td>
  </tr>
  <tr>
    <td>
<a name="5615"> </a>invalid
</td>
    <td>
<a name="5617"> </a>NaN
</td>
    <td>
<a name="5619"> </a>operands
</td>
  </tr>
  <tr>
    <td>
<a name="5621"> </a>inexact
</td>
    <td>
<a name="5623"> </a>round(<em>x</em>)
</td>
    <td>
<a name="5625"> </a>round(<em>x</em>)
</td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="5253"> </a><font face="Verdana, Arial, Helvetica, sans-serif">*<font face="Arial,Helvetica"><em>x</em></font> is the exact result of the operation,  <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font> = 192 for single precision, 1536 for double, and <font face="Arial,Helvetica"><em>x</em></font><sub>max</sub> = 1.11 <font  face="Verdana, Arial, Helvetica, sans-serif">...</font>11 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg186.gif" height="20" width="27">
</font>.</font>
</p>


<p>
  <a name="977"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The inexact exception is raised when the result of a floating-point operation is not exact. In the <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 3 system, 3.5 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> 4.2 = 14.7 is exact, but 3.5&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font>&nbsp;4.3&nbsp;=&nbsp;15.0 is not exact (since 3.5 <font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font> 4.3 = 15.05), and raises an inexact exception. <a href="ncg_goldberg.html#1251">Binary to Decimal Conversion</a> discusses an algorithm that uses the inexact exception. A summary of the behavior of all five exceptions is given in <a href="ncg_goldberg.html#5585">TABLE&nbsp;D-4</a>. </font>
</p>


<p>
  <a name="978"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There is an implementation issue connected with the fact that the inexact exception is raised so often. If floating-point hardware does not have flags of its own, but instead interrupts the operating system to signal a floating-point exception, the cost of inexact exceptions could be prohibitive. This cost can be avoided by having the status flags maintained by software. The first time an exception is raised, set the software flag for the appropriate class, and tell the floating-point hardware to mask off that class of exceptions. Then all further exceptions will run without interrupting the operating system. When a user resets that status flag, the hardware mask is re-enabled. </font>
</p>


<h4>
  <a name="979"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Trap Handlers </font>
</h4>


<p>
  <a name="980"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One obvious use for trap handlers is for backward compatibility. Old codes that expect to be aborted when exceptions occur can install a trap handler that aborts the process. This is especially useful for codes with a loop like <code>do</code>&nbsp;<code>S</code>&nbsp;<code>until</code>&nbsp;<code>(x</code> <code>&gt;=</code> <code>100)</code>. Since comparing a NaN to a number with &lt;, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>, &gt;,<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/gtequal.gif"></font>, or = (but not <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font>) always returns false, this code will go into an infinite loop if <code>x</code> ever becomes a NaN. </font>
</p>


<p>
  <a name="981"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There is a more interesting use for trap handlers that comes up when computing products such as<em> <img src="images/ncg_goldberg238.gif" height="21" width="44">
</em> that could potentially overflow. One solution is to use logarithms, and compute exp<img src="images/ncg_goldberg243.gif" height="19" width="51">
 instead. The problem with this approach is that it is less accurate, and that it costs more than the simple expression <img src="images/ncg_goldberg249.gif" height="22" width="23">
, even if there is no overflow. There is another solution using trap handlers called <em>over/underflow counting</em> that avoids both of these problems [Sterbenz 1974]. </font>
</p>


<p>
  <a name="982"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The idea is as follows. There is a global counter initialized to zero. Whenever the partial product <img src="images/ncg_goldberg254.gif" height="21" width="75">
 overflows for some<font face="Arial,Helvetica"><em> k</em></font>, the trap handler increments the counter by one and returns the overflowed quantity with the exponent wrapped around. In IEEE 754 single precision, <em>e</em><sub>max</sub> = 127, so if <em>p</em><sub>k</sub>&nbsp;=&nbsp;1.45 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup>130</sup>, it will overflow and cause the trap handler to be called, which will wrap the exponent back into range, changing <em>p</em><sub>k</sub> to 1.45 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup>-62</sup> (see below). Similarly, if <em>p</em><sub>k</sub> underflows, the counter would be decremented, and negative exponent would get wrapped around into a positive one. When all the multiplications are done, if the counter is zero then the final product is <em>p</em><sub>n</sub>. If the counter is positive, the product overflowed, if the counter is negative, it underflowed. If none of the partial products are out of range, the trap handler is never called and the computation incurs no extra cost. Even if there are over/underflows, the calculation is more accurate than if it had been computed with logarithms, because each <em>p</em><sub>k</sub> was computed from <em>p</em><sub>k - 1</sub> using a full precision multiply. Barnett [1987] discusses a formula where the full accuracy of over/underflow counting turned up an error in earlier tables of that formula. </font>
</p>


<p>
  <a name="983"> </a><font face="Verdana, Arial, Helvetica, sans-serif">IEEE 754 specifies that when an overflow or underflow trap handler is called, it is passed the wrapped-around result as an argument. The definition of wrapped-around for overflow is that the result is computed as if to infinite precision, then divided by 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font>, and then rounded to the relevant precision. For underflow, the result is multiplied by 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font>. The exponent <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/alpha.gif"></font> is 192 for single precision and 1536 for double precision. This is why 1.45 x 2<sup>130</sup> was transformed into 1.45 <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> 2<sup>-62</sup> in the example above. </font>
</p>


<h4>
  <a name="984"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Rounding Modes </font>
</h4>


<p>
  <a name="985"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In the IEEE standard, rounding occurs whenever an operation has a result that is not exact, since (with the exception of binary decimal conversion) each operation is computed exactly and then rounded. By default, rounding means round toward nearest. The standard requires that three other rounding modes be provided, namely round toward 0, round toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, and round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. When used with the convert to integer operation, round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> causes the convert to become the floor function, while round toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> is ceiling. The rounding mode affects overflow, because when round toward 0 or round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> is in effect, an overflow of positive magnitude causes the default result to be the largest representable number, not +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. Similarly, overflows of negative magnitude will produce the largest negative number when round toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> or round toward 0 is in effect. </font>
</p>


<p>
  <a name="717"> </a><font face="Verdana, Arial, Helvetica, sans-serif">One application of rounding modes occurs in interval arithmetic (another is mentioned in <a href="ncg_goldberg.html#1251">Binary to Decimal Conversion</a>). When using interval arithmetic, the sum of two numbers <em>x</em> and <em>y</em> is an interval <img src="images/ncg_goldberg37.gif" height="18" width="28">
, where <img src="images/ncg_goldberg260.gif" height="18" width="9">
 is <em>x </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> rounded toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, and <img src="images/ncg_goldberg265.gif" height="16" width="9">
 is <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> rounded toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. The exact result of the addition is contained within the interval <img src="images/ncg_goldberg271.gif" height="18" width="28">
. Without rounding modes, interval arithmetic is usually implemented by computing <img src="images/ncg_goldberg275.gif" height="18" width="101">
 and <img src="images/ncg_goldberg281.gif" height="16" width="102">
, where <img src="images/ncg_goldberg286.gif" height="16" width="9">
 is machine epsilon.<a href="#753"><sup>21</sup></a> This results in overestimates for the size of the intervals. Since the result of an operation in interval arithmetic is an interval, in general the input to an operation will also be an interval. If two intervals <img src="images/ncg_goldberg300.gif" height="17" width="30">
, and <img src="images/ncg_goldberg305.gif" height="19" width="30">
, are added, the result is <img src="images/ncg_goldberg3.gif" height="18" width="28">
, where <img src="images/ncg_goldberg7.gif" height="18" width="9">
 is <img src="images/ncg_goldberg13.gif" height="19" width="31">
 with the rounding mode set to round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, and <img src="images/ncg_goldberg18.gif" height="16" width="9">
 is <img src="images/ncg_goldberg24.gif" height="19" width="30">
 with the rounding mode set to round toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. </font>
</p>


<p>
  <a name="988"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When a floating-point calculation is performed using interval arithmetic, the final answer is an interval that contains the exact result of the calculation. This is not very helpful if the interval turns out to be large (as it often does), since the correct answer could be anywhere in that interval. Interval arithmetic makes more sense when used in conjunction with a multiple precision floating-point package. The calculation is first performed with some precision <em>p</em>. If interval arithmetic suggests that the final answer may be inaccurate, the computation is redone with higher and higher precisions until the final interval is a reasonable size.</font>
</p>


<h4>
  <a name="989"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Flags </font>
</h4>


<p>
  <a name="990"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard has a number of flags and modes. As discussed above, there is one status flag for each of the five exceptions: underflow, overflow, division by zero, invalid operation and inexact. There are four rounding modes: round toward nearest, round toward +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, round toward 0, and round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. It is strongly recommended that there be an enable mode bit for each of the five exceptions. This section gives some simple examples of how these modes and flags can be put to good use. A more sophisticated example is discussed in the section <a href="ncg_goldberg.html#1251">Binary to Decimal Conversion</a>. </font>
</p>


<p>
  <a name="6167"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Consider writing a subroutine to compute <em>x</em><sup>n</sup>, where <font face="Arial,Helvetica"><em>n</em></font> is an integer. When <font face="Arial,Helvetica"><em>n</em></font>&nbsp;&gt;&nbsp;0, a simple routine like <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="13583"> </a>
<pre>PositivePower(x,n) { 
</pre><a name="13584"> </a>
<pre> while (n is even) { 
</pre><a name="13585"> </a>
<pre>     x = x*x
</pre><a name="13586"> </a>
<pre>     n = n/2
</pre><a name="13587"> </a>
<pre> } 
</pre><a name="13588"> </a>
<pre> u = x
</pre><a name="13589"> </a>
<pre> while (true) { 
</pre><a name="13590"> </a>
<pre>     n = n/2
</pre><a name="13591"> </a>
<pre>     if (n==0) return u
</pre><a name="13592"> </a>
<pre>     x = x*x
</pre><a name="13593"> </a>
<pre>     if (n is odd) u = u*x
</pre><a name="6181"> </a>
<pre> } 
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="6183"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If n &lt; 0, then a more accurate way to compute <em>x</em><sup>n</sup> is not to call <code>PositivePower(1/x,</code> <code>-n)</code> but rather <code>1/PositivePower(x,</code> <code>-n)</code>, because the first expression multiplies <font face="Arial,Helvetica"><em>n</em></font> quantities each of which have a rounding error from the division (i.e., 1/<font face="Arial,Helvetica"><em>x</em></font>). In the second expression these are exact (i.e., <em>x</em>), and the final division commits just one additional rounding error. Unfortunately, these is a slight snag in this strategy. If <code>PositivePower(x,</code> <code>-n)</code> underflows, then either the underflow trap handler will be called, or else the underflow status flag will be set. This is incorrect, because if <em>x</em><sup>-</sup><sup><em>n</em></sup> underflows, then <em>x</em><sup>n</sup> will either overflow or be in range.<a href="#6189"><sup>22</sup></a> But since the IEEE standard gives the user access to all the flags, the subroutine can easily correct for this. It simply turns off the overflow and underflow trap enable bits and saves the overflow and underflow status bits. It then computes <code>1/PositivePower(x,</code> <code>-n)</code>. If neither the overflow nor underflow status bit is set, it restores them together with the trap enable bits. If one of the status bits is set, it restores the flags and redoes the calculation using <code>PositivePower(1/x,</code> <code>-n)</code>, which causes the correct exceptions to occur. </font>
</p>


<p>
  <a name="1014"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another example of the use of flags occurs when computing arccos via the formula</font>
</p>


<a name="6197"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">arccos <font face="Arial,Helvetica"><em>x</em></font> = 2 arctan <img src="images/ncg_goldberg58.gif" height="35" width="38">
. <br></font>


<p>
  <a name="6199"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If arctan(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>) evaluates to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/pi.gif"></font>/2, then arccos(-1) will correctly evaluate to 2<font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font>arctan(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>)&nbsp;=<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/pi.gif"></font>, because of infinity arithmetic. However, there is a small snag, because the computation of (1 - <font face="Arial,Helvetica"><em>x</em></font>)/(1 + <font face="Arial,Helvetica"><em>x</em></font>) will cause the divide by zero exception flag to be set, even though arccos(-1) is not exceptional. The solution to this problem is straightforward. Simply save the value of the divide by zero flag before computing arccos, and then restore its old value after the computation. </font>
</p>


<h2>
  <a name="1015"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Systems Aspects</font>
</h2>


<p>
  <a name="1016"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The design of almost every aspect of a computer system requires knowledge about floating-point. Computer architectures usually have floating-point instructions, compilers must generate those floating-point instructions, and the operating system must decide what to do when exception conditions are raised for those floating-point instructions. Computer system designers rarely get guidance from numerical analysis texts, which are typically aimed at users and writers of software, not at computer designers. As an example of how plausible design decisions can lead to unexpected behavior, consider the following BASIC program. <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="1017"> </a>
<pre>q = 3.0/7.0
</pre><a name="1018"> </a>
<pre>if q = 3.0/7.0 then print "Equal":
</pre><a name="1019"> </a>
<pre>    else print "Not Equal"
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="1020"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When compiled and run using Borland's Turbo Basic on an IBM PC, the program prints <code>Not</code> <code>Equal</code>! This example will be analyzed in the next section</font>
</p>


<p>
  <a name="1021"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Incidentally, some people think that the solution to such anomalies is never to compare floating-point numbers for equality, but instead to consider them equal if they are within some error bound <font face="Arial,Helvetica"><em>E</em></font>. This is hardly a cure-all because it raises as many questions as it answers. What should the value of <font face="Arial,Helvetica"><em>E</em></font> be? If <font face="Arial,Helvetica"><em>x</em></font> &lt; 0 and y&nbsp;&gt;&nbsp;0 are within <font face="Arial,Helvetica"><em>E</em></font>, should they really be considered to be equal, even though they have different signs? Furthermore, the relation defined by this rule, <font face="Arial,Helvetica"><em>a</em></font>&nbsp;~&nbsp;<font face="Arial,Helvetica"><em>b</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwdbbo.gif"></font> |a - <font face="Arial,Helvetica"><em>b</em></font>| &lt; <font face="Arial,Helvetica"><em>E</em></font>, is not an equivalence relation because <font face="Arial,Helvetica"><em>a</em></font> ~ <font face="Arial,Helvetica"><em>b</em></font> and <font face="Arial,Helvetica"><em>b</em></font> ~ <font face="Arial,Helvetica"><em>c</em></font> does not imply that <font face="Arial,Helvetica"><em>a</em></font> ~ <font face="Arial,Helvetica"><em>c</em></font>.</font>
</p>


<h3>
  <a name="1022"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Instruction Sets </font>
</h3>


<p>
  <a name="12029"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It is quite common for an algorithm to require a short burst of higher precision in order to produce accurate results. One example occurs in the quadratic formula (<img src="images/ncg_goldberg241.gif" height="21" width="85">
)/2<font face="Arial,Helvetica"><em>a</em></font>. As discussed in the section <a href="ncg_goldberg.html#1224">Proof of Theorem 4</a>, when <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> 4<font face="Arial,Helvetica"><em>ac</em></font>, rounding error can contaminate up to half the digits in the roots computed with the quadratic formula. By performing the subcalculation of <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - 4<font face="Arial,Helvetica"><em>ac</em></font> in double precision, half the double precision bits of the root are lost, which means that all the single precision bits are preserved. </font>
</p>


<p>
  <a name="12036"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The computation of <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - 4<font face="Arial,Helvetica"><em>ac</em></font> in double precision when each of the quantities <font face="Arial,Helvetica"><em>a</em></font>, <font face="Arial,Helvetica"><em>b</em></font>, and <font face="Arial,Helvetica"><em>c</em></font> are in single precision is easy if there is a multiplication instruction that takes two single precision numbers and produces a double precision result. In order to produce the exactly rounded product of two <em>p</em>-digit numbers, a multiplier needs to generate the entire 2<font face="Arial,Helvetica"><em>p</em></font> bits of product, although it may throw bits away as it proceeds. Thus, hardware to compute a double precision product from single precision operands will normally be only a little more expensive than a single precision multiplier, and much cheaper than a double precision multiplier. Despite this, modern instruction sets tend to provide only instructions that produce a result of the same precision as the operands.<a href="#12039"><sup>23</sup></a> </font>
</p>


<p>
  <a name="1026"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If an instruction that combines two single precision operands to produce a double precision product was only useful for the quadratic formula, it wouldn't be worth adding to an instruction set. However, this instruction has many other uses. Consider the problem of solving a system of linear equations, </font>
</p>


<a name="1027"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>a</em></font><sub>11</sub><font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> + <font face="Arial,Helvetica"><em>a</em></font><sub>12</sub><font face="Arial,Helvetica"><em>x</em></font><sub>2</sub> +<sub><em> </em></sub><font  face="Verdana, Arial, Helvetica, sans-serif">&#183; &#183; &#183; + </font><font face="Arial,Helvetica"><em>a</em></font><sub>1n</sub><font face="Arial,Helvetica"><em>x</em></font><sub>n</sub>=<font face="Arial,Helvetica"><em>   b</em></font><sub>1</sub><br></font>


<a name="11266"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>a</em></font><sub>21</sub><font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> + <font face="Arial,Helvetica"><em>a</em></font><sub>22</sub><font face="Arial,Helvetica"><em>x</em></font><sub>2</sub> +<sub><em> </em></sub><font  face="Verdana, Arial, Helvetica, sans-serif">&#183; &#183; &#183; + </font><font face="Arial,Helvetica"><em>a</em></font><sub>2n</sub><font face="Arial,Helvetica"><em>x</em></font><sub>n</sub>=<font face="Arial,Helvetica"><em>   b</em></font><sub>2</sub><br></font>


<a name="1029"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font  face="Verdana, Arial, Helvetica, sans-serif">&#183; &#183; &#183;</font><br></font>


<a name="1030"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>a</em></font><sub>n1</sub><font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> + <font face="Arial,Helvetica"><em>a</em></font><sub>n2</sub><font face="Arial,Helvetica"><em>x</em></font><sub>2</sub> +<sub><em> </em></sub><font  face="Verdana, Arial, Helvetica, sans-serif">&#183; &#183; &#183;+ </font><font face="Arial,Helvetica"><em>a</em></font><sub>nn</sub><font face="Arial,Helvetica"><em>x</em></font><sub>n</sub>=<font face="Arial,Helvetica"><em>   b</em></font><sub>n</sub><br></font>


<p>
  <a name="11280"> </a><font face="Verdana, Arial, Helvetica, sans-serif">which can be written in matrix form as <font face="Arial,Helvetica"><em>Ax</em></font> = <font face="Arial,Helvetica"><em>b</em></font>, where </font>
</p>


<a name="11300"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg216.gif" height="186" width="591">
<br></font>


<p>
  <a name="11301"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Suppose that a solution <em>x</em><sup>(1)</sup> is computed by some method, perhaps Gaussian elimination. There is a simple way to improve the accuracy of the result called <em>iterative improvement</em>. First compute</font>
</p>


<a name="11302"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(12) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font> = <font face="Arial,Helvetica"><em>Ax</em></font><sup>(1)</sup> - <font face="Arial,Helvetica"><em>b</em></font> <br></font>


<p>
  <a name="11303"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and then solve the system </font>
</p>


<a name="11305"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(13) <font face="Arial,Helvetica"><em>Ay</em></font>  = <font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/xi.gif"></font><br></font>


<p>
  <a name="11306"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Note that if <em>x</em><sup>(1)</sup> is an exact solution, then <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font> is the zero vector, as is <em>y</em>. In general, the computation of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font> and <em>y</em> will incur rounding error, so <font face="Arial,Helvetica"><em>Ay</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>Ax</em></font><sup>(1)</sup>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>b</em></font>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>A</em></font>(<font face="Arial,Helvetica"><em>x</em></font><sup>(1)</sup> - <font face="Arial,Helvetica"><em>x</em></font>), where <em>x</em> is the (unknown) true solution. Then <em>y&nbsp;</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font><em>&nbsp;</em><font face="Arial,Helvetica"><em>x</em></font><sup>(1)</sup> - <font face="Arial,Helvetica"><em>x</em></font>, so an improved estimate for the solution is </font>
</p>


<a name="11308"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(14) <font face="Arial,Helvetica"><em>x</em></font><sup>(2)</sup> = <font face="Arial,Helvetica"><em>x</em></font><sup>(1)</sup> - <font face="Arial,Helvetica"><em>y</em></font> <br></font>


<p>
  <a name="11318"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The three steps <a href="ncg_goldberg.html#11302">(12)</a>, <a href="ncg_goldberg.html#11305">(13)</a>, and <a href="ncg_goldberg.html#11308">(14)</a> can be repeated, replacing <em>x</em><sup>(1)</sup> with <em>x</em><sup>(2)</sup>, and <em>x</em><sup>(2)</sup> with <em>x</em><sup>(3)</sup>. This argument that <em>x</em><sup>(</sup><sup><em>i</em></sup><sup> + 1)</sup> is more accurate than x<sup>(</sup><sup><em>i</em></sup><sup>)</sup> is only informal. For more information, see [Golub and Van Loan 1989]. </font>
</p>


<p>
  <a name="1041"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When performing iterative improvement, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font> is a vector whose elements are the difference of nearby inexact floating-point numbers, and so can suffer from catastrophic cancellation. Thus iterative improvement is not very useful unless <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font>=&nbsp;<font face="Arial,Helvetica"><em>Ax</em></font><sup>(1)</sup> - <font face="Arial,Helvetica"><em>b</em></font> is computed in double precision. Once again, this is a case of computing the product of two single precision numbers (<em>A</em> and <em>x</em><sup>(1)</sup>), where the full double precision result is needed. </font>
</p>


<p>
  <a name="1042"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To summarize, instructions that multiply two floating-point numbers and return a product with twice the precision of the operands make a useful addition to a floating-point instruction set. Some of the implications of this for compilers are discussed in the next section. </font>
</p>


<h3>
  <a name="1043"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Languages and Compilers </font>
</h3>


<p>
  <a name="1044"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The interaction of compilers and floating-point is discussed in Farnum [1988], and much of the discussion in this section is taken from that paper.</font>
</p>


<h4>
  <a name="1045"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Ambiguity </font>
</h4>


<p>
  <a name="1046"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Ideally, a language definition should define the semantics of the language precisely enough to prove statements about programs. While this is usually true for the integer part of a language, language definitions often have a large grey area when it comes to floating-point. Perhaps this is due to the fact that many language designers believe that nothing can be proven about floating-point, since it entails rounding error. If so, the previous sections have demonstrated the fallacy in this reasoning. This section discusses some common grey areas in language definitions, including suggestions about how to deal with them.</font>
</p>


<p>
  <a name="1047"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Remarkably enough, some languages don't clearly specify that if <code>x</code> is a floating-point variable (with say a value of <code>3.0/10.0</code>), then every occurrence of (say) <code>10.0*x</code> must have the same value. For example Ada, which is based on Brown's model, seems to imply that floating-point arithmetic only has to satisfy Brown's axioms, and thus expressions can have one of many possible values. Thinking about floating-point in this fuzzy way stands in sharp contrast to the IEEE model, where the result of each floating-point operation is precisely defined. In the IEEE model, we can prove that <code>(3.0/10.0)*10.0</code> evaluates to <code>3</code> (Theorem 7). In Brown's model, we cannot. </font>
</p>


<p>
  <a name="1048"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another ambiguity in most language definitions concerns what happens on overflow, underflow and other exceptions. The IEEE standard precisely specifies the behavior of exceptions, and so languages that use the standard as a model can avoid any ambiguity on this point. </font>
</p>


<p>
  <a name="1049"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another grey area concerns the interpretation of parentheses. Due to roundoff errors, the associative laws of algebra do not necessarily hold for floating-point numbers. For example, the expression <code>(x+y)+z</code> has a totally different answer than <code>x+(y+z)</code> when <em>x</em> = 10<sup>30</sup>, <em>y</em> = -10<sup>30</sup> and <font face="Arial,Helvetica"><em>z</em></font> = 1 (it is 1 in the former case, 0 in the latter). The importance of preserving parentheses cannot be overemphasized. The algorithms presented in theorems 3, 4 and 6 all depend on it. For example, in Theorem 6, the formula <em>x</em><sub>h</sub> = <font face="Arial,Helvetica"><em>mx</em></font> - (<font face="Arial,Helvetica"><em>mx</em></font> - <font face="Arial,Helvetica"><em>x</em></font>) would reduce to <em>x</em><sub>h</sub> = <font face="Arial,Helvetica"><em>x</em></font> if it weren't for parentheses, thereby destroying the entire algorithm. A language definition that does not require parentheses to be honored is useless for floating-point calculations. </font>
</p>


<p>
  <a name="1050"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Subexpression evaluation is imprecisely defined in many languages. Suppose that <code>ds</code> is double precision, but <code>x</code> and <code>y</code> are single precision. Then in the expression <code>ds</code>&nbsp;<code>+</code>&nbsp;<code>x*y</code> is the product performed in single or double precision? Another example: in <code>x</code> <code>+</code> <code>m/n</code> where <code>m</code> and <code>n</code> are integers, is the division an integer operation or a floating-point one? There are two ways to deal with this problem, neither of which is completely satisfactory. The first is to require that all variables in an expression have the same type. This is the simplest solution, but has some drawbacks. First of all, languages like Pascal that have subrange types allow mixing subrange variables with integer variables, so it is somewhat bizarre to prohibit mixing single and double precision variables. Another problem concerns constants. In the expression <code>0.1*x</code>, most languages interpret 0.1 to be a single precision constant. Now suppose the programmer decides to change the declaration of all the floating-point variables from single to double precision. If 0.1 is still treated as a single precision constant, then there will be a compile time error. The programmer will have to hunt down and change every floating-point constant. </font>
</p>


<p>
  <a name="1051"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The second approach is to allow mixed expressions, in which case rules for subexpression evaluation must be provided. There are a number of guiding examples. The original definition of C required that every floating-point expression be computed in double precision [Kernighan and Ritchie 1978]. This leads to anomalies like the example at the beginning of this section. The expression <code>3.0/7.0</code> is computed in double precision, but if <code>q</code> is a single-precision variable, the quotient is rounded to single precision for storage. Since 3/7 is a repeating binary fraction, its computed value in double precision is different from its stored value in single precision. Thus the comparison <font face="Arial,Helvetica"><em>q</em></font> = 3/7 fails. This suggests that computing every expression in the highest precision available is not a good rule. </font>
</p>


<p>
  <a name="1052"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another guiding example is inner products. If the inner product has thousands of terms, the rounding error in the sum can become substantial. One way to reduce this rounding error is to accumulate the sums in double precision (this will be discussed in more detail in the section <a href="ncg_goldberg.html#1070">Optimizers</a>). If <code>d</code> is a double precision variable, and <code>x[]</code> and <code>y[]</code> are single precision arrays, then the inner product loop will look like <code>d</code>&nbsp;<code>=</code> <code>d</code> <code>+</code> <code>x[i]*y[i]</code>. If the multiplication is done in single precision, than much of the advantage of double precision accumulation is lost, because the product is truncated to single precision just before being added to a double precision variable. </font>
</p>


<p>
  <a name="1053"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A rule that covers both of the previous two examples is to compute an expression in the highest precision of any variable that occurs in that expression. Then <code>q</code>&nbsp;<code>=</code>&nbsp;<code>3.0/7.0</code> will be computed entirely in single precision<a href="#1054"><sup>24</sup></a> and will have the boolean value true, whereas <code>d</code> <code>=</code> <code>d</code> <code>+</code> <code>x[i]*y[i]</code> will be computed in double precision, gaining the full advantage of double precision accumulation. However, this rule is too simplistic to cover all cases cleanly. If <code>dx</code> and <code>dy</code> are double precision variables, the expression <code>y</code>&nbsp;<code>=</code>&nbsp;<code>x</code>&nbsp;<code>+</code>&nbsp;<code>single(dx-dy)</code> contains a double precision variable, but performing the sum in double precision would be pointless, because both operands are single precision, as is the result. </font>
</p>


<p>
  <a name="1055"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A more sophisticated subexpression evaluation rule is as follows. First assign each operation a tentative precision, which is the maximum of the precisions of its operands. This assignment has to be carried out from the leaves to the root of the expression tree. Then perform a second pass from the root to the leaves. In this pass, assign to each operation&nbsp;the maximum of the tentative precision and the precision expected by the parent. In the case of <code>q</code>&nbsp;<code>=</code>&nbsp;<code>3.0/7.0</code>, every leaf is single precision, so all the operations are done in single precision. In the case of <code>d</code>&nbsp;<code>=</code>&nbsp;<code>d</code>&nbsp;<code>+</code>&nbsp;<code>x[i]*y[i]</code>, the tentative precision of the multiply operation is single precision, but in the second pass it gets promoted to double precision, because its parent operation expects a double precision operand. And in <code>y</code>&nbsp;<code>=</code>&nbsp;<code>x</code>&nbsp;<code>+</code>&nbsp;<code>single(dx-dy)</code>, the addition is done in single precision. Farnum [1988] presents evidence that this algorithm in not difficult to implement. </font>
</p>


<p>
  <a name="1056"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The disadvantage of this rule is that the evaluation of a subexpression depends on the expression in which it is embedded. This can have some annoying consequences. For example, suppose you are debugging a program and want to know the value of a subexpression. You cannot simply type the subexpression to the debugger and ask it to be evaluated, because the value of the subexpression in the program depends on the expression it is embedded in. A final comment on subexpressions: since converting decimal constants to binary is an operation, the evaluation rule also affects the interpretation of decimal constants. This is especially important for constants like <code>0.1</code> which are not exactly representable in binary. </font>
</p>


<p>
  <a name="1057"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another potential grey area occurs when a language includes exponentiation as one of its built-in operations. Unlike the basic arithmetic operations, the value of exponentiation is not always obvious [Kahan and Coonen 1982]. If <code>**</code> is the exponentiation operator, then <code>(-3)**3</code> certainly has the value -27. However, <code>(-3.0)**3.0</code> is problematical. If the <code>**</code> operator checks for integer powers, it would compute <code>(-3.0)**3.0</code> as -3.0<sup>3</sup> = -27. On the other hand, if the formula <em>x</em><sup>y</sup>&nbsp;=&nbsp;<em>e</em><sup>ylog</sup><sup><em>x</em></sup> is used to define <code>**</code> for real arguments, then depending on the log function, the result could be a NaN (using the natural definition of log(<font face="Arial,Helvetica"><em>x</em></font>) = <code>NaN</code> when <em>x</em> &lt; 0). If the FORTRAN <code>CLOG</code> function is used however, then the answer will be -27, because the ANSI FORTRAN standard defines <code>CLOG(-3.0)</code> to be <font face="Arial,Helvetica"><em>i</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/pi.gif"></font> + log 3 [ANSI 1978]. The programming language Ada avoids this problem by only defining exponentiation for integer powers, while ANSI FORTRAN prohibits raising a negative number to a real power. </font>
</p>


<p>
  <a name="1058"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In fact, the FORTRAN standard says that </font>
</p>

<dl>  <dl>
     <dt> <a name="1059"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Any arithmetic operation whose result is not mathematically defined is prohibited... </font>
  </dl>
</dl>
<p>
  <a name="1060"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Unfortunately, with the introduction of <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font> by the IEEE standard, the meaning of <em>not mathematically defined</em> is no longer totally clear cut. One definition might be to use the method shown in section <a href="ncg_goldberg.html#918">Infinity</a>. For example, to determine the value of <font face="Arial,Helvetica"><em>a</em></font><sup>b</sup>, consider non-constant analytic functions <font face="Arial,Helvetica"><em>f</em></font> and <font face="Arial,Helvetica"><em>g</em></font> with the property that <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> <font face="Arial,Helvetica"><em>a</em></font> and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> <font face="Arial,Helvetica"><em>b</em></font> as <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> 0. If <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)<sup><em>g</em></sup><sup>(</sup><sup><em>x</em></sup><sup>)</sup> always approaches the same limit, then this should be the value of <font face="Arial,Helvetica"><em>a</em></font><sup>b</sup>. This definition would set 2<sup><img src="chars/infinity.gif"></sup>&nbsp;=&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font> which seems quite reasonable. In the case of 1.0<sup><img src="chars/infinity.gif"></sup>, when <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = 1 and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;=&nbsp;1/<font face="Arial,Helvetica"><em>x</em></font> the limit approaches 1, but when <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = 1 - <font face="Arial,Helvetica"><em>x</em></font> and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = 1/<font face="Arial,Helvetica"><em>x</em></font> the limit is <em>e</em><sup>-1</sup>. So 1.0<sup><img src="chars/infinity.gif"></sup>, should be a NaN. In the case of 0<sup>0</sup>, <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)<sup><em>g</em></sup><sup>(</sup><sup><em>x</em></sup><sup>)</sup> = <em>e</em><sup>g(</sup><sup><em>x</em></sup><sup>)log </sup><sup><em>f</em></sup><sup>(</sup><sup><em>x</em></sup><sup>)</sup>. Since <font face="Arial,Helvetica"><em>f</em></font> and <font face="Arial,Helvetica"><em>g</em></font> are analytic and take on the value 0 at 0, <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = <font face="Arial,Helvetica"><em>a</em></font><sub>1</sub><font face="Arial,Helvetica"><em>x</em></font><sup>1</sup> + <font face="Arial,Helvetica"><em>a</em></font><sub>2</sub><font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> + <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> and <font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>b</em></font><sub>1</sub><font face="Arial,Helvetica"><em>x</em></font><sup>1</sup>&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>b</em></font><sub>2</sub><font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> + <font  face="Verdana, Arial, Helvetica, sans-serif">...</font>. Thus lim<sub><em>x</em></sub><sub> <img src="chars/arrwrite.gif"> 0</sub><font face="Arial,Helvetica"><em>g</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) log <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>) = lim<sub><em>x</em></sub><sub>&nbsp;<img src="chars/arrwrite.gif">&nbsp;0</sub><font face="Arial,Helvetica"><em>x</em></font>&nbsp;log(<font face="Arial,Helvetica"><em>x</em></font>(<font face="Arial,Helvetica"><em>a</em></font><sub>1</sub>&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>a</em></font><sub>2</sub><font face="Arial,Helvetica"><em>x</em></font>&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>)) = lim<sub><em>x</em></sub><sub> <img src="chars/arrwrite.gif"> 0</sub><font face="Arial,Helvetica"><em>x</em></font> log(<font face="Arial,Helvetica"><em>a</em></font><sub>1</sub><font face="Arial,Helvetica"><em>x</em></font>) = 0. So <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)<sup><em>g</em></sup><sup>(</sup><sup><em>x</em></sup><sup>)</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> <em>e</em><sup>0</sup> = 1 for all <font face="Arial,Helvetica"><em>f</em></font> and <font face="Arial,Helvetica"><em>g</em></font>, which means that 0<sup>0</sup>&nbsp;=&nbsp;1.<a href="#1061"><sup>25</sup></a> <a href="#1062"><sup>26</sup></a> Using this definition would unambiguously define the exponential function for all arguments, and in particular would define <code>(-3.0)**3.0</code> to be -27. </font>
</p>


<h4>
  <a name="1063"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">The IEEE Standard </font>
</h4>


<p>
  <a name="1064"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The section <a href="ncg_goldberg.html#799">The IEEE Standard</a>," discussed many of the features of the IEEE standard. However, the IEEE standard says nothing about how these features are to be accessed from a programming language. Thus, there is usually a mismatch between floating-point hardware that supports the standard and programming languages like C, Pascal or FORTRAN. Some of the IEEE capabilities can be accessed through a library of subroutine calls. For example the IEEE standard requires that square root be exactly rounded, and the square root function is often implemented directly in hardware. This functionality is easily accessed via a library square root routine. However, other aspects of the standard are not so easily implemented as subroutines. For example, most computer languages specify at most two floating-point types, while the IEEE standard has four different precisions (although the recommended configurations are single plus single-extended or single, double, and double-extended). Infinity provides another example. Constants to represent <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;<img src="chars/infinity.gif"></font> could be supplied by a subroutine. But that might make them unusable in places that require constant expressions, such as the initializer of a constant variable. </font>
</p>


<p>
  <a name="1065"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A more subtle situation is manipulating the state associated with a computation, where the state consists of the rounding modes, trap enable bits, trap handlers and exception flags. One approach is to provide subroutines for reading and writing the state. In addition, a single call that can atomically set a new value and return the old value is often useful. As the examples in the section <a href="ncg_goldberg.html#989">Flags</a> show, a very common pattern of modifying IEEE state is to change it only within the scope of a block or subroutine. Thus the burden is on the programmer to find each exit from the block, and make sure the state is restored. Language support for setting the state precisely in the scope of a block would be very useful here. Modula-3 is one language that implements this idea for trap handlers [Nelson 1991]. </font>
</p>


<p>
  <a name="1066"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There are a number of minor points that need to be considered when implementing the IEEE standard in a language. Since <em>x</em> - <font face="Arial,Helvetica"><em>x</em></font> = +0 for all <em>x</em>,<a href="#1067"><sup>27</sup></a> (+0)&nbsp;-&nbsp;(+0) = +0. However, -(+0) = -0, thus -<font face="Arial,Helvetica"><em>x</em></font> should not be defined as 0&nbsp;-&nbsp;x. The introduction of NaNs can be confusing, because a NaN is never equal to any other number (including another NaN), so <em>x</em> = <font face="Arial,Helvetica"><em>x</em></font> is no longer always true. In fact, the expression <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font>  <font face="Arial,Helvetica"><em>x</em></font> is the simplest way to test for a NaN if the IEEE recommended function <code>Isnan</code> is not provided. Furthermore, NaNs are unordered with respect to all other numbers, so <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> cannot be defined as <em>not</em> <em>x</em> &gt; <font face="Arial,Helvetica"><em>y</em></font>. Since the introduction of NaNs causes floating-point numbers to become partially ordered, a <code>compare</code> function that returns one of &lt;, =, &gt;, or <font face="Arial,Helvetica"><em>unordered</em></font> can make it easier for the programmer to deal with comparisons. </font>
</p>


<p>
  <a name="1068"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Although the IEEE standard defines the basic floating-point operations to return a NaN if any operand is a NaN, this might not always be the best definition for compound operations. For example when computing the appropriate scale factor to use in plotting a graph, the maximum of a set of values must be computed. In this case it makes sense for the max operation to simply ignore NaNs. </font>
</p>


<p>
  <a name="1069"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, rounding can be a problem. The IEEE standard defines rounding very precisely, and it depends on the current value of the rounding modes. This sometimes conflicts with the definition of implicit rounding in type conversions or the explicit <code>round</code> function in languages. This means that programs which wish to use IEEE rounding can't use the natural language primitives, and conversely the language primitives will be inefficient to implement on the ever increasing number of IEEE machines. </font>
</p>


<h4>
  <a name="1070"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Optimizers </font>
</h4>


<p>
  <a name="1071"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Compiler texts tend to ignore the subject of floating-point. For example Aho et al. [1986] mentions replacing <code>x/2.0</code> with <code>x*0.5</code>, leading the reader to assume that <code>x/10.0</code> should be replaced by <code>0.1*x</code>. However, these two expressions do not have the same semantics on a binary machine, because 0.1 cannot be represented exactly in binary. This textbook also suggests replacing <code>x*y-x*z</code> by <code>x*(y-z)</code>, even though we have seen that these two expressions can have quite different values when <em>y</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> z. Although it does qualify the statement that any algebraic identity can be used when optimizing code by noting that optimizers should not violate the language definition, it leaves the impression that floating-point semantics are not very important. Whether or not the language standard specifies that parenthesis must be honored, <code>(x+y)+z</code> can have a totally different answer than <code>x+(y+z)</code>, as discussed above. There is a problem closely related to preserving parentheses that is illustrated by the following code<p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="1072"> </a>
<pre>eps = 1;
</pre><a name="1073"> </a>
<pre>do eps = 0.5*eps; while (eps + 1 &gt; 1);
</pre></td>
  </tr>
</table>


</p>
<br>:</font>
</p>


<p>
  <a name="1074"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This is designed to give an estimate for machine epsilon. If an optimizing compiler notices that <font face="Arial,Helvetica"><em>eps</em></font> + 1 &gt; 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwdbbo.gif"></font> <font face="Arial,Helvetica"><em>eps</em></font> &gt; 0, the program will be changed completely. Instead of computing the smallest number <em>x</em> such that 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> is still greater than <em>x </em>(<em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font face="Arial,Helvetica"><em>e</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <img src="images/ncg_goldberg71.gif" height="18" width="22">
), it will compute the largest number <em>x</em> for which <em>x</em>/2 is rounded to 0 (<em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <img src="images/ncg_goldberg76.gif" height="20" width="27">
). Avoiding this kind of "optimization" is so important that it is worth presenting one more very useful algorithm that is totally ruined by it. </font>
</p>


<p>
  <a name="1075"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Many problems, such as numerical integration and the numerical solution of differential equations involve computing sums with many terms. Because each addition can potentially introduce an error as large as .5 ulp, a sum involving thousands of terms can have quite a bit of rounding error. A simple way to correct for this is to store the partial summand in a double precision variable and to perform each addition using double precision. If the calculation is being done in single precision, performing the sum in double precision is easy on most computer systems. However, if the calculation is already being done in double precision, doubling the precision is not so simple. One method that is sometimes advocated is to sort the numbers and add them from smallest to largest. However, there is a much more efficient method which dramatically improves the accuracy of sums, namely</font>
</p>


<h4>
  <a name="1076"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 8 (Kahan Summation Formula)</font>
</h4>

<dl>
  <dt> <a name="1091"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Suppose that <img src="images/ncg_goldberg81.gif" height="21" width="44">
 is computed using the following algorithm</em> <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td colspan=7 rowspan=1><a name="1077"> </a>
<pre>S = X[1];
</pre><a name="1078"> </a>
<pre>C = 0;
</pre><a name="1079"> </a>
<pre>for j = 2 to N { 
</pre><a name="1080"> </a>
<pre>    Y = X[j] - C;
</pre><a name="1081"> </a>
<pre>    T = S + Y;
</pre><a name="1082"> </a>
<pre>    C = (T - S) - Y;
</pre><a name="1083"> </a>
<pre>    S = T;
</pre><a name="1084"> </a>
<pre>} 
</pre></td>
  </tr>
</table>


</p>
<br></font>
  <dt> <a name="1092"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Then the computed sum </em><font face="Arial,Helvetica"><em>S</em></font><em> is equal to</em> <img src="images/ncg_goldberg87.gif" height="21" width="146">
 <em>where </em><img src="images/ncg_goldberg90.gif" height="19" width="56">
. </font>
</dl>

<p>
  <a name="1093"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Using the naive formula <img src="images/ncg_goldberg96.gif" height="19" width="22">
, the computed sum is equal to <img src="images/ncg_goldberg100.gif" height="19" width="63">
 where |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>j</em></sub>|&nbsp;&lt;&nbsp;(<font face="Arial,Helvetica"><em>n</em></font> - <font face="Arial,Helvetica"><em>j</em></font>)<font face="Arial,Helvetica"><em>e</em></font>. Comparing this with the error in the Kahan summation formula shows a dramatic improvement. Each summand is perturbed by only 2<font face="Arial,Helvetica"><em>e</em></font>, instead of perturbations as large as <font face="Arial,Helvetica"><em>ne</em></font> in the simple formula. Details are in, <a href="ncg_goldberg.html#1262">Errors In Summation</a>. </font>
</p>


<p>
  <a name="1094"> </a><font face="Verdana, Arial, Helvetica, sans-serif">An optimizer that believed floating-point arithmetic obeyed the laws of algebra would conclude that <font face="Arial,Helvetica"><em>C</em></font> = [<font face="Arial,Helvetica"><em>T</em></font>-<font face="Arial,Helvetica"><em>S</em></font>] - <font face="Arial,Helvetica"><em>Y</em></font> = [(<font face="Arial,Helvetica"><em>S</em></font>+<font face="Arial,Helvetica"><em>Y</em></font>)-<font face="Arial,Helvetica"><em>S</em></font>] - <font face="Arial,Helvetica"><em>Y</em></font> = 0, rendering the algorithm completely useless. These examples can be summarized by saying that optimizers should be extremely cautious when applying algebraic identities that hold for the mathematical real numbers to expressions involving floating-point variables. </font>
</p>


<p>
  <a name="1095"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another way that optimizers can change the semantics of floating-point code involves constants. In the expression <code>1.0E-40*x</code>, there is an implicit decimal to binary conversion operation that converts the decimal number to a binary constant. Because this constant cannot be represented exactly in binary, the inexact exception should be raised. In addition, the underflow flag should to be set if the expression is evaluated in single precision. Since the constant is inexact, its exact conversion to binary depends on the current value of the IEEE rounding modes. Thus an optimizer that converts <code>1.0E-40</code> to binary at compile time would be changing the semantics of the program. However, constants like 27.5 which are exactly representable in the smallest available precision can be safely converted at compile time, since they are always exact, cannot raise any exception, and are unaffected by the rounding modes. Constants that are intended to be converted at compile time should be done with a constant declaration, such as <code>const</code> <code>pi</code> <code>=</code> <code>3.14159265</code>.</font>
</p>


<p>
  <a name="1096"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Common subexpression elimination is another example of an optimization that can change floating-point semantics, as illustrated by the following code <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td colspan=2 rowspan=1><a name="1097"> </a>
<pre>C = A*B;
</pre><a name="1098"> </a>
<pre>RndMode = Up
</pre><a name="1099"> </a>
<pre>D = A*B;
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="1101"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Although <code>A*B</code> can appear to be a common subexpression, it is not because the rounding mode is different at the two evaluation sites. Three final examples: <em>x</em>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>x</em></font> cannot be replaced by the boolean constant <code>true</code>, because it fails when <em>x</em> is a NaN; -<font face="Arial,Helvetica"><em>x</em></font>&nbsp;= 0 - <font face="Arial,Helvetica"><em>x</em></font> fails for <em>x</em> = +0; and <em>x</em> &lt; <font face="Arial,Helvetica"><em>y</em></font> is not the opposite of <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>, because NaNs are neither greater than nor less than ordinary floating-point numbers. </font>
</p>


<p>
  <a name="1102"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Despite these examples, there are useful optimizations that can be done on floating-point code. First of all, there are algebraic identities that are valid for floating-point numbers. Some examples in IEEE arithmetic are <em>x</em> + <font face="Arial,Helvetica"><em>y</em></font> = <font face="Arial,Helvetica"><em>y</em></font> + <font face="Arial,Helvetica"><em>x</em></font>, 2&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp; <font face="Arial,Helvetica"><em>x</em></font> = <font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>x</em></font>, 1&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>x</em></font>, and 0.5<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font face="Arial,Helvetica"><em>x</em></font> = <font face="Arial,Helvetica"><em>x</em></font>/2. However, even these simple identities can fail on a few machines such as CDC and Cray supercomputers. Instruction scheduling and in-line procedure substitution are two other potentially useful optimizations.<a href="#1103"><sup>28</sup></a></font>
</p>


<p>
  <a name="1104"> </a><font face="Verdana, Arial, Helvetica, sans-serif">As a final example, consider the&nbsp;expression <code>dx</code>&nbsp;<code>=</code>&nbsp;<code>x*y</code>, where <code>x</code> and <code>y</code> are single precision variables, and <code>dx</code> is double precision. On machines that have an instruction that multiplies two single precision numbers to produce a double precision number, <code>dx</code>&nbsp;<code>=</code>&nbsp;<code>x*y</code> can get mapped to that instruction, rather than compiled to a series of instructions that convert the operands to double and then perform a double to double precision multiply. </font>
</p>


<p>
  <a name="1105"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Some compiler writers view restrictions which prohibit converting (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) + <font face="Arial,Helvetica"><em>z</em></font> to <font face="Arial,Helvetica"><em>x</em></font> + (<font face="Arial,Helvetica"><em>y</em></font> + <font face="Arial,Helvetica"><em>z</em></font>) as irrelevant, of interest only to programmers who use unportable tricks. Perhaps they have in mind that floating-point numbers model real numbers and should obey the same laws that real numbers do. The problem with real number semantics is that they are extremely expensive to implement. Every time two <font face="Arial,Helvetica"><em>n</em></font> bit numbers are multiplied, the product will have 2<font face="Arial,Helvetica"><em>n</em></font> bits. Every time two <font face="Arial,Helvetica"><em>n</em></font> bit numbers with widely spaced exponents are added, the number of bits in the sum is n + the space between the exponents. The sum could have up to <em>(e</em><sup>max</sup> - <em>e</em><sup>min</sup>) + n bits, or roughly 2<font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font><em>e</em><sup>max</sup> + n bits. An algorithm that involves thousands of operations (such as solving a linear system) will soon be operating on numbers with many significant bits, and be hopelessly slow. The implementation of library functions such as sin and cos is even more difficult, because the value of these transcendental functions aren't rational numbers. Exact integer arithmetic is often provided by lisp systems and is handy for some problems. However, exact floating-point arithmetic is rarely useful. </font>
</p>


<p>
  <a name="1106"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The fact is that there are useful algorithms (like the Kahan summation formula) that exploit the fact that (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) + <font face="Arial,Helvetica"><em>z</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> + (<font face="Arial,Helvetica"><em>y</em></font> + <font face="Arial,Helvetica"><em>z</em></font>), and work whenever the bound </font>
</p>


<a name="1107"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>a </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"> </font><font face="Arial,Helvetica"><em>b</em></font> = (<font face="Arial,Helvetica"><em>a</em></font> + <font face="Arial,Helvetica"><em>b</em></font>)(<font  face="Verdana, Arial, Helvetica, sans-serif">1 + <img src="chars/delta.gif">)</font><br></font>


<p>
  <a name="1108"> </a><font face="Verdana, Arial, Helvetica, sans-serif">holds (as well as similar bounds for -, <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> and /). Since these bounds hold for almost all commercial hardware, it would be foolish for numerical programmers to ignore such algorithms, and it would be irresponsible for compiler writers to destroy these algorithms by pretending that floating-point variables have real number semantics. </font>
</p>


<h3>
  <a name="1109"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Exception Handling </font>
</h3>


<p>
  <a name="1110"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The topics discussed up to now have primarily concerned systems implications of accuracy and precision. Trap handlers also raise some interesting systems issues. The IEEE standard strongly recommends that users be able to specify a trap handler for each of the five classes of exceptions, and the section <a href="ncg_goldberg.html#979">Trap Handlers</a>, gave some applications of user defined trap handlers. In the case of invalid operation and division by zero exceptions, the handler should be provided with the operands, otherwise, with the exactly rounded result. Depending on the programming language being used, the trap handler might be able to access other variables in the program as well. For all exceptions, the trap handler must be able to identify what operation was being performed and the precision of its destination. </font>
</p>


<p>
  <a name="1111"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The IEEE standard assumes that operations are conceptually serial and that when an interrupt occurs, it is possible to identify the operation and its operands. On machines which have pipelining or multiple arithmetic units, when an exception occurs, it may not be enough to simply have the trap handler examine the program counter. Hardware support for identifying exactly which operation trapped may be necessary. </font>
</p>


<p>
  <a name="1116"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Another problem is illustrated by the following program fragment. <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="1112"> </a>
<pre>x = y*z;
</pre><a name="1113"> </a>
<pre>z = x*w;
</pre><a name="1114"> </a>
<pre>a = b + c;
</pre><a name="1115"> </a>
<pre>d = a/x;
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="1117"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Suppose the second multiply raises an exception, and the trap handler wants to use the value of <code>a</code>. On hardware that can do an add and multiply in parallel, an optimizer would probably move the addition operation ahead of the second multiply, so that the add can proceed in parallel with the first multiply. Thus when the second multiply traps, <code>a</code>&nbsp;<code>=</code>&nbsp;<code>b</code>&nbsp;<code>+</code>&nbsp;<code>c</code> has already been executed, potentially changing the result of <code>a</code>. It would not be reasonable for a compiler to avoid this kind of optimization, because every floating-point operation can potentially trap, and thus virtually all instruction scheduling optimizations would be eliminated. This problem can be avoided by prohibiting trap handlers from accessing any variables of the program directly. Instead, the handler can be given the operands or result as an argument. </font>
</p>


<p>
  <a name="1120"> </a><font face="Verdana, Arial, Helvetica, sans-serif">But there are still problems. In the fragment <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="1118"> </a>
<pre>x = y*z;
</pre><a name="1119"> </a>
<pre>z = a + b;
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="1121"> </a><font face="Verdana, Arial, Helvetica, sans-serif">the two instructions might well be executed in parallel. If the multiply traps, its argument <code>z</code> could already have been overwritten by the addition, especially since addition is usually faster than multiply. Computer systems that support the IEEE standard must provide some way to save the value of <code>z</code>, either in hardware or by having the compiler avoid such a situation in the first place. </font>
</p>


<p>
  <a name="1122"> </a><font face="Verdana, Arial, Helvetica, sans-serif">W. Kahan has proposed using <em>presubstitution</em> instead of trap handlers to avoid these problems. In this method, the user specifies an exception and the value he wants to be used as the result when the exception occurs. As an example, suppose that in code for computing (sin <font face="Arial,Helvetica"><em>x)</em></font>/<font face="Arial,Helvetica"><em>x</em></font>, the user decides that <em>x</em> = 0 is so rare that it would improve performance to avoid a test for <em>x</em> = 0, and instead handle this case when a 0/0 trap occurs. Using IEEE trap handlers, the user would write a handler that returns a value of 1 and install it before computing sin <font face="Arial,Helvetica"><em>x</em></font>/<font face="Arial,Helvetica"><em>x</em></font>. Using presubstitution, the user would specify that when an invalid operation occurs, the value 1 should be used. Kahan calls this presubstitution, because the value to be used must be specified before the exception occurs. When using trap handlers, the value to be returned can be computed when the trap occurs. </font>
</p>


<p>
  <a name="1123"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The advantage of presubstitution is that it has a straightforward hardware implementation.<a href="#1124"><sup>29</sup></a> As soon as the type of exception has been determined, it can be used to index a table which contains the desired result of the operation. Although presubstitution has some attractive attributes, the widespread acceptance of the IEEE standard makes it unlikely to be widely implemented by hardware manufacturers. </font>
</p>


<h2>
  <a name="1125"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">The Details </font>
</h2>


<p>
  <a name="1126"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A number of claims have been made in this paper concerning properties of floating-point arithmetic. We now proceed to show that floating-point is not black magic, but rather is a straightforward subject whose claims can be verified mathematically. This section is divided into three parts. The first part presents an introduction to error analysis, and provides the details for the section <a href="ncg_goldberg.html#680">Rounding Error</a>. The second part explores binary to decimal conversion, filling in some gaps from the section <a href="ncg_goldberg.html#799">The IEEE Standard</a>. The third part discusses the Kahan summation formula, which was used as an example in the section <a href="ncg_goldberg.html#1015">Systems Aspects</a>. </font>
</p>


<h3>
  <a name="1127"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Rounding Error </font>
</h3>


<p>
  <a name="1128"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In the discussion of rounding error, it was stated that a single guard digit is enough to guarantee that addition and subtraction will always be accurate (Theorem 2). We now proceed to verify this fact. Theorem 2 has two parts, one for subtraction and one for addition. The part for subtraction is </font>
</p>


<h4>
  <a name="1129"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 9</font>
</h4>


<p>
  <a name="1130"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If x and y are positive floating-point numbers in a format with parameters </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><em> and p, and if subtraction is done with p + 1 digits (i.e. one guard digit), then the relative rounding error in the result is less than</em></font>
</p>


<a name="11105"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><img src="images/ncg_goldberg106.gif" height="36" width="119">
</em><font face="Arial,Helvetica"><em>e</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> 2</em><font face="Arial,Helvetica"><em>e</em></font>.<br></font>


<h4>
  <a name="1131"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1132"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Interchange <em>x</em> and <em>y</em> if necessary so that <em>x</em> &gt; y. It is also harmless to scale <em>x</em> and <em>y</em> so that <em>x</em> is represented by <em>x</em><sub>0</sub>.<font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>x</em></font><sub>p - 1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>0</sup>. If <em>y</em> is represented as <em>y</em><sub>0</sub>.<font face="Arial,Helvetica"><em>y</em></font><sub>1</sub><font  face="Verdana, Arial, Helvetica, sans-serif"> ...</font> <font face="Arial,Helvetica"><em>y</em></font><sub>p-1</sub>, then the difference is exact. If <em>y</em> is represented as <em>0</em>.<font face="Arial,Helvetica"><em>y</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>y</em></font><sub>p</sub>, then the guard digit ensures that the computed difference will be the exact difference rounded to a floating-point number, so the rounding error is at most <font face="Arial,Helvetica"><em>e</em></font>. In general, let <em>y</em> = 0.0 <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> 0<font face="Arial,Helvetica"><em>y</em></font><sub>k + 1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>y</em></font><sub>k + </sub><sub><em>p</em></sub> and <img src="images/ncg_goldberg109.gif" height="16" width="10">
 be <em>y</em> truncated to <em>p</em>&nbsp;+&nbsp;1 digits. Then </font>
</dl>

<a name="1133"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(15) y - <img src="images/ncg_goldberg115.gif" height="16" width="10">
 &lt; (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1)(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup> - 1</sup> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup> - 2</sup> + <font  face="Verdana, Arial, Helvetica, sans-serif">...</font><sup> </sup>+ <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup> - </sup><sup><em>k</em></sup>).<br></font>

<dl>
  <dt> <a name="1134"> </a><font face="Verdana, Arial, Helvetica, sans-serif">From the definition of guard digit, the computed value of <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y </em></font>is <font face="Arial,Helvetica"><em>x</em></font> - <img src="images/ncg_goldberg120.gif" height="16" width="10">
 rounded to be a floating-point number, that is, (<font face="Arial,Helvetica"><em>x</em></font> - <img src="images/ncg_goldberg124.gif" height="16" width="10">
) + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>, where the rounding error <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> satisfies </font>
</dl>

<a name="1135"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(16) |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>.<br></font>

<dl>
  <dt> <a name="1136"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The exact difference is <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font>, so the error is (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) - (<font face="Arial,Helvetica"><em>x</em></font> - <img src="images/ncg_goldberg128.gif" height="16" width="10">
 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>) = <img src="images/ncg_goldberg131.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>y</em></font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>. There are three cases. If x - y <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1 then the relative error is bounded by</font>
</dl>

<a name="1137"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(17) <img src="images/ncg_goldberg221.gif" height="31" width="48">
 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup> [(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"> - 1)(<img src="chars/beta.gif"></font><sup>-1</sup> + <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>k</em></sup>) + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2] &lt; <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>(1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif">	.</font><br></font>

<dl>
  <dt> <a name="1138"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Secondly, if <em>x</em> - <img src="images/ncg_goldberg226.gif" height="16" width="10">
 &lt; 1, then <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> = 0. Since the smallest that <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font> can be is</font>
</dl>

<a name="1159"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg230.gif" height="44" width="140">
  &gt; (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>-&nbsp;1)(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-1</sup>&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>&nbsp;+ <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>k</em></sup>), where <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/rho.gif"></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> - 1, <br></font>

<dl>
  <dt> <a name="1139"> </a><font face="Verdana, Arial, Helvetica, sans-serif">in this case the relative error is bounded by </font>
</dl>

<a name="1140"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(18) <img src="images/ncg_goldberg142.gif" height="35" width="315">
<font  face="Verdana, Arial, Helvetica, sans-serif">		.</font><br></font>

<dl>
  <dt> <a name="1141"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The final case is when <em>x</em> - y &lt; 1 but <em>x</em> - <img src="images/ncg_goldberg147.gif" height="16" width="10">
 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1. The only way this could happen is if <em>x</em>&nbsp;-&nbsp;<img src="images/ncg_goldberg152.gif" height="16" width="10">
 = 1, in which case <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> = 0. But if <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> = 0, then <a href="ncg_goldberg.html#1140">(18)</a> applies, so that again the relative error is bounded by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup> &lt; <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2). <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</dl>

<p>
  <a name="1142"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, the bound is exactly 2<font face="Arial,Helvetica"><em>e</em></font>, and this bound is achieved for <em>x</em>= 1 + 2<sup>2&nbsp;-&nbsp;</sup><sup><em>p</em></sup> and <em>y</em> = 2<sup>1 - </sup><sup><em>p</em></sup> - 2<sup>1 - 2</sup><sup><em>p</em></sup> in the limit as <em>p</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/arrwrite.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>. When adding numbers of the same sign, a guard digit is not necessary to achieve good accuracy, as the following result shows. </font>
</p>


<h4>
  <a name="1143"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 10</font>
</h4>


<p>
  <a name="743"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If x </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font><em> </em>0<em> and y </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font><em> </em>0<em>, then the relative error in computing x + y is at most </em>2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><em>, even if no guard digits are used.</em></font>
</p>


<h4>
  <a name="1145"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1146"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The algorithm for addition with <font face="Arial,Helvetica"><em>k</em></font> guard digits is similar to that for subtraction. If <font face="Arial,Helvetica"><em>x</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>y</em></font>, shift <font face="Arial,Helvetica"><em>y</em></font> right until the radix points of <font face="Arial,Helvetica"><em>x</em></font> and <font face="Arial,Helvetica"><em>y</em></font> are aligned. Discard any digits shifted past the <font face="Arial,Helvetica"><em>p</em></font> + <font face="Arial,Helvetica"><em>k</em></font> position. Compute the sum of these two <font face="Arial,Helvetica"><em>p</em></font> + <font face="Arial,Helvetica"><em>k</em></font> digit numbers exactly. Then round to <font face="Arial,Helvetica"><em>p</em></font> digits. </font>
  <dt> <a name="1147"> </a><font face="Verdana, Arial, Helvetica, sans-serif">We will verify the theorem when no guard digits are used; the general case is similar. There is no loss of generality in assuming that <font face="Arial,Helvetica"><em>x</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/gtequal.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 0 and that <font face="Arial,Helvetica"><em>x</em></font> is scaled to be of the form <font face="Arial,Helvetica"><em>d.dd</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>d</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>0</sup>. First, assume there is no carry out. Then the digits shifted off the end of <font face="Arial,Helvetica"><em>y</em></font> have a value less than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup> + 1</sup>, and the sum is at least 1, so the relative error is less than <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup><sup>+1</sup>/1 = 2<font face="Arial,Helvetica"><em>e</em></font>. If there is a carry out, then the error from shifting must be added to the rounding error of</font>
</dl>

<a name="6239"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg158.gif" height="31" width="47">
. <br></font>


<p>
  <a name="6241"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The sum is at least <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>, so the relative error is less than </font>
</p>


<a name="6244"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg163.gif" height="36" width="212">
<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/lt_equal.gif"> </font>2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> <br></font>


<p>
  <a name="6250"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It is obvious that combining these two theorems gives Theorem 2. Theorem 2 gives the relative error for performing one operation. Comparing the rounding error of <em>x</em><sup>2</sup>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> and (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) requires knowing the relative error of multiple operations. The relative error of <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg85.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> = [(<font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg94.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font>) - (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>)] / (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>), which satisfies |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>|&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;2<font face="Arial,Helvetica"><em>e</em></font>. Or to write it another way </font>
</p>


<a name="6266"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(19) <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg104.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> = (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>),    |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>e</em></font><br></font>


<p>
  <a name="6267"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Similarly</font>
</p>


<a name="1154"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(20) <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> = (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>),   |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>e</em></font><br></font>


<p>
  <a name="1155"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Assuming that multiplication is performed by computing the exact product and then rounding, the relative error is at most .5 ulp, so </font>
</p>


<a name="1156"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(21) <font face="Arial,Helvetica"><em>u</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>v</em></font> = <font face="Arial,Helvetica"><em>uv</em></font> (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>),          |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>e</em></font><br></font>


<p>
  <a name="1157"> </a><font face="Verdana, Arial, Helvetica, sans-serif">for any floating-point numbers <font face="Arial,Helvetica"><em>u</em></font> and <font face="Arial,Helvetica"><em>v</em></font>. Putting these three equations together (letting <font face="Arial,Helvetica"><em>u</em></font> = <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg17.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> and <font face="Arial,Helvetica"><em>v</em></font> = <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>) gives</font>
</p>


<a name="1160"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(22) (<font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg105.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"> (</font><font face="Arial,Helvetica"><em>x</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circplus.gif"> </font><font face="Arial,Helvetica"><em>y</em></font>) = (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>)<br></font>


<p>
  <a name="6313"> </a><font face="Verdana, Arial, Helvetica, sans-serif">So the relative error incurred when computing (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) is </font>
</p>


<a name="6317"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(23) <img src="images/ncg_goldberg123.gif" height="42" width="305">
<br></font>


<p>
  <a name="1164"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This relative error is equal to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>, which is bounded by 5<img src="chars/epsilon.gif"> + 8<img src="chars/epsilon.gif"><sup>2</sup>. In other words, the maximum relative error is about 5 rounding errors (since <font face="Arial,Helvetica"><em>e</em></font> is a small number, <font face="Arial,Helvetica"><em>e</em></font><sup>2</sup> is almost negligible). </font>
</p>


<p>
  <a name="1166"> </a><font face="Verdana, Arial, Helvetica, sans-serif">A similar analysis of (<font face="Arial,Helvetica"><em>x</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg160.gif" height="15" width="13">
 (<font face="Arial,Helvetica"><em>y</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>) cannot result in a small value for the relative error, because when two nearby values of <em>x</em> and <em>y</em> are plugged into <em>x</em><sup>2</sup>&nbsp;-&nbsp;y<sup>2</sup>, the relative error will usually be quite large. Another way to see this is to try and duplicate the analysis that worked on (<font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg119.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (<font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>), yielding </font>
</p>


<a name="1169"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(x <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> x) <img src="images/ncg_goldberg210.gif" height="15" width="13">
 (y <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> y) =  [<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) - <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>)] (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>)<br>	 = ((<font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> - <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) + (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>)y<sup>2</sup>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>)<br></font>


<p>
  <a name="1171"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <em>x</em> and <em>y</em> are nearby, the error term (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>)y<sup>2</sup> can be as large as the result <em>x</em><sup>2</sup> - y<sup>2</sup>. These computations formally justify our claim that (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>) (<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) is more accurate than <em>x</em><sup>2</sup> - <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup>. </font>
</p>


<p>
  <a name="1172"> </a><font face="Verdana, Arial, Helvetica, sans-serif">We next turn to an analysis of the formula for the area of a triangle. In order to estimate the maximum error that can occur when computing with <a href="ncg_goldberg.html#1405">(7)</a>, the following fact will be needed. </font>
</p>


<h4>
  <a name="1173"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 11</font>
</h4>

<dl>
  <dt> <a name="1174"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If subtraction is performed with a guard digit, and y/2 </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> x </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> 2y, then x - y is computed exactly.</em> </font>
</dl>

<h4>
  <a name="1175"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1177"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Note that if <em>x</em> and <em>y</em> have the same exponent, then certainly <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg2.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> is exact. Otherwise, from the condition of the theorem, the exponents can differ by at most 1. Scale and interchange <em>x</em> and <em>y</em> if necessary so that 0 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>, and <em>x</em> is represented as <font face="Arial,Helvetica"><em>x</em></font><sub>0</sub>.<font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>x</em></font><sub>p - 1</sub> and <em>y</em> as 0.<font face="Arial,Helvetica"><em>y</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>y</em></font><sub>p</sub>. Then the algorithm for computing <em>x</em> <img src="images/ncg_goldberg12.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>y</em></font> will compute <em>x</em> -<font face="Arial,Helvetica"><em> y</em></font> exactly and round to a floating-point number. If the difference is of the form 0.<font face="Arial,Helvetica"><em>d</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>d</em></font><sub>p</sub>, the difference will already be <em>p</em> digits long, and no rounding is necessary. Since <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>y</em></font>, <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>y</em></font>, and since <em>y</em> is of the form 0.<font face="Arial,Helvetica"><em>d</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>d</em></font><sub>p</sub>, so is <em>x</em> - <font face="Arial,Helvetica"><em>y</em></font>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</dl>

<p>
  <a name="1179"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> &gt; 2, the hypothesis of Theorem 11 cannot be replaced by <em>y</em>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"><img src="chars/lt_equal.gif"></font>x&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"> <img src="chars/beta.gif"></font><font face="Arial,Helvetica"><em>y</em></font>; the stronger condition <font face="Arial,Helvetica"><em>y</em></font>/2 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>y</em></font> is still necessary. The analysis of the error in (<font face="Arial,Helvetica"><em>x</em></font>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>y</em></font>)&nbsp;(<font face="Arial,Helvetica"><em>x</em></font>&nbsp;+ <font face="Arial,Helvetica"><em>y</em></font>), immediately following the proof of Theorem 10, used the fact that the relative error in the basic operations of addition and subtraction is small (namely equations <a href="ncg_goldberg.html#6266">(19)</a> and <a href="ncg_goldberg.html#1154">(20)</a>). This is the most common kind of error analysis. However, analyzing formula <a href="ncg_goldberg.html#1405">(7)</a> requires something more, namely Theorem 11, as the following proof will show. </font>
</p>


<h4>
  <a name="1180"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 12</font>
</h4>

<dl>
  <dt> <a name="1181"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If subtraction uses a guard digit, and if a,b and c are the sides of a triangle (a&nbsp;</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font><em>&nbsp;b</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font><em>&nbsp;c), then the relative error in computing (a&nbsp;+&nbsp;(b&nbsp;+&nbsp;c))(c&nbsp;-&nbsp;(a&nbsp;-&nbsp;b))(c&nbsp;+&nbsp;(a&nbsp;-&nbsp;b))(a&nbsp;+(b&nbsp;-&nbsp;c)) is at most </em>16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><em>, provided </em><font face="Arial,Helvetica"><em>e</em></font><em> &lt; .005. </em></font>
</dl>

<h4>
  <a name="1182"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="12079"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Let's examine the factors one by one. From Theorem 10, <font face="Arial,Helvetica"><em>b</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>c</em></font>&nbsp;=&nbsp;(<font face="Arial,Helvetica"><em>b</em></font>&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>c</em></font>)&nbsp;(1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>), where <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> is the relative error, and |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Then the value of the first factor is </font>
</dl>

<a name="12080"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>)) = (<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) = (<font face="Arial,Helvetica"><em>a</em></font>&nbsp;+&nbsp;(<font face="Arial,Helvetica"><em>b</em></font>&nbsp;+&nbsp;c)&nbsp;(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>))(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>), <br></font>

<dl>
  <dt> <a name="12081"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and thus </font>
</dl>

<a name="1184"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">   (<font face="Arial,Helvetica"><em>a</em></font> + <font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>) (1 - 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>2</sup><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/lt_equal.gif"></font> [<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>) (1 - 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<font  face="Verdana, Arial, Helvetica, sans-serif">] &#183; (1-2<img src="chars/epsilon.gif">) <br>			<img src="chars/lt_equal.gif"></font> a <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>)<br><font  face="Verdana, Arial, Helvetica, sans-serif">			<img src="chars/lt_equal.gif"></font> [<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>) (1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)] (1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<br><font  face="Verdana, Arial, Helvetica, sans-serif">			<img src="chars/lt_equal.gif"></font> (<font face="Arial,Helvetica"><em>a</em></font> + <font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>) (1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>2</sup> <br></font>

<dl>
  <dt> <a name="6357"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This means that there is an <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub> so that </font>
</dl>

<a name="6358"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(24) (a <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (b <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> c)) = (a + b + c) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub>)<sup>2</sup>, |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. <br></font>

<dl>
  <dt> <a name="6364"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The next term involves the potentially catastrophic subtraction of <font face="Arial,Helvetica"><em>c</em></font> and <font face="Arial,Helvetica"><em>a</em></font>&nbsp;<img src="images/ncg_goldberg134.gif" height="15" width="13">
&nbsp;<code>b</code>, because <font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg222.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font> may have rounding error. Because a, b and c are the sides of a triangle, a <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> b+<font face="Arial,Helvetica"><em> c</em></font>, and combining this with the ordering <font face="Arial,Helvetica"><em>c</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>a</em></font> gives <font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>b</em></font> +<font face="Arial,Helvetica"><em> c</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font face="Arial,Helvetica"><em>a</em></font>. So <font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font> satisfies the conditions of Theorem 11. This means that <font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font> = <font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg127.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font> is exact, hence <font face="Arial,Helvetica"><em>c</em></font> <img src="images/ncg_goldberg135.gif" height="15" width="13">
 (<font face="Arial,Helvetica"><em>a</em></font> - b) is a harmless subtraction which can be estimated from Theorem 9 to be </font>
</dl>

<a name="1194"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(25) (<font face="Arial,Helvetica"><em>c</em></font> <img src="images/ncg_goldberg228.gif" height="15" width="13">
 (<font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg219.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font>)) = (<font face="Arial,Helvetica"><em>c</em></font> - (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>2</sub>), |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>2</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> <br></font>

<dl>
  <dt> <a name="1195"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The third term is the sum of two exact positive quantities, so </font>
</dl>

<a name="1197"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(26) (<font face="Arial,Helvetica"><em>c</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg29.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font>)) = (c + (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>3</sub>), |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>3</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><br></font>

<dl>
  <dt> <a name="1198"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, the last term is </font>
</dl>

<a name="1200"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(27) (<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <img src="images/ncg_goldberg38.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>c</em></font>)) = (<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> - c)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>4</sub>)<sup>2</sup>, |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>4</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, <br></font>

<dl>
  <dt> <a name="1201"> </a><font face="Verdana, Arial, Helvetica, sans-serif">using both Theorem 9 and Theorem 10. If multiplication is assumed to be exactly rounded, so that <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> = <font face="Arial,Helvetica"><em>xy</em></font>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/zeta.gif"></font>) with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/zeta.gif"></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, then combining <a href="ncg_goldberg.html#6358">(24)</a>, <a href="ncg_goldberg.html#1194">(25)</a>, <a href="ncg_goldberg.html#1197">(26)</a> and <a href="ncg_goldberg.html#1200">(27)</a> gives </font>
</dl>

<a name="1206"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (b <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> c)) (c <img src="images/ncg_goldberg48.gif" height="15" width="13">
 (a <img src="images/ncg_goldberg136.gif" height="15" width="13">
 b)) (c <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (a <img src="images/ncg_goldberg168.gif" height="15" width="13">
 b)) (<font face="Arial,Helvetica"><em>a </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <img src="images/ncg_goldberg178.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>c</em></font>))<br><font  face="Verdana, Arial, Helvetica, sans-serif">	<img src="chars/lt_equal.gif"></font>(<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> + c)) (<font face="Arial,Helvetica"><em>c</em></font> - (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (<font face="Arial,Helvetica"><em>c</em></font> + (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (a + (b -<font face="Arial,Helvetica"><em> c</em></font>))<font face="Arial,Helvetica"><em> E </em></font><br></font>

<dl>
  <dt> <a name="1207"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where </font>
</dl>

<a name="1208"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>E</em></font> = (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub>)<sup>2</sup> (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>2</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>3</sub>) (1 +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>4</sub>)<sup>2 </sup>(1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/zeta.gif"></font><sub>1</sub>)(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/zeta.gif"></font><sub>2</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/zeta.gif"></font><sub>3</sub>) <br></font>

<dl>
  <dt> <a name="1209"> </a><font face="Verdana, Arial, Helvetica, sans-serif">An upper bound for <font face="Arial,Helvetica"><em>E</em></font> is (1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>6</sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>3</sup>, which expands out to 1&nbsp;+&nbsp;15<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>&nbsp;+&nbsp;O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>). Some writers simply ignore the O(<font face="Arial,Helvetica"><em>e</em></font><sup>2</sup>) term, but it is easy to account for it. Writing (1&nbsp;+&nbsp;2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>6</sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>3</sup> = 1 + 15<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><font face="Arial,Helvetica"><em>R</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>), <font face="Arial,Helvetica"><em>R</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>) is a polynomial in <font face="Arial,Helvetica"><em>e</em></font> with positive coefficients, so it is an increasing function of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Since <font face="Arial,Helvetica"><em>R</em></font>(.005)&nbsp;= .505, <font face="Arial,Helvetica"><em>R</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>) &lt; 1 for all <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> &lt; .005, and hence <font face="Arial,Helvetica"><em>E</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;(1&nbsp;+&nbsp;2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>6</sup>(1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>3</sup>&nbsp;&lt;&nbsp;1&nbsp;+&nbsp;16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. To get a lower bound on <font face="Arial,Helvetica"><em>E</em></font>, note that 1&nbsp;-&nbsp;15<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>&nbsp;-&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>R(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>) &lt; E, and so when <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> &lt; .005, 1 - 16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> &lt; (1 - 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>6</sup>(1 - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>)<sup>3</sup>. Combining these two bounds yields 1&nbsp;- 16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> &lt; <font face="Arial,Helvetica"><em>E</em></font> &lt;&nbsp;1&nbsp;+&nbsp;16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Thus the relative error is at most 16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. z </font>
</dl>

<p>
  <a name="1144"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Theorem 12 certainly shows that there is no catastrophic cancellation in formula <a href="ncg_goldberg.html#1405">(7)</a>. So although it is not necessary to show formula <a href="ncg_goldberg.html#1405">(7)</a> is numerically stable, it is satisfying to have a bound for the entire formula, which is what Theorem 3 of <a href="ncg_goldberg.html#700">Cancellation</a> gives.</font>
</p>


<h4>
  <a name="1211"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof of Theorem 3</font>
</h4>

<dl>
  <dt> <a name="1212"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Let </font>
</dl>

<a name="12086"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>q</em></font> = (<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> + <font face="Arial,Helvetica"><em>c</em></font>)) (<font face="Arial,Helvetica"><em>c</em></font> - (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (<font face="Arial,Helvetica"><em>c</em></font> + (<font face="Arial,Helvetica"><em>a</em></font> - <font face="Arial,Helvetica"><em>b</em></font>)) (<font face="Arial,Helvetica"><em>a</em></font> + (<font face="Arial,Helvetica"><em>b</em></font> - <font face="Arial,Helvetica"><em>c</em></font>)) <br></font>

<dl>
  <dt> <a name="10808"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and </font>
</dl>

<a name="12087"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>Q</em></font> = (<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (c <img src="images/ncg_goldberg214.gif" height="15" width="13">
 (<font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg188.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (<font face="Arial,Helvetica"><em>c</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>a</em></font> <img src="images/ncg_goldberg197.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>b</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> (<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> (<font face="Arial,Helvetica"><em>b</em></font> <img src="images/ncg_goldberg206.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>c</em></font>)). <br></font>

<dl>
  <dt> <a name="10824"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Then, Theorem 12 shows that Q&nbsp;= <font face="Arial,Helvetica"><em>q</em></font>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>), with <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. It is easy to check that</font>
</dl>

<a name="1217"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(28) <img src="images/ncg_goldberg132.gif" height="19" width="231">
<br></font>

<dl>
  <dt> <a name="1218"> </a><font face="Verdana, Arial, Helvetica, sans-serif">provided <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> .04/(.52)<sup>2</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> .15, and since |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 16<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 16(.005) = .08, <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font> does satisfy the condition. Thus</font>
</dl>

<a name="12088"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg137.gif" height="23" width="169">
, <br></font>

<dl>
  <dt> <a name="12090"> </a><font face="Verdana, Arial, Helvetica, sans-serif">with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;.52|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 8.5<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. If square roots are computed to within .5 ulp, then the error when computing <img src="images/ncg_goldberg139.gif" height="19" width="21">
 is (1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>)(1&nbsp;+ <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>), with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. If <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, then there is no further error committed when dividing by 4. Otherwise, one more factor 1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub> with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>|&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> is necessary for the division, and using the method in the proof of Theorem 12, the final error bound of (1 +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>) is dominated by 1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>, with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 11<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</dl>

<p>
  <a name="1219"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To make the heuristic explanation immediately following the statement of Theorem 4 precise, the next theorem describes just how closely <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>) approximates a constant. </font>
</p>


<h4>
  <a name="1220"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 13</font>
</h4>

<dl>
  <dt> <a name="1221"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If </em><font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)<em> </em>= ln(1 +<em> </em><font face="Arial,Helvetica"><em>x</em></font>)/<font face="Arial,Helvetica"><em>x</em></font><em>, then for </em>0<em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> </em><font face="Arial,Helvetica"><em>x</em></font><em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> <img src="images/ncg_goldberg143.gif" height="22" width="8">
, <img src="images/ncg_goldberg148.gif" height="22" width="8">
 </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> </em><font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<em>x</em>)<em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> </em>1<em> and the derivative satisfies |</em><font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font><em>'</em>(<em>x</em>)|<em>&nbsp;</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em>&nbsp;<img src="images/ncg_goldberg153.gif" height="22" width="8">
. </em></font>
</dl>

<h4>
  <a name="1222"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1223"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Note that <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>) = 1 - <font face="Arial,Helvetica"><em>x</em></font>/2 + <font face="Arial,Helvetica"><em>x</em></font><sup>2</sup>/3 - <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> is an alternating series with decreasing terms, so for <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1, <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1 - <font face="Arial,Helvetica"><em>x</em></font>/2 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 1/2. It is even easier to see that because the series for <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font> is alternating, <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1. The Taylor series of <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>'(<font face="Arial,Helvetica"><em>x</em></font>) is also alternating, and if <em>x</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <img src="images/ncg_goldberg159.gif" height="22" width="8">
 has decreasing terms, so - <em><img src="images/ncg_goldberg164.gif" height="22" width="8">
</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>'(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> -<em><img src="images/ncg_goldberg169.gif" height="22" width="8">
</em> + 2<font face="Arial,Helvetica"><em>x</em></font>/3, or -<em><img src="images/ncg_goldberg173.gif" height="22" width="8">
</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> &#181;'(<font face="Arial,Helvetica"><em>x</em></font>) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 0, thus |<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>'(<font face="Arial,Helvetica"><em>x</em></font>)| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <em><img src="images/ncg_goldberg179.gif" height="22" width="8">
</em>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</dl>

<h4>
  <a name="1224"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof of Theorem 4 </font>
</h4>

<dl>
  <dt> <a name="1225"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since the Taylor series for ln </font>
</dl>

<a name="1227"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg183.gif" height="33" width="150">
<br></font>

<dl>
  <dt> <a name="1228"> </a><font face="Verdana, Arial, Helvetica, sans-serif">is an alternating series, 0 &lt; <font face="Arial,Helvetica"><em>x</em></font> - ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) &lt; <font face="Arial,Helvetica"><em>x</em></font><sup>2</sup>/2, the relative error incurred when approximating ln(1 + <font face="Arial,Helvetica"><em>x</em></font>) by <em>x</em> is bounded by <em>x</em>/2. If 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> = 1, then |<font face="Arial,Helvetica"><em>x</em></font>|&nbsp;&lt;&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, so the relative error is bounded by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>/2. </font>
  <dt> <a name="9691"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/notequal.gif"></font> 1, define <img src="images/ncg_goldberg5.gif" height="16" width="10">
 via 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> = 1 + <img src="images/ncg_goldberg194.gif" height="16" width="10">
. Then since 0 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> &lt; 1, (1<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg141.gif" height="10" width="10">
 1 = <img src="images/ncg_goldberg191.gif" height="16" width="10">
. If division and logarithms are computed to within <em><img src="images/ncg_goldberg195.gif" height="22" width="8">
</em> ulp, then the computed value of the expression ln(1 + <font face="Arial,Helvetica"><em>x</em></font>)/((1 + <font face="Arial,Helvetica"><em>x</em></font>) - 1) is </font>
</dl>

<a name="9709"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(29)  <img src="images/ncg_goldberg201.gif" height="31" width="63">
(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) = <img src="images/ncg_goldberg192.gif" height="31" width="51">
 (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) = <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg196.gif" height="16" width="10">
) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>)<br><br></font>


<p>
  <a name="987"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> and |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. To estimate <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg189.gif" height="16" width="10">
), use the mean value theorem, which says that </font>
</p>


<a name="1233"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(30) <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg193.gif" height="16" width="10">
) - <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<em>x</em>) = (<img src="images/ncg_goldberg198.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>x</em></font>)<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;'</font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font>)<br></font>

<dl>
  <dt> <a name="1234"> </a><font face="Verdana, Arial, Helvetica, sans-serif">for some <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/xi.gif"></font> between <em>x</em> and <img src="images/ncg_goldberg203.gif" height="16" width="10">
. From the definition of <img src="images/ncg_goldberg207.gif" height="16" width="10">
, it follows that |<img src="images/ncg_goldberg211.gif" height="16" width="10">
 - <font face="Arial,Helvetica"><em>x</em></font>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, and combining this with Theorem 13 gives |<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg215.gif" height="16" width="10">
) - <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>/2, or |<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg220.gif" height="16" width="10">
)/<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)&nbsp;-&nbsp;1| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>/(2|<font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)|) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> which means that <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<img src="images/ncg_goldberg225.gif" height="16" width="10">
) = <font  face="Verdana, Arial, Helvetica, sans-serif">&#181;</font>(<font face="Arial,Helvetica"><em>x</em></font>)<em> </em>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>), with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Finally, multiplying by <font face="Arial,Helvetica"><em>x</em></font> introduces a final <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>, so the computed value of </font>
</dl>

<a name="12106"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>x</em><font  face="Verdana, Arial, Helvetica, sans-serif">&#183;</font>ln(1&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>)/((1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg224.gif" height="15" width="13">
 1)<br></font>


<p>
  <a name="12107"> </a><font face="Verdana, Arial, Helvetica, sans-serif">is </font>
</p>


<a name="1236"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg229.gif" height="31" width="279">
<br></font>

<dl>
  <dt> <a name="1237"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It is easy to check that if <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> &lt; 0.1, then </font>
</dl>

<a name="12109"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>) = 1 +&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>, <br></font>


<p>
  <a name="12110"> </a><font face="Verdana, Arial, Helvetica, sans-serif">with |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font>|&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 5<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</p>


<p>
  <a name="1238"> </a><font face="Verdana, Arial, Helvetica, sans-serif">An interesting example of error analysis using formulas <a href="ncg_goldberg.html#6266">(19)</a>, <a href="ncg_goldberg.html#1154">(20)</a>, and <a href="ncg_goldberg.html#1156">(21)</a> occurs in the quadratic formula <img src="images/ncg_goldberg234.gif" height="21" width="117">
. The section <a href="ncg_goldberg.html#700">Cancellation</a>, explained how rewriting the equation will eliminate the potential cancellation caused by the <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> operation. But there is another potential cancellation that can occur when computing <font face="Arial,Helvetica"><em>d</em></font> = <font face="Arial,Helvetica"><em>b</em></font><sub>2</sub> - 4<font face="Arial,Helvetica"><em>ac</em></font>. This one cannot be eliminated by a simple rearrangement of the formula. Roughly speaking, when <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> 4<font face="Arial,Helvetica"><em>ac</em></font>, rounding error can contaminate up to half the digits in the roots computed with the quadratic formula. Here is an informal proof (another approach to estimating the error in the quadratic formula appears in Kahan [1972]).</font>
</p>


<p>
  <a name="1239"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>If b</em></font><sup>2</sup><em> </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font><em> </em>4<em>ac, rounding error can contaminate up to half the digits in the roots computed with the quadratic formula </em><img src="images/ncg_goldberg239.gif" height="21" width="117">
<em>. </em></font>
</p>


<p>
  <a name="1240"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Proof: Write (<font face="Arial,Helvetica"><em>b</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circmult.gif"></font> b) <img src="images/ncg_goldberg233.gif" height="15" width="13">
 (4<font face="Arial,Helvetica"><em>a</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>c</em></font>) = (<font face="Arial,Helvetica"><em>b</em></font><sup>2</sup>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) - 4<font face="Arial,Helvetica"><em>ac</em></font>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>), where |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i</em></sub>|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>.<font face="Arial,Helvetica"><em> </em></font><a href="#1241"><sup>30</sup></a> Using <font face="Arial,Helvetica"><em>d</em></font> = <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> - 4<font face="Arial,Helvetica"><em>ac</em></font>, this can be rewritten as (<font face="Arial,Helvetica"><em>d</em></font>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>) - 4<font face="Arial,Helvetica"><em>ac</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>). To get an estimate for the size of this error, ignore second order terms in <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i</em></sub>, in which case the absolute error is <font face="Arial,Helvetica"><em>d</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>) - 4ac<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>, where |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub>| = |<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub>&nbsp;-&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>2</sub>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Since <img src="images/ncg_goldberg245.gif" height="16" width="42">
, the first term <font face="Arial,Helvetica"><em>d</em></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>1</sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>) can be ignored. To estimate the second term, use the fact that <font face="Arial,Helvetica"><em>ax</em></font><sup>2</sup>&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>bx</em></font>&nbsp;+ <font face="Arial,Helvetica"><em>c</em></font> = <font face="Arial,Helvetica"><em>a</em></font>(<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub>) (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>r</em></font><sub>2</sub>), so <font face="Arial,Helvetica"><em>ar</em></font><sub>1</sub><font face="Arial,Helvetica"><em>r</em></font><sub>2</sub>&nbsp;= <font face="Arial,Helvetica"><em>c</em></font>. Since <font face="Arial,Helvetica"><em>b</em></font><sup>2</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> 4<font face="Arial,Helvetica"><em>ac</em></font>, then<font face="Arial,Helvetica"><em> r</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <sub><em>r</em></sub><sub>2</sub>, so the second error term is <img src="images/ncg_goldberg250.gif" height="21" width="96">
 . Thus the computed value of <img src="images/ncg_goldberg256.gif" height="19" width="19">
 is</font>
</p>


<a name="12176"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg261.gif" height="24" width="75">
. <br></font>


<p>
  <a name="12178"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The inequality </font>
</p>


<a name="1242"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg267.gif" height="21" width="282">
 <br></font>


<p>
  <a name="1243"> </a><font face="Verdana, Arial, Helvetica, sans-serif">shows that</font>
</p>


<a name="12172"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg272.gif" height="24" width="131">
,<br></font>


<p>
  <a name="12174"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where</font>
</p>


<a name="6453"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg277.gif" height="24" width="88">
, <br></font>


<p>
  <a name="6455"> </a><font face="Verdana, Arial, Helvetica, sans-serif">so the absolute error in <img src="images/ncg_goldberg282.gif" height="19" width="34">
<em>a</em> is about <img src="images/ncg_goldberg288.gif" height="23" width="35">
. Since <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>4</sub> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>-</sup><sup><em>p</em></sup>, <img src="images/ncg_goldberg292.gif" height="23" width="67">
, and thus the absolute error of <img src="images/ncg_goldberg297.gif" height="23" width="35">
 destroys the bottom half of the bits of the roots <font face="Arial,Helvetica"><em>r</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> r<sub>2</sub>. In other words, since the calculation of the roots involves computing with <img src="images/ncg_goldberg301.gif" height="19" width="61">
, and this expression does not have meaningful bits in the position corresponding to the lower order half of <font face="Arial,Helvetica"><em>r</em></font><sub>i</sub>, then the lower order bits of <font face="Arial,Helvetica"><em>r</em></font><sub>i</sub> cannot be meaningful. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</p>


<p>
  <a name="1244"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, we turn to the proof of Theorem 6. It is based on the following fact, which is proven in the section <a href="ncg_goldberg.html#1324">Theorem 14 and Theorem 8</a>. </font>
</p>


<h4>
  <a name="1245"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 14</font>
</h4>

<dl>
  <dt> <a name="1246"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Let </em>0<em> &lt; k &lt; p, and set m = </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><em> + </em>1<em>, and assume that floating-point operations are exactly rounded. Then (m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> x) </em><img src="images/ncg_goldberg244.gif" height="15" width="13">
<em> (m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> x </em><img src="images/ncg_goldberg255.gif" height="15" width="13">
<em> x) is exactly equal to x rounded to p - k significant digits. More precisely, x is rounded by taking the significand of x, imagining a radix point just left of the k least significant digits and rounding to an integer. </em></font>
</dl>

<h4>
  <a name="1247"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof of Theorem 6 </font>
</h4>

<dl>
  <dt> <a name="1248"> </a><font face="Verdana, Arial, Helvetica, sans-serif">By Theorem 14, <em>x</em><sub>h</sub> is <em>x</em> rounded to <em>p</em> - k =<font  face="Verdana, Arial, Helvetica, sans-serif"> </font><img src="images/ncg_goldberg110.gif" height="16" width="39">
 places. If there is no carry out, then certainly <font face="Arial,Helvetica"><em>x</em></font><sub>h</sub> can be represented with <img src="images/ncg_goldberg107.gif" height="16" width="39">
significant digits. Suppose there is a carry-out. If <em>x</em> = <font face="Arial,Helvetica"><em>x</em></font><sub>0</sub>.<font face="Arial,Helvetica"><em>x</em></font><sub>1</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> <font face="Arial,Helvetica"><em>x</em></font><sub>p - 1</sub> &times; <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>, then rounding adds 1 to <font face="Arial,Helvetica"><em>x</em></font><sub>p&nbsp;-&nbsp;</sub><sub><em>k</em></sub><sub>&nbsp;-&nbsp;1</sub>, and the only way there can be a carry-out is if <font face="Arial,Helvetica"><em>x</em></font><sub>p - </sub><sub><em>k</em></sub><sub> - 1</sub> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"> </font>- 1, but then the low order digit of <font face="Arial,Helvetica"><em>x</em></font><sub>h</sub> is 1&nbsp;+&nbsp;<font face="Arial,Helvetica"><em>x</em></font><sub>p&nbsp;-&nbsp;</sub><sub><em>k</em></sub><sub>-&nbsp;1</sub>&nbsp;=&nbsp;0, and so again <em>x</em><sub>h</sub> is representable in <img src="images/ncg_goldberg116.gif" height="16" width="39">
 digits. </font>
  <dt> <a name="1249"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To deal with <em>x</em><sub>l</sub>, scale <em>x</em> to be an integer satisfying <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>p</em></sup><sup> - 1</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>p</em></sup> - 1. Let <img src="images/ncg_goldberg307.gif" height="19" width="63">
 where <img src="images/ncg_goldberg4.gif" height="19" width="15">
 is the <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> high order digits of <em>x</em>, and <img src="images/ncg_goldberg9.gif" height="19" width="13">
 is the <font face="Arial,Helvetica"><em>k</em></font> low order digits. There are three cases to consider. If <img src="images/ncg_goldberg14.gif" height="21" width="85">
, then rounding <em>x</em> to <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> places is the same as chopping and <img src="images/ncg_goldberg20.gif" height="19" width="46">
, and <img src="images/ncg_goldberg25.gif" height="19" width="41">
. Since <img src="images/ncg_goldberg31.gif" height="19" width="13">
 has at most <font face="Arial,Helvetica"><em>k</em></font> digits, if p is even, then <img src="images/ncg_goldberg34.gif" height="19" width="13">
 has at most k = <img src="images/ncg_goldberg129.gif" height="16" width="39">
=<img src="images/ncg_goldberg121.gif" height="16" width="39">
<font  face="Verdana, Arial, Helvetica, sans-serif"> </font>digits. Otherwise, <img src="chars/beta.gif"> = 2 and <img src="images/ncg_goldberg39.gif" height="21" width="54">
 is representable with <font face="Arial,Helvetica"><em>k</em></font> - 1 <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <img src="images/ncg_goldberg125.gif" height="16" width="39">
 significant bits. The second case is when <img src="images/ncg_goldberg44.gif" height="18" width="82">
, and then computing <em>x</em><sub>h</sub> involves rounding up, so <em>x</em><sub>h</sub> = <img src="images/ncg_goldberg49.gif" height="19" width="15">
 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>, and <em>x</em><sub>l</sub>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>x</em></font><sub>h</sub>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;-&nbsp;<img src="images/ncg_goldberg54.gif" height="19" width="15">
<font  face="Verdana, Arial, Helvetica, sans-serif">-<img src="chars/beta.gif"></font><sup>k</sup> = <img src="images/ncg_goldberg59.gif" height="19" width="13">
 - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>. Once again, <img src="images/ncg_goldberg64.gif" height="19" width="13">
 has at most <font face="Arial,Helvetica"><em>k</em></font> digits, so is representable with <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakltbt.gif"></font>p/2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakrtbt.gif"> </font> digits. Finally, if <img src="images/ncg_goldberg68.gif" height="19" width="13">
 = (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><sup> - 1</sup>, then <em>x</em><sub>h</sub> = <img src="images/ncg_goldberg73.gif" height="19" width="15">
 or <img src="images/ncg_goldberg77.gif" height="19" width="15">
&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup> depending on whether there is a round up. So <em>x</em><sub>l</sub> is either (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><sup> - 1</sup> or (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><sup>&nbsp;-&nbsp;1</sup>&nbsp;-&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>&nbsp;=&nbsp;-<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>k</sup>/2, both of which are represented with 1 digit. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</dl>

<p>
  <a name="1250"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Theorem 6 gives a way to express the product of two working precision numbers exactly as a sum. There is a companion formula for expressing a sum exactly. If |<font face="Arial,Helvetica"><em>x</em></font>|<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> |<font face="Arial,Helvetica"><em>y</em></font>| then <em>x</em> + <font face="Arial,Helvetica"><em>y</em></font> = (<font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>) + (<font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg266.gif" height="15" width="13">
 (<font face="Arial,Helvetica"><em>x</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font>)) <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>y</em></font> [Dekker 1971; Knuth 1981, Theorem C in section 4.2.2]. However, when using exactly rounded operations, this formula is only true for <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 2, and not for <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10 as the example <em>x</em>&nbsp;=&nbsp;.99998, <em>y</em>&nbsp;=&nbsp;.99997 shows. </font>
</p>


<h3>
  <a name="1251"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Binary to Decimal Conversion </font>
</h3>


<p>
  <a name="1252"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since single precision has <em>p</em> = 24, and 2<sup>24</sup> &lt; 10<sup>8</sup>, you might expect that converting a binary number to 8 decimal digits would be sufficient to recover the original binary number. However, this is not the case. </font>
</p>


<h4>
  <a name="1253"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 15</font>
</h4>

<dl>
  <dt> <a name="1254"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>When a binary IEEE single precision number is converted to the closest eight digit decimal number, it is not always possible to uniquely recover the binary number from the decimal one. However, if nine decimal digits are used, then converting the decimal number to the closest binary number will recover the original floating-point number.</em> </font>
</dl>

<h4>
  <a name="1255"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1256"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Binary single precision numbers lying in the half open interval [10<sup>3</sup>, 2<sup>10</sup>) = [1000,&nbsp;1024) have 10 bits to the left of the binary point, and 14 bits to the right of the binary point. Thus there are (2<sup>10</sup> - 10<sup>3</sup>)2<sup>14</sup> = 393,216 different binary numbers in that interval. If decimal numbers are represented with 8 digits, then there are (2<sup>10</sup>&nbsp;-&nbsp;10<sup>3</sup>)10<sup>4</sup> = 240,000 decimal numbers in the same interval. There is no way that 240,000 decimal numbers could represent 393,216 different binary numbers. So 8 decimal digits are not enough to uniquely represent each single precision binary number. </font>
  <dt> <a name="1257"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To show that 9 digits are sufficient, it is enough to show that the spacing between binary numbers is always greater than the spacing between decimal numbers. This will ensure that for each decimal number <font face="Arial,Helvetica"><em>N</em></font>, the interval </font>
</dl>

<a name="10951"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">[<font face="Arial,Helvetica"><em>N</em></font> - <img src="images/ncg_goldberg83.gif" height="31" width="10">
ulp, <font face="Arial,Helvetica"><em>N</em></font> + <img src="images/ncg_goldberg88.gif" height="31" width="10">
ulp] <br></font>

<dl>
  <dt> <a name="10952"> </a><font face="Verdana, Arial, Helvetica, sans-serif">contains at most one binary number. Thus each binary number rounds to a unique decimal number which in turn rounds to a unique binary number. </font>
  <dt> <a name="1258"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To show that the spacing between binary numbers is always greater than the spacing between decimal numbers, consider an interval [10<sup><em>n</em></sup>, 10<sup><em>n</em></sup><sup> + 1</sup>]. On this interval, the spacing between consecutive decimal numbers is 10<sup>(</sup><sup><em>n</em></sup><sup>&nbsp;+&nbsp;1)&nbsp;-&nbsp;9</sup>. On [10<sup><em>n</em></sup>, 2<sup><em>m</em></sup>], where <font face="Arial,Helvetica"><em>m</em></font> is the smallest integer so that 10<sup>n</sup> &lt; 2<sup><em>m</em></sup>, the spacing of binary numbers is 2<sup><em>m</em></sup><sup> - 24</sup>, and the spacing gets larger further on in the interval. Thus it is enough to check that 10<sup>(</sup><sup><em>n</em></sup><sup>&nbsp;+&nbsp;1)&nbsp;-&nbsp;9</sup> &lt; 2<sup><em>m</em></sup><sup> - 24</sup>. But in fact, since 10<sup><em>n</em></sup> &lt; 2<sup><em>m</em></sup>, then 10<sup>(</sup><sup><em>n</em></sup><sup>&nbsp;+&nbsp;1)&nbsp;-&nbsp;9</sup> = 10<sup><em>n</em></sup>10<sup>-8</sup> &lt; 2<sup><em>m</em></sup>10<sup>-8</sup> &lt; 2<sup><em>m</em></sup>2<sup>-24</sup>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</dl>

<p>
  <a name="1259"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The same argument applied to double precision shows that 17 decimal digits are required to recover a double precision number. </font>
</p>


<p>
  <a name="1260"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Binary-decimal conversion also provides another example of the use of flags. Recall from the section <a href="ncg_goldberg.html#810">Precision</a>, that to recover a binary number from its decimal expansion, the decimal to binary conversion must be computed exactly. That conversion is performed by multiplying the quantities <font face="Arial,Helvetica"><em>N</em></font> and 10<sup>|</sup><sup><em>P</em></sup><sup>|</sup> (which are both exact if <em>p</em> &lt; 13) in single-extended precision and then rounding this to single precision (or dividing if <em>p</em> &lt; 0; both cases are similar). Of course the computation of <font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup> cannot be exact; it is the combined operation round(<font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>) that must be exact, where the rounding is from single-extended to single precision. To see why it might fail to be exact, take the simple case of <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font> = 10, <em>p</em> = 2 for single, and <em>p</em> = 3 for single-extended. If the product is to be 12.51, then this would be rounded to 12.5 as part of the single-extended multiply operation. Rounding to single precision would give 12. But that answer is not correct, because rounding the product to single precision should give 13. The error is due to double rounding. </font>
</p>


<p>
  <a name="1261"> </a><font face="Verdana, Arial, Helvetica, sans-serif">By using the IEEE flags, double rounding can be avoided as follows. Save the current value of the inexact flag, and then reset it. Set the rounding mode to round-to-zero. Then perform the multiplication <font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>. Store the new value of the inexact flag in <code>ixflag</code>, and restore the rounding mode and inexact flag. If <code>ixflag</code> is 0, then <font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup> is exact, so round(<font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>) will be correct down to the last bit. If <code>ixflag</code> is 1, then some digits were truncated, since round-to-zero always truncates. The significand of the product will look like 1<font face="Arial,Helvetica"><em>.b</em></font><sub>1</sub><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>b</em></font><sub>22</sub><font face="Arial,Helvetica"><em>b</em></font><sub>23</sub><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>b</em></font><sub>31</sub>. A double rounding error may occur if <font face="Arial,Helvetica"><em>b</em></font><sub>23</sub> <font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>b</em></font><sub>31</sub> = 10<font  face="Verdana, Arial, Helvetica, sans-serif">...</font>0. A simple way to account for both cases is to perform a logical <code>OR</code> of <code>ixflag</code> with <font face="Arial,Helvetica"><em>b</em></font><sub>31</sub>. Then round(<font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> &#183; </font>10<sup>|</sup><sup><em>P</em></sup><sup>|</sup>) will be computed correctly in all cases. </font>
</p>


<h3>
  <a name="1262"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Errors In Summation </font>
</h3>


<p>
  <a name="1263"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The section <a href="ncg_goldberg.html#1070">Optimizers</a>, mentioned the problem of accurately computing very long sums. The simplest approach to improving accuracy is to double the precision. To get a rough estimate of how much doubling the precision improves the accuracy of a sum, let <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub> = <font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>, <font face="Arial,Helvetica"><em>s</em></font><sub>2</sub>&nbsp;=&nbsp;<font face="Arial,Helvetica"><em>s</em></font><sub>1</sub>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circplus.gif"></font>&nbsp;<font face="Arial,Helvetica"><em>x</em></font><sub>2</sub><font  face="Verdana, Arial, Helvetica, sans-serif">...</font>, <font face="Arial,Helvetica"><em>s</em></font><sub>i</sub> = <font face="Arial,Helvetica"><em>s</em></font><sub>i</sub> - 1<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circplus.gif"></font> <font face="Arial,Helvetica"><em>x</em></font><sub>i</sub>. Then <font face="Arial,Helvetica"><em>s</em></font><sub>i</sub>&nbsp;=&nbsp;(1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i</em></sub>) (<font face="Arial,Helvetica"><em>s</em></font><sub>i - 1</sub> + <font face="Arial,Helvetica"><em>x</em></font><sub>i</sub>), where <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakmidl.gif"><img src="chars/delta.gif"></font><sub><em>i</em></sub><img src="chars/brakmidl.gif"> <img src="chars/lt_equal.gif"> <img src="chars/epsilon.gif">, and ignoring second order terms in <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i</em></sub> gives </font>
</p>


<p>
  <a name="10963"> </a><font face="Verdana, Arial, Helvetica, sans-serif"></font>
</p>


<a name="1264"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(31) <img src="images/ncg_goldberg92.gif" height="47" width="272">
<br></font>


<p>
  <a name="1265"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The first equality of <a href="ncg_goldberg.html#1264">(31)</a> shows that the computed value of <img src="images/ncg_goldberg98.gif" height="19" width="22">
 is the same as if an exact summation was performed on perturbed values of <em>x</em><sub>j</sub>. The first term <em>x</em><sub>1</sub> is perturbed by <font face="Arial,Helvetica"><em>n</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>, the last term <em>x</em><sub>n</sub> by only <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. The second equality in <a href="ncg_goldberg.html#1264">(31)</a> shows that error term is bounded by <img src="images/ncg_goldberg102.gif" height="19" width="41">
. Doubling the precision has the effect of squaring <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. If the sum is being done in an IEEE double precision format, 1/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/approx.gif"></font> 10<sup>16</sup>, so that <img src="images/ncg_goldberg108.gif" height="16" width="35">
 for any reasonable value of <font face="Arial,Helvetica"><em>n</em></font>. Thus, doubling the precision takes the maximum perturbation of <font face="Arial,Helvetica"><em>n</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> and changes it to <img src="images/ncg_goldberg111.gif" height="18" width="40">
. Thus the 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> error bound for the Kahan summation formula (Theorem 8) is not as good as using double precision, even though it is much better than single precision. </font>
</p>


<p>
  <a name="1266"> </a><font face="Verdana, Arial, Helvetica, sans-serif">For an intuitive explanation of why the Kahan summation formula works, consider the following diagram of the procedure. </font>
</p>


<a name="1282"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/ncg_goldberg117.gif" height="297" width="700">
<br></font>


<p>
  <a name="1283"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Each time a summand is added, there is a correction factor <font face="Arial,Helvetica"><em>C</em></font> which will be applied on the next loop. So first subtract the correction <font face="Arial,Helvetica"><em>C</em></font> computed in the previous loop from <font face="Arial,Helvetica"><em>X</em></font><sub>j</sub>, giving the corrected summand <em>Y</em>. Then add this summand to the running sum <font face="Arial,Helvetica"><em>S</em></font>. The low order bits of <em>Y</em> (namely <em>Y</em><sub>l</sub>) are lost in the sum. Next compute the high order bits of <em>Y</em> by computing <font face="Arial,Helvetica"><em>T</em></font> - <font face="Arial,Helvetica"><em>S</em></font>. When <em>Y</em> is subtracted from this, the low order bits of <em>Y</em> will be recovered. These are the bits that were lost in the first sum in the diagram. They become the correction factor for the next loop. A formal proof of Theorem 8, taken from Knuth [1981] page 572, appears in the section <a href="ncg_goldberg.html#1324">Theorem 14 and Theorem 8</a>." </font>
</p>


<h2>
  <a name="1284"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Summary </font>
</h2>


<p>
  <a name="1285"> </a><font face="Verdana, Arial, Helvetica, sans-serif">It is not uncommon for computer system designers to neglect the parts of a system related to floating-point. This is probably due to the fact that floating-point is given very little (if any) attention in the computer science curriculum. This in turn has caused the apparently widespread belief that floating-point is not a quantifiable subject, and so there is little point in fussing over the details of hardware and software that deal with it. </font>
</p>


<p>
  <a name="1286"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This paper has demonstrated that it is possible to reason rigorously about floating-point. For example, floating-point algorithms involving cancellation can be proven to have small relative errors if the underlying hardware has a guard digit, and there is an efficient algorithm for binary-decimal conversion that can be proven to be invertible, provided that extended precision is supported. The task of constructing reliable floating-point software is made much easier when the underlying computer system is supportive of floating-point. In addition to the two examples just mentioned (guard digits and extended precision), the section <a href="ncg_goldberg.html#1015">Systems Aspects</a> of this paper has examples ranging from instruction set design to compiler optimization illustrating how to better support floating-point. </font>
</p>


<p>
  <a name="1287"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The increasing acceptance of the IEEE floating-point standard means that codes that utilize features of the standard are becoming ever more portable. The section <a href="ncg_goldberg.html#799">The IEEE Standard</a>, gave numerous examples illustrating how the features of the IEEE standard can be used in writing practical floating-point codes. </font>
</p>


<h2>
  <a name="1288"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Acknowledgments </font>
</h2>


<p>
  <a name="1289"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This article was inspired by a course given by W. Kahan at Sun Microsystems from May through July of 1988, which was very ably organized by David Hough of Sun. My hope is to enable others to learn about the interaction of floating-point and computer systems without having to get up in time to attend 8:00 a.m. lectures. Thanks are due to Kahan and many of my colleagues at Xerox PARC (especially John Gilbert) for reading drafts of this paper and providing many useful comments. Reviews from Paul Hilfinger and an anonymous referee also helped improve the presentation. </font>
</p>


<h2>
  <a name="1290"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">References </font>
</h2>


<p>
  <a name="1291"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Aho, Alfred V., Sethi, R., and Ullman J. D. 1986. <em>Compilers: Principles, Techniques and Tools</em>, Addison-Wesley, Reading, MA. </font>
</p>


<p>
  <a name="1292"> </a><font face="Verdana, Arial, Helvetica, sans-serif">ANSI 1978. <em>American National Standard Programming Language FORTRAN</em>, ANSI Standard X3.9-1978, American National Standards Institute, New York, NY. </font>
</p>


<p>
  <a name="1293"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Barnett, David 1987. <em>A Portable Floating-Point Environment</em>, unpublished manuscript. </font>
</p>


<p>
  <a name="1294"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Brown, W. S. 1981. <em>A Simple but Realistic Model of Floating-Point Computation</em>, ACM Trans. on Math. Software 7(4), pp. 445-480. </font>
</p>


<p>
  <a name="1295"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Cody, W. J et. al. 1984. <em>A Proposed Radix- and Word-length-independent Standard for Floating-point Arithmetic</em>, IEEE Micro 4(4), pp. 86-100. </font>
</p>


<p>
  <a name="1296"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Cody, W. J. 1988. <em>Floating-Point Standards -- Theory and Practice</em>, in "Reliability in Computing: the role of interval methods in scientific computing", ed. by Ramon E. Moore, pp. 99-107, Academic Press, Boston, MA. </font>
</p>


<p>
  <a name="1297"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Coonen, Jerome 1984. <em>Contributions to a Proposed Standard for Binary Floating-Point Arithmetic</em>, PhD Thesis, Univ. of California, Berkeley. </font>
</p>


<p>
  <a name="1298"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Dekker, T. J. 1971. <em>A Floating-Point Technique for Extending the Available Precision</em>, Numer. Math. 18(3), pp. 224-242. </font>
</p>


<p>
  <a name="1299"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Demmel, James 1984. <em>Underflow and the Reliability of Numerical Software</em>, SIAM J. Sci. Stat. Comput. 5(4), pp. 887-919. </font>
</p>


<p>
  <a name="1300"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Farnum, Charles 1988. <em>Compiler Support for Floating-point Computation</em>, Software-Practice and Experience, 18(7), pp. 701-709. </font>
</p>


<p>
  <a name="1301"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Forsythe, G. E. and Moler, C. B. 1967. <em>Computer Solution of Linear Algebraic Systems</em>, Prentice-Hall, Englewood Cliffs, NJ.</font>
</p>


<p>
  <a name="1302"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Goldberg, I. Bennett 1967. <em>27 Bits Are Not Enough for 8-Digit Accuracy</em>, Comm. of the ACM. 10(2), pp 105-106.</font>
</p>


<p>
  <a name="1303"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Goldberg, David 1990. <em>Computer Arithmetic</em>, in "Computer Architecture: A Quantitative Approach", by David Patterson and John L. Hennessy, Appendix A, Morgan Kaufmann, Los Altos, CA. </font>
</p>


<p>
  <a name="1304"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Golub, Gene H. and Van Loan, Charles F. 1989. <em>Matrix Computations</em>, 2nd edition,The Johns Hopkins University Press, Baltimore Maryland. </font>
</p>


<p>
  <a name="1305"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Graham, Ronald L. , Knuth, Donald E. and Patashnik, Oren. 1989. <em>Concrete Mathematics, </em>Addison-Wesley, Reading, MA, p.162.</font>
</p>


<p>
  <a name="1306"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Hewlett Packard 1982. <em>HP-15C Advanced Functions Handbook</em>.</font>
</p>


<p>
  <a name="1307"> </a><font face="Verdana, Arial, Helvetica, sans-serif">IEEE 1987. <em>IEEE Standard 754-1985 for Binary Floating-point Arithmetic</em>, IEEE, (1985). Reprinted in SIGPLAN 22(2) pp. 9-25.</font>
</p>


<p>
  <a name="1308"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. 1972. <em>A Survey Of Error Analysis</em>, in Information Processing 71, Vol 2, pp. 1214 - 1239 (Ljubljana, Yugoslavia), North Holland, Amsterdam.</font>
</p>


<p>
  <a name="1309"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. 1986. <em>Calculating Area and Angle of a Needle-like Triangle</em>, unpublished manuscript. </font>
</p>


<p>
  <a name="1310"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. 1987. <em>Branch Cuts for Complex Elementary Functions</em>, in "The State of the Art in Numerical Analysis", ed. by M.J.D. Powell and A. Iserles (Univ of Birmingham, England), Chapter 7, Oxford University Press, New York. </font>
</p>


<p>
  <a name="1311"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. 1988. Unpublished lectures given at Sun Microsystems, Mountain View, CA.</font>
</p>


<p>
  <a name="1312"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. and Coonen, Jerome T. 1982. <em>The Near Orthogonality of Syntax, Semantics, and Diagnostics in Numerical Programming Environments</em>, in "The Relationship Between Numerical Computation And Programming Languages", ed. by J. K. Reid, pp. 103-115, North-Holland, Amsterdam. </font>
</p>


<p>
  <a name="1313"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kahan, W. and LeBlanc, E. 1985. <em>Anomalies in the IBM Acrith Package</em>, Proc. 7th IEEE Symposium on Computer Arithmetic (Urbana, Illinois), pp. 322-331. </font>
</p>


<p>
  <a name="1314"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kernighan, Brian W. and Ritchie, Dennis M. 1978. <em>The C Programming Language</em>, Prentice-Hall, Englewood Cliffs, NJ.</font>
</p>


<p>
  <a name="1315"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kirchner, R. and Kulisch, U. 1987. <em>Arithmetic for Vector Processors</em>, Proc. 8th IEEE Symposium on Computer Arithmetic (Como, Italy), pp. 256-269. </font>
</p>


<p>
  <a name="1316"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Knuth, Donald E., 1981. <em>The Art of Computer Programming, Volume II</em>, Second Edition, Addison-Wesley, Reading, MA. </font>
</p>


<p>
  <a name="1317"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Kulisch, U. W., and Miranker, W. L. 1986. <em>The Arithmetic of the Digital Computer: A New Approach</em>, SIAM Review 28(1), pp 1-36.</font>
</p>


<p>
  <a name="1318"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Matula, D. W. and Kornerup, P. 1985. <em>Finite Precision Rational Arithmetic: Slash Number Systems</em>, IEEE Trans. on Comput. C-34(1), pp 3-18. </font>
</p>


<p>
  <a name="1319"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Nelson, G. 1991. <em>Systems Programming With Modula-3</em>, Prentice-Hall, Englewood Cliffs, NJ. </font>
</p>


<p>
  <a name="1320"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Reiser, John F. and Knuth, Donald E. 1975. <em>Evading the Drift in Floating-point Addition</em>, Information Processing Letters 3(3), pp 84-87. </font>
</p>


<p>
  <a name="1321"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Sterbenz, Pat H. 1974. <em>Floating-Point Computation</em>, Prentice-Hall, Englewood Cliffs, NJ. </font>
</p>


<p>
  <a name="1322"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Swartzlander, Earl E. and Alexopoulos, Aristides G. 1975. <em>The Sign/Logarithm Number System</em>, IEEE Trans. Comput. C-24(12), pp. 1238-1242.</font>
</p>


<p>
  <a name="1323"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Walther, J. S., 1971. <em>A unified algorithm for elementary functions</em>, Proceedings of the AFIP Spring Joint Computer Conf. 38, pp. 379-385. </font>
</p>


<h2>
  <a name="1324"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 14 and Theorem 8 </font>
</h2>


<p>
  <a name="1325"> </a><font face="Verdana, Arial, Helvetica, sans-serif">This section contains two of the more technical proofs that were omitted from the text. </font>
</p>


<h3>
  <a name="1326"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 14</font>
</h3>

<dl>
  <dt> <a name="1327"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Let </em>0<em> &lt; k &lt; p, and set m = </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><em> + </em>1<em>, and assume that floating-point operations are exactly rounded. Then </em>(<em>m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> x</em>)<em> </em><img src="images/ncg_goldberg276.gif" height="15" width="13">
<em> </em>(<em>m </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> x </em><img src="images/ncg_goldberg287.gif" height="15" width="13">
<em> x</em>)<em> is exactly equal to x rounded to p&nbsp;-&nbsp;k significant digits. More precisely, x is rounded by taking the significand of x, imagining a radix point just left of the k least significant digits, and rounding to an integer.</em></font>
</dl>

<h3>
  <a name="1328"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h3>

<dl>
  <dt> <a name="1329"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The proof breaks up into two cases, depending on whether or not the computation of <font face="Arial,Helvetica"><em>mx</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>x</em></font> has a carry-out or not. </font>
  <dt> <a name="1162"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Assume there is no carry out. It is harmless to scale <em>x</em> so that it is an integer. Then the computation of <font face="Arial,Helvetica"><em>mx</em></font> = <font face="Arial,Helvetica"><em>x</em></font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> looks like this: </font>
  <dl>
     <dt> <a name="1165"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><code>	 aa...aabb...bb<br>+	 </code><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">aa...aabb...bb<br></font><code>	 zz...zzbb...bb</code></font>
  </dl>
  <dt> <a name="12191"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where <em>x</em> has been partitioned into two parts. The low order <font face="Arial,Helvetica"><em>k</em></font> digits are marked <code>b</code> and the high order <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> digits are marked <code>a</code>. To compute <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> from <font face="Arial,Helvetica"><em>mx </em></font>involves rounding off the low order <font face="Arial,Helvetica"><em>k</em></font> digits (the ones marked with <code>b</code>) so </font>
</dl>

<a name="12192"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(32) <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> = <font face="Arial,Helvetica"><em>mx</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + r<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>k</sup><br></font>

<dl>
  <dt> <a name="12196"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The value of <font face="Arial,Helvetica"><em>r</em></font> is 1 if <code>.bb...b</code> is greater than <img src="images/ncg_goldberg30.gif" height="22" width="8">
 and 0 otherwise. More precisely</font>
</dl>

<a name="12201"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(33) <font face="Arial,Helvetica"><em>r</em></font>&nbsp;=&nbsp;1 if <code>a.bb...b</code> rounds to <font face="Arial,Helvetica"><em>a</em></font> + 1, <font face="Arial,Helvetica"><em>r</em></font> = 0 otherwise. <br></font>

<dl>
  <dt> <a name="1334"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Next compute <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> = <font face="Arial,Helvetica"><em>mx</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font face="Arial,Helvetica"><em>r</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup> - <font face="Arial,Helvetica"><em>x</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>r</em></font>) - <font face="Arial,Helvetica"><em>x </em></font>mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>). The picture below shows the computation of <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> rounded, that is, (<font face="Arial,Helvetica"><em>m</em></font>&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg296.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>x</em></font>. The top line is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>r</em></font>), where <code>B</code> is the digit that results from adding <code>r</code> to the lowest order digit <code>b</code>.</font>
  <dl>
     <dt> <a name="9755"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><code>	 aa...aabb...bB00...00<br>-	 </code><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">bb...bb            <br></font><code>	 zz...     zzZ00...00</code></font>
  </dl>
  <dt> <a name="11025"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <code>.bb...b</code> &lt; <img src="images/ncg_goldberg235.gif" height="22" width="8">
 then <font face="Arial,Helvetica"><em>r</em></font> = 0, subtracting causes a borrow from the digit marked <code>B</code>, but the difference is rounded up, and so the net effect is that the rounded difference equals the top line, which is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font>. If <code>.bb...b</code> &gt; <img src="images/ncg_goldberg202.gif" height="22" width="8">
 then <font face="Arial,Helvetica"><em>r</em></font>&nbsp;=&nbsp;1, and 1 is subtracted from <code>B</code> because of the borrow, so the result is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font>. Finally consider the case <code>.bb...b</code>&nbsp;= <img src="images/ncg_goldberg205.gif" height="22" width="8">
. If <font face="Arial,Helvetica"><em>r</em></font> = 0 then <code>B</code> is even, <code>Z</code> is odd, and the difference is rounded up, giving <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font>. Similarly when <font face="Arial,Helvetica"><em>r</em></font> = 1, <code>B</code> is odd, <code>Z</code> is even, the difference is rounded down, so again the difference is <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font>. To summarize </font>
</dl>

<a name="1337"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(34) (<font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg306.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>x</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> <br></font>

<dl>
  <dt> <a name="1338"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Combining equations <a href="ncg_goldberg.html#12192">(32)</a> and <a href="ncg_goldberg.html#1337">(34)</a> gives (<font face="Arial,Helvetica"><em>m</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) - (<font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg8.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>x</em></font>) = <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/rho.gif">&#183;<img src="chars/beta.gif"></font><sup><em>k</em></sup>. The result of performing this computation is </font>
  <dl>
     <dt> <a name="9823"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><code>	 r00...00<br>       + aa...aabb...bb<br>       - </code><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">      bb...bb<br></font><code>         aa...aA00...00</code></font>
  </dl>
  <dt> <a name="1340"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The rule for computing <font face="Arial,Helvetica"><em>r</em></font>, equation (33), is the same as the rule for rounding <code>a...</code><font  face="Verdana, Arial, Helvetica, sans-serif"> </font><code>ab...b</code> to <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> places. Thus computing <font face="Arial,Helvetica"><em>mx</em></font> - (<font face="Arial,Helvetica"><em>mx</em></font> - <font face="Arial,Helvetica"><em>x</em></font>) in floating-point arithmetic precision is exactly equal to rounding <em>x</em> to <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> places, in the case when <em>x</em> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>k</sup><font face="Arial,Helvetica"><em>x</em></font> does not carry out. </font>
  <dt> <a name="1341"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <em>x</em> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> does carry out, then <font face="Arial,Helvetica"><em>mx</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>x</em></font> looks like this: </font>
  <dl>
     <dt> <a name="9798"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><code>	 aa...aabb...bb<br>+	 </code><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">aa...aabb...bb<br></font><code>	 zz...zZbb...bb</code></font>
  </dl>
  <dt> <a name="9799"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Thus, <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> = <font face="Arial,Helvetica"><em>mx</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>, where <font face="Arial,Helvetica"><em>w</em></font> = -<font face="Arial,Helvetica"><em>Z</em></font> if <font face="Arial,Helvetica"><em>Z</em></font> &lt; <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font>/2, but the exact value of <font face="Arial,Helvetica"><em>w</em></font> is unimportant. Next, <font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>. In a picture </font>
  <dl>
     <dt> <a name="1196"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><code>	 aa...aabb...bb00...00<br>- 	  bb... bb<br>+  </code><font  size="3" face="Verdana, Arial, Helvetica, sans-serif">	 w                 <br></font><code>	  zz   ... zZbb ...bb<a href="#1343"><sup>31</sup></a></code></font>
  </dl>
  <dt> <a name="1344"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Rounding gives (<font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) <img src="images/ncg_goldberg19.gif" height="15" width="13">
 <font face="Arial,Helvetica"><em>x</em></font> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup> - <font face="Arial,Helvetica"><em>r</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>, where <font face="Arial,Helvetica"><em>r</em></font> = 1 if <code>.bb...b</code> &gt;&nbsp;<img src="images/ncg_goldberg257.gif" height="22" width="8">
 or if <code>.bb...b</code> = <img src="images/ncg_goldberg262.gif" height="22" width="8">
 and <font face="Arial,Helvetica"><em>b</em></font><sub>0</sub> = 1.<a href="#1345"><sup>32</sup></a> Finally, </font>
</dl>

<a name="12144"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">(<font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font>) - (<font face="Arial,Helvetica"><em>m</em></font> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <font face="Arial,Helvetica"><em>x</em></font> <img src="images/ncg_goldberg62.gif" height="15" width="13">
 x) = <font face="Arial,Helvetica"><em>mx</em></font>&nbsp;-&nbsp;<font face="Arial,Helvetica"><em>x</em></font>&nbsp;mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup>k</sup> - (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup> - <font face="Arial,Helvetica"><em>r</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>)<br>	 = <font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>x</em></font> mod(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>) + <font face="Arial,Helvetica"><em>r</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup>.<br></font>

<dl>
  <dt> <a name="12146"> </a><font face="Verdana, Arial, Helvetica, sans-serif">And once again, <font face="Arial,Helvetica"><em>r</em></font> = 1 exactly when rounding <code>a...ab...b</code> to <em>p</em> - <font face="Arial,Helvetica"><em>k</em></font> places involves rounding up. Thus Theorem 14 is proven in all cases. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</dl>

<h4>
  <a name="1346"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 8 (Kahan Summation Formula)</font>
</h4>

<dl>
  <dt> <a name="1347"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Suppose that <img src="images/ncg_goldberg268.gif" height="21" width="44">
 is computed using the following algorithm <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="1348"> </a>
<pre>S = X [1];
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1349"> </a>
<pre>C = 0;
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1350"> </a>
<pre>for j = 2 to N {
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1351"> </a>
<pre>Y = X [j] - C;
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1352"> </a>
<pre>   T = S + Y;
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1353"> </a>
<pre>   C = (T - S) - Y;
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1354"> </a>
<pre>   S = T;
</pre></td>
  </tr>
  <tr>
    <td>
<a name="1355"> </a>
<pre>}
</pre></td>
  </tr>
</table>


</p>
<br></font>
  <dt> <a name="1357"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>Then the computed sum </em><font face="Arial,Helvetica"><em>S</em></font><em> is equal to </em><font face="Arial,Helvetica"><em>S</em></font><em> = </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/capsigma.gif"> </font><em>x</em><sub>j</sub><em> (</em>1<em> + </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>j</em></sub><em>) + </em><font face="Arial,Helvetica"><em>O</em></font><em>(</em><font face="Arial,Helvetica"><em>N</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup><em>2</em></sup><em>) </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/capsigma.gif"> </font><em>|</em><font face="Arial,Helvetica"><em>x</em></font><sub>j</sub><em>|, where |</em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>j</em></sub><em>| </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font><em> </em>2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><em>.</em> </font>
</dl>

<h4>
  <a name="1358"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>

<dl>
  <dt> <a name="1359"> </a><font face="Verdana, Arial, Helvetica, sans-serif">First recall how the error estimate for the simple formula <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/capsigma.gif"></font> <font face="Arial,Helvetica"><em>x</em></font><sub>i</sub> went. Introduce <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub> = <font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>, <font face="Arial,Helvetica"><em>s</em></font><sub>i</sub> = (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i</em></sub>) (<font face="Arial,Helvetica"><em>s</em></font><sub>i - 1</sub> + <font face="Arial,Helvetica"><em>x</em></font><sub>i</sub>). Then the computed sum is <font face="Arial,Helvetica"><em>s</em></font><sub>n</sub>, which is a sum of terms, each of which is an <font face="Arial,Helvetica"><em>x</em></font><sub>i</sub> multiplied by an expression involving <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>j</em></sub>'s. The exact coefficient of <em>x</em><sub>1</sub> is (1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/delta.gif"></font><sub>2</sub>)(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>)<font  face="Verdana, Arial, Helvetica, sans-serif"> ...</font> (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>n</em></sub>), and so by renumbering, the coefficient of <em>x</em><sub>2</sub> must be (1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>3</sub>)(1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/delta.gif"></font><sub>4</sub>) <font  face="Verdana, Arial, Helvetica, sans-serif">...</font> (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub>n</sub>), and so on. The proof of Theorem 8 runs along exactly the same lines, only the coefficient of <em>x</em><sub>1</sub> is more complicated. In detail <font face="Arial,Helvetica"><em>s</em></font><sub>0</sub> = <font face="Arial,Helvetica"><em>c</em></font><sub>0</sub> = 0 and </font>
  <dl>
     <dt> <a name="1360"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>y</em></font><sub>k </sub><font face="Arial,Helvetica"><em>= x</em></font><sub>k</sub><font face="Arial,Helvetica"><em> </em></font><img src="images/ncg_goldberg33.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> c</em></font><sub>k - 1</sub><font face="Arial,Helvetica"><em> = </em></font>(<font face="Arial,Helvetica"><em>x</em></font><sub>k</sub><font face="Arial,Helvetica"><em> - c</em></font><sub>k - 1</sub>) (1<font face="Arial,Helvetica"><em> + </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>)<font face="Arial,Helvetica"><em> </em></font></font>
     <dt> <a name="9836"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>s</em></font><sub>k </sub><font face="Arial,Helvetica"><em>= s</em></font><sub>k - 1</sub><font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/circplus.gif"><img src="chars/approx.gif"></font><font face="Arial,Helvetica"><em> y</em></font><sub>k </sub><font face="Arial,Helvetica"><em>= </em></font>(<font face="Arial,Helvetica"><em>s</em></font><sub>k-1</sub><font face="Arial,Helvetica"><em> + y</em></font><sub>k</sub>) (1<font face="Arial,Helvetica"><em> + </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="9837"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>c</em></font><sub>k </sub><font face="Arial,Helvetica"><em>= </em></font>(<font face="Arial,Helvetica"><em>s</em></font><sub>k</sub><font face="Arial,Helvetica"><em> </em></font><img src="images/ncg_goldberg43.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> s</em></font><sub>k - 1</sub>)<font face="Arial,Helvetica"><em> </em></font><img src="images/ncg_goldberg53.gif" height="15" width="13">
<font face="Arial,Helvetica"><em> y</em></font><sub>k</sub><font face="Arial,Helvetica"><em>=</em></font> [(<font face="Arial,Helvetica"><em>s</em></font><sub>k</sub><font face="Arial,Helvetica"><em> - s</em></font><sub>k - 1</sub>) (1<font face="Arial,Helvetica"><em> + </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) -<font face="Arial,Helvetica"><em> y</em></font><sub>k</sub>] (1<font face="Arial,Helvetica"><em> + </em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>)</font>
  </dl>
  <dt> <a name="1361"> </a><font face="Verdana, Arial, Helvetica, sans-serif">where all the Greek letters are bounded by <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Although the coefficient of <em>x</em><sub>1</sub> in <font face="Arial,Helvetica"><em>s</em></font><sub>k</sub> is the ultimate expression of interest, in turns out to be easier to compute the coefficient of <em>x</em><sub>1</sub> in <font face="Arial,Helvetica"><em>s</em></font><sub>k</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k</sub> and <font face="Arial,Helvetica"><em>c</em></font><sub>k</sub>.</font>
  <dt> <a name="12151"> </a><font face="Verdana, Arial, Helvetica, sans-serif">When <font face="Arial,Helvetica"><em>k</em></font> = 1, </font>
  <dl>
     <dt> <a name="1176"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>c</em></font><sub>1</sub> 	 	 = (<font face="Arial,Helvetica"><em>s</em></font><sub>1</sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub>) - <font face="Arial,Helvetica"><em>y</em></font><sub>1</sub>) (1 + <font face="Arial,Helvetica"><em>d</em></font><sub>1</sub>)</font>
     <dt> <a name="9839"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = <font face="Arial,Helvetica"><em>y</em></font><sub>1</sub>((1 + <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub>) - 1) (1 + <font face="Arial,Helvetica"><em>d</em></font><sub>1</sub>) </font>
     <dt> <a name="9841"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = <font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>(<font face="Arial,Helvetica"><em>s</em></font><sub>1</sub> +<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub> + <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub><font face="Arial,Helvetica"><em>g</em></font><sub>1</sub>) (1 + <font face="Arial,Helvetica"><em>d</em></font><sub>1</sub>) (1 + <font face="Arial,Helvetica"><em>h</em></font><sub>1</sub>) </font>
     <dt> <a name="9843"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>s</em></font><sub>1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>1</sub> 	 	 = <font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>[(1 + <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub>) - (<font face="Arial,Helvetica"><em>s</em></font><sub>1</sub> + <font face="Arial,Helvetica"><em>g</em></font><sub>1</sub> + <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub><font face="Arial,Helvetica"><em>g</em></font><sub>1</sub>) (1 + <font face="Arial,Helvetica"><em>d</em></font><sub>1</sub>)](1 + <font face="Arial,Helvetica"><em>h</em></font><sub>1</sub>) </font>
     <dt> <a name="9844"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = <font face="Arial,Helvetica"><em>x</em></font><sub>1</sub>[1 - <font face="Arial,Helvetica"><em>g</em></font><sub>1</sub> - <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub><font face="Arial,Helvetica"><em>d</em></font><sub>1</sub> - <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub><font face="Arial,Helvetica"><em>g</em></font><sub>1</sub> - <font face="Arial,Helvetica"><em>d</em></font><sub>1</sub><font face="Arial,Helvetica"><em>g</em></font><sub>1</sub> - <font face="Arial,Helvetica"><em>s</em></font><sub>1</sub><font face="Arial,Helvetica"><em>g</em></font><sub>1</sub><font face="Arial,Helvetica"><em>d</em></font><sub>1</sub>](1 + <font face="Arial,Helvetica"><em>h</em></font><sub>1</sub>)</font>
  </dl>
  <dt> <a name="1363"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Calling the coefficients of <em>x</em><sub>1</sub> in these expressions <em>C</em><sub>k</sub> and <font face="Arial,Helvetica"><em>S</em></font><sub>k</sub> respectively, then</font>
</dl>

<a name="1364"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>C</em></font><sub>1 </sub>= 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>) <br></font>


<a name="9846"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>S</em></font><sub>1 </sub>= + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub> + 4<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>3</sup>) <br></font>

<dl>
  <dt> <a name="12242"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To get the general formula for <font face="Arial,Helvetica"><em>S</em></font><sub>k</sub> and <em>C</em><sub>k</sub>, expand the definitions of <font face="Arial,Helvetica"><em>s</em></font><sub>k</sub> and <font face="Arial,Helvetica"><em>c</em></font><sub>k</sub>, ignoring all terms involving <em>x</em><sub>i</sub> with <font face="Arial,Helvetica"><em>i</em></font> &gt; 1 to get </font>
  <dl>
     <dt> <a name="12243"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>s</em></font><sub>k 	 	 </sub>= (<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> + <font face="Arial,Helvetica"><em>y</em></font><sub>k</sub>)(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="12244"> </a><font face="Verdana, Arial, Helvetica, sans-serif"> 	 	 = [<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> + (<font face="Arial,Helvetica"><em>x</em></font><sub>k</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>)](1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="5718"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = [(<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub><font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>](1+<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="5719"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>c</em></font><sub>k	 	 </sub>= [{<font face="Arial,Helvetica"><em>s</em></font><sub>k</sub> - <font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub>}(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) - <font face="Arial,Helvetica"><em>y</em></font><sub>k</sub>](1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="5720"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = [{((<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub><font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>)(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) - <font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub>}(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) + <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>)](1&nbsp;+&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="5721"> </a><font face="Verdana, Arial, Helvetica, sans-serif"> 	 	 = [{(<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>c<sub><em>k</em></sub><sub>-1</sub>(1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/sigma.gif"></font><sub><em>k</em></sub>) - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>}(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) + c<sub><em>k</em></sub><sub> - 1</sub>(1 +<font  face="Verdana, Arial, Helvetica, sans-serif"> <img src="chars/eta.gif"></font><sub><em>k</em></sub>)](1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="9847"> </a><font face="Verdana, Arial, Helvetica, sans-serif">	 	 = [(<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>))](1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>),</font>
     <dt> <a name="9848"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>s</em><sub>k</sub> - <em>c</em><sub>k	 	 </sub>= ((<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub><font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="9849"> </a><font face="Verdana, Arial, Helvetica, sans-serif">        	 	     - [(<font face="Arial,Helvetica"><em>s</em></font><sub>k - 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>)](1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>) </font>
     <dt> <a name="5725"> </a><font face="Verdana, Arial, Helvetica, sans-serif">     	 	  = (<font face="Arial,Helvetica"><em>s</em></font><sub>k- 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>)((1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>)(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>)) </font>
     <dt> <a name="5726"> </a><font face="Verdana, Arial, Helvetica, sans-serif">                    + <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>(-<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>) + (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>)) (1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>)) </font>
     <dt> <a name="5727"> </a><font face="Verdana, Arial, Helvetica, sans-serif">  	 	  = (<font face="Arial,Helvetica"><em>s</em></font><sub>- 1</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub>) (1 - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>)) </font>
     <dt> <a name="5728"> </a><font face="Verdana, Arial, Helvetica, sans-serif">           	 	     + <font face="Arial,Helvetica"><em>c</em></font><sub>k - 1</sub> -<font  face="Verdana, Arial, Helvetica, sans-serif"> [<img src="chars/eta.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>) + (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub><em>k</em></sub>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub>))<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>k</em></sub>]</font>
  </dl>
  <dt> <a name="1375"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Since <font face="Arial,Helvetica"><em>S</em></font><sub>k</sub> and <font face="Arial,Helvetica"><em>C</em></font><sub>k</sub> are only being computed up to order <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>, these formulas can be simplified to </font>
  <dl>
     <dt> <a name="1376"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>C</em></font><sub>k</sub>= (<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>))<font face="Arial,Helvetica"><em>S</em></font><sub>k - 1</sub> + (-<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub><em>k</em></sub> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>))<font face="Arial,Helvetica"><em>C</em></font><sub>k - 1</sub> </font>
     <dt> <a name="1384"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>S</em></font><sub>k</sub>= ((1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>3</sup>))<font face="Arial,Helvetica"><em>S</em></font><sub>k - 1</sub> + (2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/capomicr.gif"></font>(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>))<font face="Arial,Helvetica"><em>C</em></font><sub>k - 1</sub> </font>
  </dl>
  <dt> <a name="1387"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Using these formulas gives </font>
</dl>

<a name="1389"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>C</em></font><sub>2</sub> = <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub>2</sub> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>) <br></font>


<a name="1398"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>S</em></font><sub>2 </sub>= 1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub> + 10<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>3</sup>) <br></font>

<dl>
  <dt> <a name="1399"> </a><font face="Verdana, Arial, Helvetica, sans-serif">and in general it is easy to check by induction that </font>
</dl>

<a name="1400"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>C</em></font><sub>k </sub>= <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/sigma.gif"></font><sub><em>k</em></sub> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>) <br></font>


<a name="1401"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif"><font face="Arial,Helvetica"><em>S</em></font><sub>k </sub>= 1 + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub> + (4<sub><em>k</em></sub>+2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup> + O(<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>3</sup>) <br></font>


<p>
  <a name="1210"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, what is wanted is the coefficient of <em>x</em><sub>1</sub> in <font face="Arial,Helvetica"><em>s</em></font><sub>k</sub>. To get this value, let <em>x</em><sub>n&nbsp;+&nbsp;1</sub> = 0, let all the Greek letters with subscripts of <font face="Arial,Helvetica"><em>n</em></font> + 1 equal 0, and compute <font face="Arial,Helvetica"><em>s</em></font><sub>n + 1</sub>. Then <font face="Arial,Helvetica"><em>s</em></font><sub>n + 1</sub> =<font face="Arial,Helvetica"><em> s</em></font><sub>n</sub> - <font face="Arial,Helvetica"><em>c</em></font><sub>n</sub>, and the coefficient of <em>x</em><sub>1</sub> in <font face="Arial,Helvetica"><em>s</em></font><sub>n</sub> is less than the coefficient in <font face="Arial,Helvetica"><em>s</em></font><sub>n + 1</sub>, which is <font face="Arial,Helvetica"><em>S</em></font><sub>n</sub>&nbsp;=&nbsp;1&nbsp;+ <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/eta.gif"></font><sub>1</sub> - <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gamma.gif"></font><sub>1</sub> + (4<font face="Arial,Helvetica"><em>n</em></font> + 2)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup> = (1 + 2<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font> + <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/capomicr.gif"></font>(<font face="Arial,Helvetica"><em>n</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font><sup>2</sup>)). <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font></font>
</p>


<h2>
  <a name="3098"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Differences Among IEEE 754 Implementations</font>
</h2>


<p><hr noshade size="1">
  <a name="3099"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><b>Note &#150; </b>This section is not part of the published paper. It has been added to clarify certain points and correct possible misconceptions about the IEEE standard that the reader might infer from the paper. This material was not written by David Goldberg, but it appears here with his permission.</font>
<hr noshade size="1"></p>


<p>
  <a name="3093"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The preceding paper has shown that floating-point arithmetic must be implemented carefully, since programmers may depend on its properties for the correctness and accuracy of their programs. In particular, the IEEE standard requires a careful implementation, and it is possible to write useful programs that work correctly and deliver accurate results only on systems that conform to the standard. The reader might be tempted to conclude that such programs should be portable to all IEEE systems. Indeed, portable software would be easier to write if the remark "When a program is moved between two machines and both support IEEE arithmetic, then if any intermediate result differs, it must be because of software bugs, not from differences in arithmetic," were true.</font>
</p>


<p>
  <a name="3105"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Unfortunately, the IEEE standard does not guarantee that the same program will deliver identical results on all conforming systems. Most programs will actually produce different results on different systems for a variety of reasons. For one, most programs involve the conversion of numbers between decimal and binary formats, and the IEEE standard does not completely specify the accuracy with which such conversions must be performed. For another, many programs use elementary functions supplied by a system library, and the standard doesn't specify these functions at all. Of course, most programmers know that these features lie beyond the scope of the IEEE standard.</font>
</p>


<p>
  <a name="3663"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Many programmers may not realize that even a program that uses only the numeric formats and operations prescribed by the IEEE standard can compute different results on different systems. In fact, the authors of the standard intended to allow different implementations to obtain different results. Their intent is evident in the definition of the term <em>destination</em> in the IEEE 754 standard: "A destination may be either explicitly designated by the user or implicitly supplied by the system (for example, intermediate results in subexpressions or arguments for procedures). Some languages place the results of intermediate calculations in destinations beyond the user's control. Nonetheless, this standard defines the result of an operation in terms of that destination's format and the operands' values." (IEEE 754-1985, p. 7) In other words, the IEEE standard requires that each result be rounded correctly to the precision of the destination into which it will be placed, but the standard does not require that the precision of that destination be determined by a user's program. Thus, different systems may deliver their results to destinations with different precisions, causing the same program to produce different results (sometimes dramatically so), even though those systems all conform to the standard.</font>
</p>


<p>
  <a name="3756"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Several of the examples in the preceding paper depend on some knowledge of the way floating-point arithmetic is rounded. In order to rely on examples such as these, a programmer must be able to predict how a program will be interpreted, and in particular, on an IEEE system, what the precision of the destination of each arithmetic operation may be. Alas, the loophole in the IEEE standard's definition of <em>destination</em> undermines the programmer's ability to know how a program will be interpreted. Consequently, several of the examples given above, when implemented as apparently portable programs in a high-level language, may not work correctly on IEEE systems that normally deliver results to destinations with a different precision than the programmer expects. Other examples may work, but proving that they work may lie beyond the average programmer's ability.</font>
</p>


<p>
  <a name="3766"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In this section, we classify existing implementations of IEEE 754 arithmetic based on the precisions of the destination formats they normally use. We then review some examples from the paper to show that delivering results in a wider precision than a program expects can cause it to compute wrong results even though it is provably correct when the expected precision is used. We also revisit one of the proofs in the paper to illustrate the intellectual effort required to cope with unexpected precision even when it doesn't invalidate our programs. These examples show that despite all that the IEEE standard prescribes, the differences it allows among different implementations can prevent us from writing portable, efficient numerical software whose behavior we can accurately predict. To develop such software, then, we must first create programming languages and environments that limit the variability the IEEE standard permits and allow programmers to express the floating-point semantics upon which their programs depend.</font>
</p>


<h3>
  <a name="3164"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Current IEEE 754 Implementations</font>
</h3>


<p>
  <a name="3154"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Current implementations of IEEE 754 arithmetic can be divided into two groups distinguished by the degree to which they support different floating-point formats in hardware. <em>Extended-based</em> systems, exemplified by the Intel x86 family of processors, provide full support for an extended double precision format but only partial support for single and double precision: they provide instructions to load or store data in single and double precision, converting it on-the-fly to or from the extended double format, and they provide special modes (not the default) in which the results of arithmetic operations are rounded to single or double precision even though they are kept in registers in extended double format. (Motorola 68000 series processors round results to both the precision and range of the single or double formats in these modes. Intel x86 and compatible processors round results to the precision of the single or double formats but retain the same range as the extended double format.) <em>Single/double</em> systems, including most RISC processors, provide full support for single and double precision formats but no support for an IEEE-compliant extended double precision format. (The IBM POWER architecture provides only partial support for single precision, but for the purpose of this section, we classify it as a single/double system.)</font>
</p>


<p>
  <a name="3172"> </a><font face="Verdana, Arial, Helvetica, sans-serif">To see how a computation might behave differently on an extended-based system than on a single/double system, consider a C version of the example from the section <a href="ncg_goldberg.html#1015">Systems Aspects</a>: <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption ALIGN="left"><b><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"></font></b></caption>
  <tr>
    <td>
<a name="3169"> </a>
<pre>int main() {
</pre><a name="3183"> </a>
<pre>    double  q;
</pre><a name="3184"> </a>
<pre>
</pre><a name="3185"> </a>
<pre>    q = 3.0/7.0;
</pre><a name="3170"> </a>
<pre>    if (q == 3.0/7.0) printf("Equal\n");
</pre><a name="3171"> </a>
<pre>    else printf("Not Equal\n");
</pre><a name="3186"> </a>
<pre>    return 0;
</pre><a name="3187"> </a>
<pre>}
</pre></td>
  </tr>
</table>


</p>
<br></font>
</p>


<p>
  <a name="3165"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Here the constants 3.0 and 7.0 are interpreted as double precision floating-point numbers, and the expression 3.0/7.0 inherits the <code>double</code> data type. On a single/double system, the expression will be evaluated in double precision since that is the most efficient format to use. Thus, <code>q</code> will be assigned the value 3.0/7.0 rounded correctly to double precision. In the next line, the expression 3.0/7.0 will again be evaluated in double precision, and of course the result will be equal to the value just assigned to <code>q</code>, so the program will print "Equal" as expected.</font>
</p>


<p>
  <a name="3191"> </a><font face="Verdana, Arial, Helvetica, sans-serif">On an extended-based system, even though the expression 3.0/7.0 has type <code>double</code>, the quotient will be computed in a register in extended double format, and thus in the default mode, it will be rounded to extended double precision. When the resulting value is assigned to the variable <code>q</code>, however, it may then be stored in memory, and since <code>q</code> is declared <code>double</code>, the value will be rounded to double precision. In the next line, the expression 3.0/7.0 may again be evaluated in extended precision yielding a result that differs from the double precision value stored in <code>q</code>, causing the program to print "Not equal". Of course, other outcomes are possible, too: the compiler could decide to store and thus round the value of the expression 3.0/7.0 in the second line before comparing it with <code>q</code>, or it could keep <code>q</code> in a register in extended precision without storing it. An optimizing compiler might evaluate the expression 3.0/7.0 at compile time, perhaps in double precision or perhaps in extended double precision. (With one x86 compiler, the program prints "Equal" when compiled with optimization and "Not Equal" when compiled for debugging.) Finally, some compilers for extended-based systems automatically change the rounding precision mode to cause operations producing results in registers to round those results to single or double precision, albeit possibly with a wider range. Thus, on these systems, we can't predict the behavior of the program simply by reading its source code and applying a basic understanding of IEEE 754 arithmetic. Neither can we accuse the hardware or the compiler of failing to provide an IEEE 754 compliant environment; the hardware has delivered a correctly rounded result to each destination, as it is required to do, and the compiler has assigned some intermediate results to destinations that are beyond the user's control, as it is allowed to do.</font>
</p>


<h3>
  <a name="3377"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Pitfalls in Computations on Extended-Based Systems</font>
</h3>


<p>
  <a name="3201"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Conventional wisdom maintains that extended-based systems must produce results that are at least as accurate, if not more accurate than those delivered on single/double systems, since the former always provide at least as much precision and often more than the latter. Trivial examples such as the C program above as well as more subtle programs based on the examples discussed below show that this wisdom is naive at best: some apparently portable programs, which are indeed portable across single/double systems, deliver incorrect results on extended-based systems precisely because the compiler and hardware conspire to occasionally provide more precision than the program expects.</font>
</p>


<p>
  <a name="3212"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Current programming languages make it difficult for a program to specify the precision it expects. As the section <a href="ncg_goldberg.html#1043">Languages and Compilers</a> mentions, many programming languages don't specify that each occurrence of an expression like <code>10.0*x</code> in the same context should evaluate to the same value. Some languages, such as Ada, were influenced in this respect by variations among different arithmetics prior to the IEEE standard. More recently, languages like ANSI C have been influenced by standard-conforming extended-based systems. In fact, the ANSI C standard explicitly allows a compiler to evaluate a floating-point expression to a precision wider than that normally associated with its type. As a result, the value of the expression <code>10.0*x</code> may vary in ways that depend on a variety of factors: whether the expression is immediately assigned to a variable or appears as a subexpression in a larger expression; whether the expression participates in a comparison; whether the expression is passed as an argument to a function, and if so, whether the argument is passed by value or by reference; the current precision mode; the level of optimization at which the program was compiled; the precision mode and expression evaluation method used by the compiler when the program was compiled; and so on.</font>
</p>


<p>
  <a name="3258"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Language standards are not entirely to blame for the vagaries of expression evaluation. Extended-based systems run most efficiently when expressions are evaluated in extended precision registers whenever possible, yet values that must be stored are stored in the narrowest precision required. Constraining a language to require that <code>10.0*x</code> evaluate to the same value everywhere would impose a performance penalty on those systems. Unfortunately, allowing those systems to evaluate <code>10.0*x</code> differently in syntactically equivalent contexts imposes a penalty of its own on programmers of accurate numerical software by preventing them from relying on the syntax of their programs to express their intended semantics.</font>
</p>


<p>
  <a name="3784"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Do real programs depend on the assumption that a given expression always evaluates to the same value? Recall the algorithm presented in Theorem 4 for computing ln(1 +<em> x</em>), written here in Fortran: <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption align="left"><b></b></caption>
  <tr>
    <td><font face="Courier"><a name="3261"> </a>
<pre>real function log1p(x)
</pre><a name="3262"> </a>
<pre>real x
</pre><a name="3263"> </a>
<pre>if (1.0 + x .eq. 1.0) then
</pre><a name="3264"> </a>
<pre>   log1p = x
</pre><a name="3265"> </a>
<pre>else
</pre><a name="3266"> </a>
<pre>   log1p = log(1.0 + x) * x / ((1.0 + x) - 1.0)
</pre><a name="3267"> </a>
<pre>endif
</pre><a name="3268"> </a>
<pre>return
</pre></font></td>
  </tr>
</table>


</p>
</font>
</p>


<p>
  <a name="3215"> </a><font face="Verdana, Arial, Helvetica, sans-serif">On an extended-based system, a compiler may evaluate the expression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> in the third line in extended precision and compare the result with <code>1.0</code>. When the same expression is passed to the log function in the sixth line, however, the compiler may store its value in memory, rounding it to single precision. Thus, if <code>x</code> is not so small that <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> rounds to <code>1.0</code> in extended precision but small enough that <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> rounds to <code>1.0</code> in single precision, then the value returned by <code>log1p(x)</code> will be zero instead of <code>x</code>, and the relative error will be one--rather larger than 5<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/epsilon.gif"></font>. Similarly, suppose the rest of the expression in the sixth line, including the reoccurrence of the subexpression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code>, is evaluated in extended precision. In that case, if <code>x</code> is small but not quite small enough that <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> rounds to <code>1.0</code> in single precision, then the value returned by <code>log1p(x)</code> can exceed the correct value by nearly as much as <code>x</code>, and again the relative error can approach one. For a concrete example, take <code>x</code> to be 2<sup>-24</sup> + 2<sup>-47</sup>, so <code>x</code> is the smallest single precision number such that <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> rounds up to the next larger number, 1 + 2<sup>-23</sup>. Then <code>log(1.0</code>&nbsp;<code>+</code>&nbsp;<code>x)</code> is approximately 2<sup>-23</sup>. Because the denominator in the expression in the sixth line is evaluated in extended precision, it is computed exactly and delivers <code>x</code>, so <code>log1p(x)</code> returns approximately 2<sup>-23</sup>, which is nearly twice as large as the exact value. (This actually happens with at least one compiler. When the preceding code is compiled by the Sun WorkShop Compilers 4.2.1 Fortran 77 compiler for x86 systems using the <code>-O</code> optimization flag, the generated code computes <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> exactly as described. As a result, the function delivers zero for <code>log1p(1.0e-10)</code> and <code>1.19209E-07</code> for <code>log1p(5.97e-8)</code>.)</font>
</p>


<p>
  <a name="3858"> </a><font face="Verdana, Arial, Helvetica, sans-serif">For the algorithm of Theorem 4 to work correctly, the expression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> must be evaluated the same way each time it appears; the algorithm can fail on extended-based systems only when <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> is evaluated to extended double precision in one instance and to single or double precision in another. Of course, since <code>log</code> is a generic intrinsic function in Fortran, a compiler could evaluate the expression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> in extended precision throughout, computing its logarithm in the same precision, but evidently we cannot assume that the compiler will do so. (One can also imagine a similar example involving a user-defined function. In that case, a compiler could still keep the argument in extended precision even though the function returns a single precision result, but few if any existing Fortran compilers do this, either.) We might therefore attempt to ensure that <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> is evaluated consistently by assigning it to a variable. Unfortunately, if we declare that variable <code>real</code>, we may still be foiled by a compiler that substitutes a value kept in a register in extended precision for one appearance of the variable and a value stored in memory in single precision for another. Instead, we would need to declare the variable with a type that corresponds to the extended precision format. Standard FORTRAN 77 does not provide a way to do this, and while Fortran 95 offers the <code>SELECTED_REAL_KIND</code> mechanism for describing various formats, it does not explicitly require implementations that evaluate expressions in extended precision to allow variables to be declared with that precision. In short, there is no portable way to write this program in standard Fortran that is guaranteed to prevent the expression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> from being evaluated in a way that invalidates our proof.</font>
</p>


<p>
  <a name="3340"> </a><font face="Verdana, Arial, Helvetica, sans-serif">There are other examples that can malfunction on extended-based systems even when each subexpression is stored and thus rounded to the same precision. The cause is <em>double-rounding</em>. In the default precision mode, an extended-based system will initially round each result to extended double precision. If that result is then stored to double precision, it is rounded again. The combination of these two roundings can yield a value that is different than what would have been obtained by rounding the first result correctly to double precision. This can happen when the result as rounded to extended double precision is a "halfway case", i.e., it lies exactly halfway between two double precision numbers, so the second rounding is determined by the round-ties-to-even rule. If this second rounding rounds in the same direction as the first, the net rounding error will exceed half a unit in the last place. (Note, though, that double-rounding only affects double precision computations. One can prove that the sum, difference, product, or quotient of two <em>p</em>-bit numbers, or the square root of a <em>p</em>-bit number, rounded first to <em>q</em> bits and then to <em>p</em> bits gives the same value as if the result were rounded just once to <em>p</em> bits provided <em>q</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> 2<em>p</em> + 2. Thus, extended double precision is wide enough that single precision computations don't suffer double-rounding.)</font>
</p>


<p>
  <a name="3317"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Some algorithms that depend on correct rounding can fail with double-rounding. In fact, even some algorithms that don't require correct rounding and work correctly on a variety of machines that don't conform to IEEE 754 can fail with double-rounding. The most useful of these are the portable algorithms for performing simulated multiple precision arithmetic mentioned in the section <a href="ncg_goldberg.html#704">Exactly Rounded Operations</a>. For example, the procedure described in Theorem 6 for splitting a floating-point number into high and low parts doesn't work correctly in double-rounding arithmetic: try to split the double precision number 2<sup>52</sup> + 3&nbsp;<font  face="Verdana, Arial, Helvetica, sans-serif">&times;</font>&nbsp;2<sup>26</sup> - 1 into two parts each with at most 26 bits. When each operation is rounded correctly to double precision, the high order part is 2<sup>52</sup>&nbsp;+&nbsp;2<sup>27</sup> and the low order part is 2<sup>26</sup> - 1, but when each operation is rounded first to extended double precision and then to double precision, the procedure produces a high order part of 2<sup>52</sup> + 2<sup>28</sup> and a low order part of -2<sup>26</sup> - 1. The latter number occupies 27 bits, so its square can't be computed exactly in double precision. Of course, it would still be possible to compute the square of this number in extended double precision, but the resulting algorithm would no longer be portable to single/double systems. Also, later steps in the multiple precision multiplication algorithm assume that all partial products have been computed in double precision. Handling a mixture of double and extended double variables correctly would make the implementation significantly more expensive.</font>
</p>


<p>
  <a name="3214"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Likewise, portable algorithms for adding multiple precision numbers represented as arrays of double precision numbers can fail in double-rounding arithmetic. These algorithms typically rely on a technique similar to Kahan's summation formula. As the informal explanation of the summation formula given on <a href="ncg_goldberg.html#1262">Errors In Summation</a> suggests, if <code>s</code> and <code>y</code> are floating-point variables with |<code>s</code>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/gtequal.gif"></font> |<code>y</code>| and we compute: <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption align="left"><b></b></caption>
  <tr>
    <td><font face="Courier"><a name="3506"> </a>
<pre>t = s + y;
</pre><a name="3507"> </a>
<pre>e = (s - t) + y;
</pre></font></td>
  </tr>
</table>


</p>
 </font>
</p>


<p>
  <a name="3508"> </a><font face="Verdana, Arial, Helvetica, sans-serif">then in most arithmetics, <code>e</code> recovers exactly the roundoff error that occurred in computing <code>t</code>. This technique doesn't work in double-rounded arithmetic, however: if <code>s</code> = 2<sup>52</sup> + 1 and <code>y</code> = 1/2 - 2<sup>-54</sup>, then <code>s</code>&nbsp;<code>+</code>&nbsp;<code>y</code> rounds first to 2<sup>52</sup> + 3/2 in extended double precision, and this value rounds to 2<sup>52</sup> + 2 in double precision by the round-ties-to-even rule; thus the net rounding error in computing <code>t</code> is 1/2 + 2<sup>-54</sup>, which is not representable exactly in double precision and so can't be computed exactly by the expression shown above. Here again, it would be possible to recover the roundoff error by computing the sum in extended double precision, but then a program would have to do extra work to reduce the final outputs back to double precision, and double-rounding could afflict this process, too. For this reason, although portable programs for simulating multiple precision arithmetic by these methods work correctly and efficiently on a wide variety of machines, they do not work as advertised on extended-based systems.</font>
</p>


<p>
  <a name="3216"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, some algorithms that at first sight appear to depend on correct rounding may in fact work correctly with double-rounding. In these cases, the cost of coping with double-rounding lies not in the implementation but in the verification that the algorithm works as advertised. To illustrate, we prove the following variant of Theorem 7:</font>
</p>


<h4>
  <a name="3382"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Theorem 7'</font>
</h4>

<dl>
  <dt> <a name="3383"> </a><font face="Verdana, Arial, Helvetica, sans-serif"><em>If </em><font face="Arial,Helvetica"><em>m</em></font><em> and </em><font face="Arial,Helvetica"><em>n</em></font><em> are integers representable in IEEE 754 double precision with |m| &lt; </em>2<sup>52</sup><em> and </em><font face="Arial,Helvetica"><em>n</em></font><em> has the special form n = </em>2<sup><em>i</em></sup><em> + </em>2<sup><em>j</em></sup><em>, then (m </em><img src="images/ncg_goldberg72.gif" height="12" width="11">
<em> n) </em><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font><em> n = m, provided both floating-point operations are either rounded correctly to double precision or rounded first to extended double precision and then to double precision.</em> </font>
</dl>

<h4>
  <a name="3389"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Proof</font>
</h4>


<p>
  <a name="3380"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Assume without loss that <em>m</em> &gt; 0. Let <em>q</em> = <em>m </em><img src="images/ncg_goldberg63.gif" height="12" width="11">
<em> n</em>. Scaling by powers of two, we can consider an equivalent setting in which 2<sup>52</sup> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <em>m</em> &lt; 2<sup>53</sup> and likewise for <em>q</em>, so that both <em>m</em> and <em>q</em> are integers whose least significant bits occupy the units place (i.e., ulp(<em>m</em>) = ulp(<em>q</em>) = 1). Before scaling, we assumed <em>m</em> &lt; 2<sup>52</sup>, so after scaling, <em>m </em>is an even integer. Also, because the scaled values of <em>m</em> and <em>q</em> satisfy <em>m</em>/2 &lt; <em>q</em> &lt; 2<em>m</em>, the corresponding value of <em>n</em> must have one of two forms depending on which of <em>m</em> or <em>q</em> is larger: if <em>q</em>&nbsp;&lt;&nbsp;<em>m</em>, then evidently 1 &lt; <em>n</em> &lt; 2, and since <em>n</em> is a sum of two powers of two, <em>n</em> = 1 + 2<sup>-</sup><sup><em>k</em></sup> for some <em>k</em>; similarly, if <em>q</em> &gt; <em>m</em>, then 1/2 &lt; <em>n</em> &lt; 1, so <em>n</em> = 1/2 + 2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup>. (As <em>n</em> is the sum of two powers of two, the closest possible value of <em>n</em> to one is <em>n</em> = 1 + 2<sup>-52</sup>. Because <em>m</em>/(1&nbsp;+ 2<sup>-52</sup>) is no larger than the next smaller double precision number less than <em>m</em>, we can't have <em>q</em> = <em>m</em>.)</font>
</p>


<p>
  <a name="3546"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Let <em>e</em> denote the rounding error in computing <em>q</em>, so that <em>q</em> = <em>m</em>/<em>n</em> + <em>e</em>, and the computed value <em>q</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <em>n</em> will be the (once or twice) rounded value of <em>m</em> + <em>ne</em>. Consider first the case in which each floating-point operation is rounded correctly to double precision. In this case, |<em>e</em>| &lt; 1/2. If <em>n</em> has the form 1/2 + 2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup>, then <em>ne</em> = <em>nq</em> - <em>m</em> is an integer multiple of 2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup> and |<em>ne</em>| &lt; 1/4 + 2<sup>-(</sup><sup><em>k</em></sup><sup>&nbsp;+&nbsp;2)</sup>. This implies that |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/4. Recall that the difference between <em>m</em> and the next larger representable number is 1 and the difference between <em>m</em> and the next smaller representable number is either 1 if <em>m</em> &gt; 2<sup>52</sup> or 1/2 if <em>m</em> = 2<sup>52</sup>. Thus, as |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/4, <em>m</em> + <em>ne</em> will round to <em>m</em>. (Even if <em>m</em> = 2<sup>52</sup> and <em>ne</em> = -1/4, the product will round to <em>m</em> by the round-ties-to-even rule.) Similarly, if <em>n</em> has the form 1 + 2<sup>-</sup><sup><em>k</em></sup>, then <em>ne</em> is an integer multiple of 2<sup>-</sup><sup><em>k</em></sup> and |<em>ne</em>|&nbsp;&lt;&nbsp;1/2&nbsp;+ 2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup>; this implies |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/2. We can't have <em>m</em> = 2<sup>52</sup> in this case because <em>m</em> is strictly greater than <em>q</em>, so <em>m</em> differs from its nearest representable neighbors by <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font>1. Thus, as |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/2, again <em>m</em> + <em>ne</em> will round to <em>m</em>. (Even if |<em>ne</em>| = 1/2, the product will round to <em>m</em> by the round-ties-to-even rule because <em>m</em> is even.) This completes the proof for correctly rounded arithmetic.</font>
</p>


<p>
  <a name="3415"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In double-rounding arithmetic, it may still happen that <em>q</em> is the correctly rounded quotient (even though it was actually rounded twice), so |<em>e</em>| &lt; 1/2 as above. In this case, we can appeal to the arguments of the previous paragraph provided we consider the fact that <em>q</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/circmult.gif"></font> <em>n</em> will be rounded twice. To account for this, note that the IEEE standard requires that an extended double format carry at least 64 significant bits, so that the numbers <em>m</em> <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> 1/2 and <em>m</em> <font  face="Verdana, Arial, Helvetica, sans-serif">&#177;</font> 1/4 are exactly representable in extended double precision. Thus, if <em>n</em> has the form 1/2 + 2<sup>-(</sup><sup><em>k</em></sup><sup>&nbsp;+&nbsp;1)</sup>, so that |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/4, then rounding <em>m</em> + <em>ne</em> to extended double precision must produce a result that differs from <em>m</em> by at most 1/4, and as noted above, this value will round to <em>m</em> in double precision. Similarly, if <em>n</em> has the form 1 + 2<sup>-</sup><sup><em>k</em></sup>, so that |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/2, then rounding <em>m</em>&nbsp;+&nbsp;<em>ne</em> to extended double precision must produce a result that differs from <em>m</em> by at most 1/2, and this value will round to <em>m</em> in double precision. (Recall that <em>m</em> &gt; 2<sup>52</sup> in this case.)</font>
</p>


<p>
  <a name="3540"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Finally, we are left to consider cases in which <em>q</em> is not the correctly rounded quotient due to double-rounding. In these cases, we have |<em>e</em>| &lt; 1/2 + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 1)</sup> in the worst case, where <em>d</em> is the number of extra bits in the extended double format. (All existing extended-based systems support an extended double format with exactly 64 significant bits; for this format, <em>d</em> = 64 - 53 = 11.) Because double-rounding only produces an incorrectly rounded result when the second rounding is determined by the round-ties-to-even rule, <em>q</em> must be an even integer. Thus if <em>n</em> has the form 1/2&nbsp;+&nbsp;2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup>, then <em>ne</em> = <em>nq</em> - <em>m</em> is an integer multiple of 2<sup>-</sup><sup><em>k</em></sup>, and </font>
</p>


<a name="12699"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">|<em>ne</em>| &lt; (1/2&nbsp;+&nbsp;2<sup>-(</sup><sup><em>k</em></sup><sup>&nbsp;+&nbsp;1)</sup>)(1/2 + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 1)</sup>) = 1/4 + 2<sup>-(</sup><sup><em>k</em></sup><sup> +&nbsp;2)</sup> + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 2)</sup> + 2<sup>-(</sup><sup><em>k</em></sup><sup> + </sup><sup><em>d</em></sup><sup> + 2)</sup>. <br></font>


<p>
  <a name="12700"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <em>k</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <em>d</em>, this implies |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/4. If <em>k</em> &gt; <em>d</em>, we have |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/4 + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 2)</sup>. In either case, the first rounding of the product will deliver a result that differs from <em>m</em> by at most 1/4, and by previous arguments, the second rounding will round to <em>m</em>. Similarly, if <em>n</em> has the form 1 + 2<sup>-</sup><sup><em>k</em></sup>, then <em>ne</em> is an integer multiple of 2<sup>-(</sup><sup><em>k</em></sup><sup> - 1)</sup>, and</font>
</p>


<a name="12701"> </a><font  size="2" face="Verdana, Arial, Helvetica, sans-serif">|<em>ne</em>| &lt; 1/2 + 2<sup>-(</sup><sup><em>k</em></sup><sup> + 1)</sup> + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 1)</sup> + 2<sup>-(</sup><sup><em>k</em></sup><sup> + </sup><sup><em>d</em></sup><sup> + 1)</sup>. <br></font>


<p>
  <a name="12703"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If <em>k</em> <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> <em>d</em>, this implies |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/2. If <em>k</em> &gt; <em>d</em>, we have |<em>ne</em>| <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/lt_equal.gif"></font> 1/2 + 2<sup>-(</sup><sup><em>d</em></sup><sup> + 1)</sup>. In either case, the first rounding of the product will deliver a result that differs from <em>m</em> by at most 1/2, and again by previous arguments, the second rounding will round to <em>m</em>. <font  size="1" face="Verdana, Arial, Helvetica, sans-serif">z</font> </font>
</p>


<p>
  <a name="3497"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The preceding proof shows that the product can incur double-rounding only if the quotient does, and even then, it rounds to the correct result. The proof also shows that extending our reasoning to include the possibility of double-rounding can be challenging even for a program with only two floating-point operations. For a more complicated program, it may be impossible to systematically account for the effects of double-rounding, not to mention more general combinations of double and extended double precision computations.</font>
</p>


<h3>
  <a name="3922"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Programming Language Support for Extended Precision</font>
</h3>


<p>
  <a name="3927"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The preceding examples should not be taken to suggest that extended precision <em>per se</em> is harmful. Many programs can benefit from extended precision when the programmer is able to use it selectively. Unfortunately, current programming languages do not provide sufficient means for a programmer to specify when and how extended precision should be used. To indicate what support is needed, we consider the ways in which we might want to manage the use of extended precision.</font>
</p>


<p>
  <a name="3945"> </a><font face="Verdana, Arial, Helvetica, sans-serif">In a portable program that uses double precision as its nominal working precision, there are five ways we might want to control the use of a wider precision:</font>
</p>

<ol type="1">
<p><li value="1"><a name="3946"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Compile to produce the fastest code, using extended precision where possible on extended-based systems. Clearly most numerical software does not require more of the arithmetic than that the relative error in each operation is bounded by the "machine epsilon". When data in memory are stored in double precision, the machine epsilon is usually taken to be the largest relative roundoff error in that precision, since the input data are (rightly or wrongly) assumed to have been rounded when they were entered and the results will likewise be rounded when they are stored. Thus, while computing some of the intermediate results in extended precision may yield a more accurate result, extended precision is not essential. In this case, we might prefer that the compiler use extended precision only when it will not appreciably slow the program and use double precision otherwise.</font>
</p><p><li value="2"><a name="3947"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Use a format wider than double if it is reasonably fast and wide enough, otherwise resort to something else. Some computations can be performed more easily when extended precision is available, but they can also be carried out in double precision with only somewhat greater effort. Consider computing the Euclidean norm of a vector of double precision numbers. By computing the squares of the elements and accumulating their sum in an IEEE 754 extended double format with its wider exponent range, we can trivially avoid premature underflow or overflow for vectors of practical lengths. On extended-based systems, this is the fastest way to compute the norm. On single/double systems, an extended double format would have to be emulated in software (if one were supported at all), and such emulation would be much slower than simply using double precision, testing the exception flags to determine whether underflow or overflow occurred, and if so, repeating the computation with explicit scaling. Note that to support this use of extended precision, a language must provide both an indication of the widest available format that is reasonably fast, so that a program can choose which method to use, and environmental parameters that indicate the precision and range of each format, so that the program can verify that the widest fast format is wide enough (e.g., that it has wider range than double).</font>
</p><p><li value="3"><a name="3948"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Use a format wider than double even if it has to be emulated in software. For more complicated programs than the Euclidean norm example, the programmer may simply wish to avoid the need to write two versions of the program and instead rely on extended precision even if it is slow. Again, the language must provide environmental parameters so that the program can determine the range and precision of the widest available format.</font>
</p><p><li value="4"><a name="3949"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Don't use a wider precision; round results correctly to the precision of the double format, albeit possibly with extended range. For programs that are most easily written to depend on correctly rounded double precision arithmetic, including some of the examples mentioned above, a language must provide a way for the programmer to indicate that extended precision must not be used, even though intermediate results may be computed in registers with a wider exponent range than double. (Intermediate results computed in this way can still incur double-rounding if they underflow when stored to memory: if the result of an arithmetic operation is rounded first to 53 significant bits, then rounded again to fewer significant bits when it must be denormalized, the final result may differ from what would have been obtained by rounding just once to a denormalized number. Of course, this form of double-rounding is highly unlikely to affect any practical program adversely.)</font>
</p><p><li value="5"><a name="3950"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Round results correctly to both the precision and range of the double format. This strict enforcement of double precision would be most useful for programs that test either numerical software or the arithmetic itself near the limits of both the range and precision of the double format. Such careful test programs tend to be difficult to write in a portable way; they become even more difficult (and error prone) when they must employ dummy subroutines and other tricks to force results to be rounded to a particular format. Thus, a programmer using an extended-based system to develop robust software that must be portable to all IEEE 754 implementations would quickly come to appreciate being able to emulate the arithmetic of single/double systems without extraordinary effort.</font>
</p></ol>

<p>
  <a name="3951"> </a><font face="Verdana, Arial, Helvetica, sans-serif">No current language supports all five of these options. In fact, few languages have attempted to give the programmer the ability to control the use of extended precision at all. One notable exception is the ISO/IEC 9899:1999 Programming Languages - C standard, the latest revision to the C language, which is now in the final stages of standardization.</font>
</p>


<p>
  <a name="4014"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The C99 standard allows an implementation to evaluate expressions in a format wider than that normally associated with their type, but the C99 standard recommends using one of only three expression evaluation methods. The three recommended methods are characterized by the extent to which expressions are "promoted" to wider formats, and the implementation is encouraged to identify which method it uses by defining the preprocessor macro <code>FLT_EVAL_METHOD</code>: if <code>FLT_EVAL_METHOD</code> is 0, each expression is evaluated in a format that corresponds to its type; if <code>FLT_EVAL_METHOD</code> is 1, <code>float</code> expressions are promoted to the format that corresponds to <code>double</code>; and if <code>FLT_EVAL_METHOD</code> is 2, <code>float</code> and <code>double</code> expressions are promoted to the format that corresponds to <code>long double</code>. (An implementation is allowed to set <code>FLT_EVAL_METHOD</code> to -1 to indicate that the expression evaluation method is indeterminable.) The C99 standard also requires that the <code>&lt;math.h&gt;</code> header file define the types <code>float_t</code> and <code>double_t</code>, which are at least as wide as <code>float</code> and <code>double</code>, respectively, and are intended to match the types used to evaluate <code>float</code> and <code>double</code> expressions. For example, if <code>FLT_EVAL_METHOD</code> is 2, both <code>float_t</code> and <code>double_t</code> are <code>long double</code>. Finally, the C99 standard requires that the <code>&lt;float.h&gt;</code> header file define preprocessor macros that specify the range and precision of the formats corresponding to each floating-point type.</font>
</p>


<p>
  <a name="4073"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The combination of features required or recommended by the C99 standard supports some of the five options listed above but not all. For example, if an implementation maps the <code>long double</code> type to an extended double format and defines <code>FLT_EVAL_METHOD</code> to be 2, the programmer can reasonably assume that extended precision is relatively fast, so programs like the Euclidean norm example can simply use intermediate variables of type <code>long double</code> (or <code>double_t</code>). On the other hand, the same implementation must keep anonymous expressions in extended precision even when they are stored in memory (e.g., when the compiler must spill floating-point registers), and it must store the results of expressions assigned to variables declared <code>double</code> to convert them to double precision even if they could have been kept in registers. Thus, neither the <code>double</code> nor the <code>double_t</code> type can be compiled to produce the fastest code on current extended-based hardware.</font>
</p>


<p>
  <a name="4027"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Likewise, the C99 standard provides solutions to some of the problems illustrated by the examples in this section but not all. A C99 standard version of the <code>log1p</code> function is guaranteed to work correctly if the expression <code>1.0</code>&nbsp;<code>+</code>&nbsp;<code>x</code> is assigned to a variable (of any type) and that variable used throughout. A portable, efficient C99 standard program for splitting a double precision number into high and low parts, however, is more difficult: how can we split at the correct position and avoid double-rounding if we cannot guarantee that <code>double</code> expressions are rounded correctly to double precision? One solution is to use the <code>double_t</code> type to perform the splitting in double precision on single/double systems and in extended precision on extended-based systems, so that in either case the arithmetic will be correctly rounded. Theorem 14 says that we can split at any bit position provided we know the precision of the underlying arithmetic, and the <code>FLT_EVAL_METHOD</code> and environmental parameter macros should give us this information.</font>
</p>


<p>
  <a name="11089"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The following fragment shows one possible implementation: <p>
<table border="1" bordercolorlight="#FFFFFF" bordercolordark="#000000"
       cellpadding="5" cellspacing="0">
  <caption align="left"><b></b></caption>
  <tr>
    <td><font face="Courier"><a name="4101"> </a>
<pre>#include &lt;math.h&gt;
</pre><a name="4106"> </a>
<pre>#include &lt;float.h&gt;
</pre><a name="4107"> </a>
<pre>
</pre><a name="4108"> </a>
<pre>#if (FLT_EVAL_METHOD==2)
</pre><a name="4109"> </a>
<pre>#define PWR2  LDBL_MANT_DIG - (DBL_MANT_DIG/2)
</pre><a name="4110"> </a>
<pre>#elif ((FLT_EVAL_METHOD==1) || (FLT_EVAL_METHOD==0))
</pre><a name="4102"> </a>
<pre>#define PWR2  DBL_MANT_DIG - (DBL_MANT_DIG/2)
</pre><a name="4111"> </a>
<pre>#else
</pre><a name="4113"> </a>
<pre>#error FLT_EVAL_METHOD unknown!
</pre><a name="4112"> </a>
<pre>#endif
</pre><a name="4114"> </a>
<pre>
</pre><a name="4115"> </a>
<pre>...
</pre><a name="4116"> </a>
<pre>    double   x, xh, xl;
</pre><a name="4117"> </a>
<pre>    double_t m;
</pre><a name="4118"> </a>
<pre>
</pre><a name="4120"> </a>
<pre>    m = scalbn(1.0, PWR2) + 1.0;  // 2**PWR2 + 1
</pre><a name="4124"> </a>
<pre>    xh = (m * x) - ((m * x) - x);
</pre><a name="4125"> </a>
<pre>    xl = x - xh;
</pre></font></td>
  </tr>
</table>


</p>
 </font>
</p>


<p>
  <a name="4130"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Of course, to find this solution, the programmer must know that <code>double</code> expressions may be evaluated in extended precision, that the ensuing double-rounding problem can cause the algorithm to malfunction, and that extended precision may be used instead according to Theorem 14. A more obvious solution is simply to specify that each expression be rounded correctly to double precision. On extended-based systems, this merely requires changing the rounding precision mode, but unfortunately, the C99 standard does not provide a portable way to do this. (Early drafts of the Floating-Point C Edits, the working document that specified the changes to be made to the C90 standard to support floating-point, recommended that implementations on systems with rounding precision modes provide <code>fegetprec</code> and <code>fesetprec</code> functions to get and set the rounding precision, analogous to the <code>fegetround</code> and <code>fesetround</code> functions that get and set the rounding direction. This recommendation was removed before the changes were made to the C99 standard.)</font>
</p>


<p>
  <a name="4133"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Coincidentally, the C99 standard's approach to supporting portability among systems with different integer arithmetic capabilities suggests a better way to support different floating-point architectures. Each C99 standard implementation supplies an <code>&lt;stdint.h&gt;</code> header file that defines those integer types the implementation supports, named according to their sizes and efficiency: for example, <code>int32_t</code> is an integer type exactly 32 bits wide, <code>int_fast16_t</code> is the implementation's fastest integer type at least 16 bits wide, and <code>intmax_t</code> is the widest integer type supported. One can imagine a similar scheme for floating-point types: for example, <code>float53_t</code> could name a floating-point type with exactly 53 bit precision but possibly wider range, <code>float_fast24_t</code> could name the implementation's fastest type with at least 24 bit precision, and <code>floatmax_t</code> could name the widest reasonably fast type supported. The fast types could allow compilers on extended-based systems to generate the fastest possible code subject only to the constraint that the values of named variables must not appear to change as a result of register spilling. The exact width types would cause compilers on extended-based systems to set the rounding precision mode to round to the specified precision, allowing wider range subject to the same constraint. Finally, <code>double_t</code> could name a type with both the precision and range of the IEEE 754 double format, providing strict double evaluation. Together with environmental parameter macros named accordingly, such a scheme would readily support all five options described above and allow programmers to indicate easily and unambiguously the floating-point semantics their programs require.</font>
</p>


<p>
  <a name="4202"> </a><font face="Verdana, Arial, Helvetica, sans-serif">Must language support for extended precision be so complicated? On single/double systems, four of the five options listed above coincide, and there is no need to differentiate fast and exact width types. Extended-based systems, however, pose difficult choices: they support neither pure double precision nor pure extended precision computation as efficiently as a mixture of the two, and different programs call for different mixtures. Moreover, the choice of when to use extended precision should not be left to compiler writers, who are often tempted by benchmarks (and sometimes told outright by numerical analysts) to regard floating-point arithmetic as "inherently inexact" and therefore neither deserving nor capable of the predictability of integer arithmetic. Instead, the choice must be presented to programmers, and they will require languages capable of expressing their selection.</font>
</p>


<h3>
  <a name="3365"> </a><font color="#003366" face="Verdana, Arial, Helvetica, sans-serif">Conclusion</font>
</h3>


<p>
  <a name="3220"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The foregoing remarks are not intended to disparage extended-based systems but to expose several fallacies, the first being that all IEEE 754 systems must deliver identical results for the same program. We have focused on differences between extended-based systems and single/double systems, but there are further differences among systems within each of these families. For example, some single/double systems provide a single instruction to multiply two numbers and add a third with just one final rounding. This operation, called a <em>fused multiply-add</em>, can cause the same program to produce different results across different single/double systems, and, like extended precision, it can even cause the same program to produce different results on the same system depending on whether and when it is used. (A fused multiply-add can also foil the splitting process of Theorem 6, although it can be used in a non-portable way to perform multiple precision multiplication without the need for splitting.) Even though the IEEE standard didn't anticipate such an operation, it nevertheless conforms: the intermediate product is delivered to a "destination" beyond the user's control that is wide enough to hold it exactly, and the final sum is rounded correctly to fit its single or double precision destination.</font>
</p>


<p>
  <a name="4304"> </a><font face="Verdana, Arial, Helvetica, sans-serif">The idea that IEEE 754 prescribes precisely the result a given program must deliver is nonetheless appealing. Many programmers like to believe that they can understand the behavior of a program and prove that it will work correctly without reference to the compiler that compiles it or the computer that runs it. In many ways, supporting this belief is a worthwhile goal for the designers of computer systems and programming languages. Unfortunately, when it comes to floating-point arithmetic, the goal is virtually impossible to achieve. The authors of the IEEE standards knew that, and they didn't attempt to achieve it. As a result, despite nearly universal conformance to (most of) the IEEE 754 standard throughout the computer industry, programmers of portable software must continue to cope with unpredictable floating-point arithmetic.</font>
</p>


<p>
  <a name="4311"> </a><font face="Verdana, Arial, Helvetica, sans-serif">If programmers are to exploit the features of IEEE 754, they will need programming languages that make floating-point arithmetic predictable. The C99 standard improves predictability to some degree at the expense of requiring programmers to write multiple versions of their programs, one for each <code>FLT_EVAL_METHOD</code>. Whether future languages will choose instead to allow programmers to write a single program with syntax that unambiguously expresses the extent to which it depends on IEEE 754 semantics remains to be seen. Existing extended-based systems threaten that prospect by tempting us to assume that the compiler and the hardware can know better than the programmer how a computation should be performed on a given system. That assumption is the second fallacy: the accuracy required in a computed result depends not on the machine that produces it but only on the conclusions that will be drawn from it, and of the programmer, the compiler, and the hardware, at best only the programmer can know what those conclusions may be.</font>
</p>


  <a href="#683"><sup>1</sup></a>
<a name="1370"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Examples of other representations are <em>floating slash</em> and <em>signed logarithm </em>[Matula and Kornerup 1985; Swartzlander and Alexopoulos 1975].</font></p>

<a href="#10061"><sup>2</sup></a>
<a name="1377"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">This term was introduced by Forsythe and Moler [1967], and has generally replaced the older term <em>mantissa</em>.</font></p>

<a href="#684"><sup>3</sup></a>
<a name="685"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">This assumes the usual arrangement where the exponent is stored to the left of the significand.</font></p>

<a href="#688"><sup>4</sup></a>
<a name="690"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Unless the number <font face="Arial,Helvetica"><em>z</em></font> is larger than <img src="images/ncg_goldberg97.gif" height="18" width="24">
+1 or smaller than <img src="images/ncg_goldberg91.gif" height="18" width="24">
. Numbers which are out of range in this fashion will not be considered until further notice.</font></p>

<a href="#688"><sup>5</sup></a>
<a name="728"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Let <font face="Arial,Helvetica"><em>z</em></font>' be the floating-point number that approximates <font face="Arial,Helvetica"><em>z</em></font>. Then <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakmidl.gif"></font><font face="Arial,Helvetica"><em>d.d</em></font><font  face="Verdana, Arial, Helvetica, sans-serif">...</font><font face="Arial,Helvetica"><em>d</em></font> - (<font face="Arial,Helvetica"><em>z</em></font>/<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>e</em></sup>)<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/brakmidl.gif"><img src="chars/beta.gif"></font><sup><em>p-1</em></sup> is equivalent to             <img src="chars/brakmidl.gif"><font face="Arial,Helvetica"><em>z</em></font>'-<font face="Arial,Helvetica"><em>z</em></font><img src="chars/brakmidl.gif">/ulp(<font face="Arial,Helvetica"><em>z</em></font>'). A more accurate formula for measuring error is <img src="chars/brakmidl.gif"><font face="Arial,Helvetica"><em>z</em></font>'-<font face="Arial,Helvetica"><em>z</em></font><img src="chars/brakmidl.gif">/ulp(<font face="Arial,Helvetica"><em>z</em></font>). - Ed. </font></p>

<a href="#9518"><sup>6</sup></a>
<a name="9521"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">700, not 70. Since .1 - .0292 = .0708, the error in terms of ulp(0.0292) is 708 ulps. - Ed.</font></p>

<a href="#1393"><sup>7</sup></a>
<a name="1397"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Although the expression (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) does not cause a catastrophic cancellation, it is slightly less accurate than <font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> -<font face="Arial,Helvetica"><em> y</em></font><sup>2</sup> if <img src="images/ncg_goldberg149.gif" height="13" width="26">
 or <img src="images/ncg_goldberg155.gif" height="13" width="26">
. In this case, (<font face="Arial,Helvetica"><em>x</em></font> - <font face="Arial,Helvetica"><em>y</em></font>)(<font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>y</em></font>) has three rounding errors, but x<sup>2</sup> - y<sup>2 </sup>has only two since the rounding error committed when computing the smaller of <font face="Arial,Helvetica"><em>x</em></font><sup>2</sup> and <font face="Arial,Helvetica"><em>y</em></font><sup>2</sup> does not affect the final subtraction.</font></p>

<a href="#705"><sup>8</sup></a>
<a name="729"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Also commonly referred to as <em>correctly rounded</em>. -  Ed. </font></p>

<a href="#11655"><sup>9</sup></a>
<a name="730"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">When n = 845, x<sub>n</sub>= 9.45, x<sub>n</sub> + 0.555 = 10.0, and 10.0 - 0.555 = 9.45. Therefore, x<sub>n</sub> = x<sub>845 </sub>for<font face="Arial,Helvetica"><em> n</em></font> &gt; 845. </font></p>

<a href="#11706"><sup>10</sup></a>
<a name="11697"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Notice that in binary,<em> q</em> cannot equal <img src="images/ncg_goldberg217.gif" height="16" width="10">
 . - Ed. </font></p>

<a href="#9922"><sup>11</sup></a>
<a name="9921"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Left as an exercise to the reader: extend the proof to bases other than 2. - Ed. </font></p>

<a href="#807"><sup>12</sup></a>
<a name="808"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">This appears to have first been published by Goldberg [1967], although Knuth ([1981], page 211) attributes this idea to Konrad Zuse.<br></font>

<a href="#853"><sup>13</sup></a>
<a name="854"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">According to Kahan, extended precision has 64 bits of significand because that was the widest precision across which carry propagation could be done on the Intel 8087 without increasing the cycle time [Kahan 1988].<br></font>

<a href="#12892"><sup>14</sup></a>
<a name="12895"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Some arguments against including inner product as one of the basic operations are presented by Kahan and LeBlanc [1985].</font></p>

<a href="#12892"><sup>15</sup></a>
<a name="12898"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">Kirchner writes: It is possible to compute inner products to within 1 ulp in hardware in one partial product per clock cycle. The additionally needed hardware compares to the multiplier array needed anyway for that speed. <br></font>

<a href="#873"><sup>16</sup></a>
<a name="874"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">CORDIC is an acronym for Coordinate Rotation Digital Computer and is a method of computing transcendental functions that uses mostly shifts and adds (i.e., very few multiplications and divisions) [Walther 1971]. It is the method additionally needed hardware compares to the multiplier array needed anyway for that speed. d used on both the Intel 8087 and the Motorola 68881.<br></font>

<a href="#919"><sup>17</sup></a>
<a name="920"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Fine point: Although the default in IEEE arithmetic is to round overflowed numbers to <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, it is possible to change the default (see <a href="ncg_goldberg.html#984">Rounding Modes</a>)</font></p>

<a href="#936"><sup>18</sup></a>
<a name="935"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">They are called <em>subnormal</em> in 854, <em>denormal</em> in 754.</font></p>

<a href="#936"><sup>19</sup></a>
<a name="937"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">This is the cause of one of the most troublesome aspects of the standard. Programs that frequently underflow often run noticeably slower on hardware that uses software traps.<br></font>

<a href="#5376"><sup>20</sup></a>
<a name="5385"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">No invalid exception is raised unless a "trapping" NaN is involved in the operation. See section 6.2 of IEEE Std 754-1985. - Ed. </font></p>

<a href="#717"><sup>21</sup></a>
<a name="753"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1"><img src="images/ncg_goldberg291.gif" height="18" width="9">
 may be greater than <img src="images/ncg_goldberg295.gif" height="16" width="9">
 if both x and y are negative. - Ed. </font></p>

<a href="#6183"><sup>22</sup></a>
<a name="6189"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">It can be in range because if <em>x</em> &lt; 1, <font face="Arial,Helvetica"><em>n</em></font> &lt;  0 and <em>x</em><sup>-</sup><sup><em>n</em></sup> is just a tiny bit smaller than the underflow threshold <img src="images/ncg_goldberg66.gif" height="20" width="26">
, then <img src="images/ncg_goldberg79.gif" height="20" width="92">
, and so may not overflow, since in all IEEE precisions, -<em>e</em><sub>min</sub> &lt; <em>e</em><sub>max.</sub></font></p>

<a href="#12036"><sup>23</sup></a>
<a name="12039"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">This is probably because designers like "orthogonal" instruction sets, where the precisions of a floating-point instruction are independent of the actual operation. Making a special case for multiplication destroys this orthogonality.</font></p>

<a href="#1053"><sup>24</sup></a>
<a name="1054"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">This assumes the common convention that <code>3.0</code> is a single-precision constant, while <code>3.0D0</code> is a double precision constant.</font></p>

<a href="#1060"><sup>25</sup></a>
<a name="1061"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">The conclusion that 0<sup>0</sup> = 1 depends on the restriction that <font face="Arial,Helvetica"><em>f</em></font> be nonconstant. If this restriction is removed, then letting <font face="Arial,Helvetica"><em>f</em></font> be the identically 0 function gives 0 as a possible value for lim <sub>x <img src="chars/arrwrite.gif"> 0</sub> <font face="Arial,Helvetica"><em>f</em></font>(<font face="Arial,Helvetica"><em>x</em></font>)<sup><em>g</em></sup><sup>(</sup><sup><em>x</em></sup><sup>)</sup>, and so 0<sup>0</sup> would have to be defined to be a NaN.</font></p>

<a href="#1060"><sup>26</sup></a>
<a name="1062"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">In the case of 0<sup>0</sup>, plausibility arguments can be made, but the convincing argument is found in "Concrete Mathematics" by Graham, Knuth and Patashnik, and argues that 0<font  size="3" face="Verdana, Arial, Helvetica, sans-serif">0</font> = 1 for the binomial theorem to work.          - Ed. <br></font>

<a href="#1066"><sup>27</sup></a>
<a name="1067"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">Unless the rounding mode is round toward -<font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/infinity.gif"></font>, in which case <em>x</em> - <font face="Arial,Helvetica"><em>x</em></font> = -0.</font></p>

<a href="#1102"><sup>28</sup></a>
<a name="1103"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">The VMS math libraries on the VAX use a weak form of in-line procedure substitution, in that they use the inexpensive jump to subroutine call rather than the slower <code>CALLS</code> and <code>CALLG</code> instructions.</font></p>

<a href="#1123"><sup>29</sup></a>
<a name="1124"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">The difficulty with presubstitution is that it requires either direct hardware implementation, or continuable floating-point traps if implemented in software. - Ed. </font></p>

<a href="#1240"><sup>30</sup></a>
<a name="1241"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">In this informal proof, assume that <img src="chars/beta.gif"> = 2 so that multiplication by 4 is exact and doesn't require a <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/delta.gif"></font><sub><em>i.</em></sub></font></p>

<a href="#1196"><sup>31</sup></a>
<a name="1343"> </a><font face="Verdana, Arial, Helvetica, sans-serif" size="-1">This is the sum if adding w does not generate carry out. Additional argument is needed for the special case where adding w does generate carry out. - Ed. </font></p>

<a href="#1344"><sup>32</sup></a>
<a name="1345"> </a><font  size="1" face="Verdana, Arial, Helvetica, sans-serif">Rounding gives <font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup> - <font face="Arial,Helvetica"><em>r</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k </em></sup>only if<sup> (</sup><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font> + <font face="Arial,Helvetica"><em>w</em></font><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><sup>) </sup>keeps the form of<sup> </sup><font  face="Verdana, Arial, Helvetica, sans-serif"><img src="chars/beta.gif"></font><sup><em>k</em></sup><font face="Arial,Helvetica"><em>x</em></font><sup>. </sup>-<sup> Ed. </sup><br></font>

</blockquote>

<hr>

<!-- BEGINNING OF NAVIGATION BAR ------------------------------------------------- -->

<table width="100%" cellpadding="6" cellspacing-"0" border="0">
<tr>
<td valign="top" align="left">
<font size="2">
<a href="http://www.sun.com">Sun Microsystems, Inc.</a><br>
<a href="PRN.html">Copyright information</a>. All rights reserved.<br>
<a href="http://www.sun.com/cgi-bin/comment-form.pl">Feedback</a><br>
</font>
</td>

<td valign="top" align="right">
<font face="helvetica,arial" size="2">
<a href="../../../index.html">Library</a>
&nbsp;&nbsp;|&nbsp;&nbsp;
<a href="ncgTOC.html">Contents</a>
&nbsp;&nbsp;|&nbsp;&nbsp;
<a href="ncg_x86.html">Previous</a>
&nbsp;&nbsp;|&nbsp;&nbsp;
<a href="ncg_compliance.html">Next</a>
&nbsp;&nbsp;|&nbsp;&nbsp;
<a href="ncgIX.html">Index</a>
</font>
</td>

</tr>
</table>

<!-- END OF NAVIGATION BAR ------------------------------------------------------- -->

</body>
</html>
